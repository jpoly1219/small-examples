<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml producer="poppler" version="24.02.0">
<page number="1" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="0" size="22" family="GAQDOW+LinBiolinumTB" color="#000000"/>
	<fontspec id="1" size="16" family="WVOPFG+LinBiolinumT" color="#005595"/>
	<fontspec id="2" size="16" family="WVOPFG+LinBiolinumT" color="#000000"/>
	<fontspec id="3" size="13" family="JZXWNF+LinLibertineT" color="#000000"/>
	<fontspec id="4" size="13" family="PFQUFB+LinLibertineTB" color="#000000"/>
	<fontspec id="5" size="13" family="NVCMIJ+txsys" color="#000000"/>
	<fontspec id="6" size="13" family="BQBJUC+LinLibertineTI" color="#000000"/>
	<fontspec id="7" size="13" family="JZXWNF+LinLibertineT" color="#781d7d"/>
	<fontspec id="8" size="13" family="JZXWNF+LinLibertineT" color="#005595"/>
	<fontspec id="9" size="12" family="JZXWNF+LinLibertineT" color="#000000"/>
	<fontspec id="10" size="12" family="JZXWNF+LinLibertineT" color="#005595"/>
	<fontspec id="11" size="12" family="IMUZXN+LinLibertineT" color="#000000"/>
<image top="895" left="69" width="73" height="25" src="output-1_1.png"/>
<image top="108" left="0" width="39" height="39" src="output-1_2.png"/>
<text top="127" left="69" width="542" height="20" font="0">Statically Contextualizing Large Language Models with</text>
<text top="152" left="68" width="121" height="20" font="0">Typed Holes</text>
<text top="191" left="68" width="119" height="15" font="1"><a href="HTTPS://ORCID.ORG/0000-0001-6938-7379">ANDREW BLINN</a></text>
<text top="191" left="187" width="4" height="15" font="2"><a href="HTTPS://ORCID.ORG/0000-0001-6938-7379">,</a></text>
<text top="193" left="194" width="158" height="13" font="3">University of Michigan, USA</text>
<text top="210" left="68" width="65" height="15" font="1"><a href="HTTPS://ORCID.ORG/0009-0005-6860-039X">XIANG LI</a></text>
<text top="210" left="134" width="4" height="15" font="2"><a href="HTTPS://ORCID.ORG/0009-0005-6860-039X">,</a></text>
<text top="212" left="141" width="158" height="13" font="3">University of Michigan, USA</text>
<text top="230" left="68" width="132" height="15" font="1"><a href="HTTPS://ORCID.ORG/0009-0005-0820-9532">JUNE HYUNG KIM</a></text>
<text top="230" left="200" width="4" height="15" font="2"><a href="HTTPS://ORCID.ORG/0009-0005-0820-9532">,</a></text>
<text top="231" left="207" width="158" height="13" font="3">University of Michigan, USA</text>
<text top="249" left="69" width="101" height="15" font="1"><a href="HTTPS://ORCID.ORG/0000-0003-4502-7971">CYRUS OMAR</a></text>
<text top="249" left="170" width="4" height="15" font="2"><a href="HTTPS://ORCID.ORG/0000-0003-4502-7971">,</a></text>
<text top="251" left="177" width="158" height="13" font="3">University of Michigan, USA</text>
<text top="277" left="69" width="592" height="13" font="3">Large language models (LLMs) have reshaped the landscape of program synthesis. However, contemporary</text>
<text top="294" left="69" width="593" height="13" font="3">LLM-based code completion systems often hallucinate broken code because they lack appropriate code context,</text>
<text top="310" left="69" width="592" height="13" font="3">particularly when working with definitions that are neither in the training data nor near the cursor. This</text>
<text top="327" left="69" width="592" height="13" font="3">paper demonstrates that tighter integration with the type and binding structure of the programming language</text>
<text top="343" left="69" width="592" height="13" font="3">in use, as exposed by its language server, can help address this contextualization problem in a token-efficient</text>
<text top="359" left="69" width="592" height="13" font="3">manner. In short, we contend that AIs need IDEs, too! In particular, we integrate LLM code generation into</text>
<text top="376" left="69" width="592" height="13" font="3">the Hazel live program sketching environment. The Hazel Language Server is able to identify the type and</text>
<text top="392" left="69" width="592" height="13" font="3">typing context of the hole that the programmer is filling, with Hazel’s total syntax and type error correction</text>
<text top="409" left="69" width="592" height="13" font="3">ensuring that a meaningful program sketch is available whenever the developer requests a completion. This</text>
<text top="425" left="69" width="592" height="13" font="3">allows the system to prompt the LLM with codebase-wide contextual information that is not lexically local</text>
<text top="442" left="69" width="592" height="13" font="3">to the cursor, nor necessarily in the same file, but that is likely to be semantically local to the developer’s</text>
<text top="458" left="69" width="592" height="13" font="3">goal. Completions synthesized by the LLM are then iteratively refined via further dialog with the language</text>
<text top="475" left="69" width="592" height="13" font="3">server, which provides error localization and error messages. To evaluate these techniques, we introduce</text>
<text top="491" left="69" width="592" height="13" font="3">MVUBench, a dataset of model-view-update (MVU) web applications with accompanying unit tests that have</text>
<text top="507" left="69" width="592" height="13" font="3">been written from scratch to avoid data contamination, and that can easily be ported to new languages because</text>
<text top="524" left="69" width="592" height="13" font="3">they do not have large external library dependencies. These applications serve as challenge problems due to</text>
<text top="540" left="69" width="592" height="13" font="3">their extensive reliance on application-specific data structures. Through an ablation study, we examine the</text>
<text top="557" left="69" width="592" height="13" font="3">impact of contextualization with type definitions, function headers, and errors messages, individually and in</text>
<text top="573" left="69" width="592" height="13" font="3">combination. We find that contextualization with type definitions is particularly impactful. After introducing</text>
<text top="590" left="69" width="592" height="13" font="3">our ideas in the context of Hazel, a low-resource language, we duplicate our techniques and port MVUBench</text>
<text top="606" left="69" width="594" height="13" font="3">to TypeScript in order to validate the applicability of these methods to higher-resource mainstream languages.</text>
<text top="622" left="69" width="592" height="13" font="3">Finally, we outline ChatLSP, a conservative extension to the Language Server Protocol (LSP) that language</text>
<text top="639" left="69" width="592" height="13" font="3">servers can implement to expose capabilities that AI code completion systems of various designs can use to</text>
<text top="655" left="69" width="354" height="13" font="3">incorporate static context when generating prompts for an LLM.</text>
<text top="680" left="69" width="91" height="13" font="3">CCS Concepts: •</text>
<text top="680" left="164" width="178" height="13" font="4">Software and its engineering</text>
<text top="680" left="345" width="14" height="12" font="5">→</text>
<text top="680" left="363" width="221" height="13" font="4">Software creation and management</text>
<text top="680" left="583" width="12" height="13" font="3">; •</text>
<text top="680" left="598" width="62" height="13" font="4">Theory of</text>
<text top="696" left="69" width="78" height="13" font="4">computation</text>
<text top="696" left="150" width="14" height="12" font="5">→</text>
<text top="696" left="167" width="95" height="13" font="4">Type structures</text>
<text top="696" left="262" width="3" height="13" font="3">.</text>
<text top="721" left="68" width="530" height="13" font="3">Additional Key Words and Phrases: Large Language Models, Program Synthesis, Program Repair</text>
<text top="746" left="68" width="147" height="13" font="4">ACM Reference Format:</text>
<text top="762" left="68" width="592" height="13" font="3">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar. 2024. Statically Contextualizing Large Language</text>
<text top="779" left="69" width="150" height="13" font="3">Models with Typed Holes.</text>
<text top="779" left="223" width="148" height="13" font="6">Proc. ACM Program. Lang.</text>
<text top="779" left="375" width="230" height="13" font="3">8, OOPSLA2, Article 288 (October 2024),</text>
<text top="779" left="610" width="13" height="13" font="7"><a href="output.html#31">31</a></text>
<text top="779" left="628" width="35" height="13" font="3">pages.</text>
<text top="795" left="69" width="171" height="13" font="8"><a href="https://doi.org/10.1145/3689728">https://doi.org/10.1145/3689728</a></text>
<text top="825" left="69" width="150" height="11" font="9">Authors’ Contact Information:</text>
<text top="825" left="222" width="70" height="11" font="10"><a href="https://orcid.org/0000-0001-6938-7379">Andrew Blinn</a></text>
<text top="825" left="292" width="322" height="11" font="9"><a href="https://orcid.org/0000-0001-6938-7379">, </a>University of Michigan, Ann Arbor, USA, blinnand@umich.edu;</text>
<text top="825" left="617" width="42" height="11" font="10"><a href="https://orcid.org/0009-0005-6860-039X">Xiang Li</a></text>
<text top="825" left="659" width="3" height="11" font="9"><a href="https://orcid.org/0009-0005-6860-039X">,</a></text>
<text top="840" left="69" width="300" height="11" font="9">University of Michigan, Ann Arbor, USA, xkevli@umich.edu;</text>
<text top="840" left="371" width="82" height="11" font="10"><a href="https://orcid.org/0009-0005-0820-9532">June Hyung Kim</a></text>
<text top="840" left="454" width="208" height="11" font="9"><a href="https://orcid.org/0009-0005-0820-9532">, </a>University of Michigan, Ann Arbor, USA,</text>
<text top="855" left="69" width="89" height="11" font="9">jpoly@umich.edu;</text>
<text top="855" left="161" width="60" height="11" font="10"><a href="https://orcid.org/0000-0003-4502-7971">Cyrus Omar</a></text>
<text top="855" left="221" width="306" height="11" font="9"><a href="https://orcid.org/0000-0003-4502-7971">, </a>University of Michigan, Ann Arbor, USA, comar@umich.edu.</text>
<text top="946" left="68" width="229" height="11" font="9">© 2024 Copyright held by the owner/author(s).</text>
<text top="961" left="68" width="161" height="11" font="9">ACM 2475-1421/2024/10-ART288</text>
<text top="976" left="69" width="152" height="11" font="10"><a href="https://doi.org/10.1145/3689728">https://doi.org/10.1145/3689728</a></text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
<text top="928" left="69" width="424" height="11" font="11"><a href="https://creativecommons.org/licenses/by/4.0/">This work is licensed under a Creative Commons Attribution 4.0 International License.</a></text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="12" size="12" family="WVOPFG+LinBiolinumT" color="#000000"/>
	<fontspec id="13" size="13" family="WVOPFG+LinBiolinumT" color="#000000"/>
	<fontspec id="14" size="13" family="WVOPFG+LinBiolinumT" color="#721679"/>
	<fontspec id="15" size="15" family="GAQDOW+LinBiolinumTB" color="#000000"/>
	<fontspec id="16" size="15" family="JZXWNF+LinLibertineT" color="#000000"/>
	<fontspec id="17" size="15" family="JZXWNF+LinLibertineT" color="#721679"/>
	<fontspec id="18" size="15" family="BQBJUC+LinLibertineTI" color="#000000"/>
	<fontspec id="19" size="15" family="PFQUFB+LinLibertineTB" color="#000000"/>
	<fontspec id="20" size="13" family="DQFGLI+Inconsolatazi4" color="#7f7f7f"/>
	<fontspec id="21" size="13" family="VVWGZX+Inconsolatazi4" color="#000000"/>
	<fontspec id="22" size="13" family="DQFGLI+Inconsolatazi4" color="#000000"/>
<image top="127" left="69" width="592" height="273" src="output-2_1.png"/>
<text top="93" left="69" width="25" height="11" font="12">288:2</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="420" left="99" width="309" height="12" font="13">Fig. 1. Hazel Assistant Conversational Architecture (see</text>
<text top="420" left="411" width="49" height="12" font="14"><a href="output.html#26">section 9</a></text>
<text top="420" left="464" width="166" height="12" font="13">for image acknowledgements)</text>
<text top="485" left="69" width="8" height="14" font="15">1</text>
<text top="485" left="91" width="86" height="14" font="15">Introduction</text>
<text top="507" left="69" width="593" height="14" font="16">Recent advances in generative AI have triggered an avalanche of new AI programming assistants—</text>
<text top="525" left="69" width="192" height="14" font="16">the most prominent is Copilot <a href="output.html#27">[</a></text>
<text top="525" left="261" width="14" height="14" font="17"><a href="output.html#27">23</a></text>
<text top="525" left="275" width="385" height="14" font="16"><a href="output.html#27">], </a>but it has many competitors—that generate code completions</text>
<text top="543" left="69" width="592" height="14" font="16">by prompting a large language model (LLM) pre-trained on a corpus of diverse natural language</text>
<text top="561" left="69" width="436" height="14" font="16">documents as well as code written in various programming languages <a href="output.html#26">[</a></text>
<text top="561" left="505" width="7" height="14" font="17"><a href="output.html#26">7</a></text>
<text top="561" left="512" width="3" height="14" font="16"><a href="output.html#26">,</a></text>
<text top="561" left="519" width="14" height="14" font="17"><a href="output.html#27">17</a></text>
<text top="561" left="532" width="3" height="14" font="16"><a href="output.html#27">,</a></text>
<text top="561" left="540" width="14" height="14" font="17"><a href="output.html#27">17</a></text>
<text top="561" left="553" width="3" height="14" font="16"><a href="output.html#27">,</a></text>
<text top="561" left="560" width="14" height="14" font="17"><a href="output.html#29">49</a></text>
<text top="561" left="574" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="561" left="581" width="14" height="14" font="17"><a href="output.html#30">73</a></text>
<text top="561" left="595" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="561" left="602" width="14" height="14" font="17"><a href="output.html#30">78</a></text>
<text top="561" left="616" width="44" height="14" font="16"><a href="output.html#30">]. </a>Once</text>
<text top="579" left="69" width="448" height="14" font="16">trained, an LLM iteratively transforms an input token sequence, called the</text>
<text top="579" left="521" width="42" height="14" font="18">prompt</text>
<text top="579" left="563" width="31" height="14" font="16">, into</text>
<text top="579" left="598" width="62" height="14" font="18">next-token</text>
<text top="597" left="69" width="146" height="14" font="18">probability distributions</text>
<text top="597" left="220" width="73" height="14" font="16">from which</text>
<text top="597" left="297" width="71" height="14" font="18">completions</text>
<text top="597" left="373" width="287" height="14" font="16">are sampled. LLMs are able to learn statistical</text>
<text top="615" left="69" width="197" height="14" font="16">regularities in the training data <a href="output.html#28">[</a></text>
<text top="615" left="265" width="14" height="14" font="17"><a href="output.html#28">29</a></text>
<text top="615" left="279" width="381" height="14" font="16"><a href="output.html#28">], </a>with limited reasoning abilities emerging as LLMs scale up in</text>
<text top="633" left="69" width="32" height="14" font="16">size <a href="output.html#31">[</a></text>
<text top="633" left="100" width="14" height="14" font="17"><a href="output.html#31">89</a></text>
<text top="633" left="114" width="546" height="14" font="16"><a href="output.html#31">]. </a>As a result, AI assistants have become capable enough to substantially impact developer</text>
<text top="650" left="69" width="86" height="14" font="16">productivity <a href="output.html#26">[</a></text>
<text top="650" left="155" width="7" height="14" font="17"><a href="output.html#26">9</a></text>
<text top="650" left="162" width="3" height="14" font="16"><a href="output.html#26">,</a></text>
<text top="650" left="169" width="14" height="14" font="17"><a href="output.html#29">61</a></text>
<text top="650" left="183" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="650" left="190" width="14" height="14" font="17"><a href="output.html#30">74</a></text>
<text top="650" left="204" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="650" left="211" width="14" height="14" font="17"><a href="output.html#31">88</a></text>
<text top="650" left="225" width="435" height="14" font="16"><a href="output.html#31">]. </a>For example, one study reports a 50% increase in productivity when</text>
<text top="668" left="69" width="88" height="14" font="16">using Copilot <a href="output.html#31">[</a></text>
<text top="668" left="157" width="14" height="14" font="17"><a href="output.html#31">88</a></text>
<text top="668" left="171" width="410" height="14" font="16"><a href="output.html#31">]. </a>The impact is particularly pronounced for developers working with</text>
<text top="668" left="584" width="76" height="14" font="18">high resource</text>
<text top="686" left="69" width="438" height="14" font="16">libraries and languages, i.e. those well-represented in the training data <a href="output.html#30">[</a></text>
<text top="686" left="507" width="14" height="14" font="17"><a href="output.html#30">78</a></text>
<text top="686" left="521" width="9" height="14" font="16"><a href="output.html#30">].</a></text>
<text top="704" left="84" width="577" height="14" font="16">Contemporary AI assistants construct the prompt primarily using the program text appearing in</text>
<text top="722" left="69" width="322" height="14" font="16">a textual window around the developer’s cursor (the</text>
<text top="722" left="394" width="87" height="14" font="18">cursor window</text>
<text top="722" left="482" width="14" height="14" font="16">) <a href="output.html#30">[</a></text>
<text top="722" left="495" width="14" height="14" font="17"><a href="output.html#30">66</a></text>
<text top="722" left="509" width="151" height="14" font="16"><a href="output.html#30">]. </a>This approach leads to</text>
<text top="740" left="69" width="592" height="14" font="16">poor performance in situations where critical task-relevant context comes from definitions that</text>
<text top="758" left="69" width="402" height="14" font="16">appear neither in the cursor window nor in the training data (the</text>
<text top="758" left="475" width="185" height="14" font="19">semantic contextualization</text>
<text top="776" left="69" width="57" height="14" font="19">problem</text>
<text top="776" left="125" width="13" height="14" font="16">) <a href="output.html#26">[</a></text>
<text top="776" left="139" width="7" height="14" font="17"><a href="output.html#26">2</a></text>
<text top="776" left="146" width="3" height="14" font="16"><a href="output.html#26">,</a></text>
<text top="776" left="153" width="14" height="14" font="17"><a href="output.html#27">19</a></text>
<text top="776" left="167" width="3" height="14" font="16"><a href="output.html#27">,</a></text>
<text top="776" left="174" width="14" height="14" font="17"><a href="output.html#28">38</a></text>
<text top="776" left="188" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="776" left="195" width="14" height="14" font="17"><a href="output.html#29">60</a></text>
<text top="776" left="208" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="776" left="215" width="14" height="14" font="17"><a href="output.html#30">67</a></text>
<text top="776" left="229" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="776" left="236" width="14" height="14" font="17"><a href="output.html#30">77</a></text>
<text top="776" left="250" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="776" left="257" width="14" height="14" font="17"><a href="output.html#30">82</a></text>
<text top="776" left="271" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="776" left="278" width="14" height="14" font="17"><a href="output.html#30">83</a></text>
<text top="776" left="292" width="368" height="14" font="16"><a href="output.html#30">]. </a>For example, consider the following cursor window, which</text>
<text top="794" left="68" width="592" height="14" font="16">would arise when a developer is implementing a GUI component using the model-view-update</text>
<text top="812" left="68" width="485" height="14" font="16">(MVU) architecture (central to popular GUI application frameworks like React <a href="output.html#26">[</a></text>
<text top="812" left="553" width="7" height="14" font="17"><a href="output.html#26">8</a></text>
<text top="812" left="560" width="68" height="14" font="16"><a href="output.html#26">] </a>and Elm <a href="output.html#27">[</a></text>
<text top="812" left="629" width="14" height="14" font="17"><a href="output.html#27">18</a></text>
<text top="812" left="642" width="13" height="14" font="16"><a href="output.html#27">]):</a></text>
<text top="835" left="90" width="434" height="17" font="20">(* update the room booking data after a user action *)</text>
<text top="855" left="90" width="62" height="11" font="21"><b>f u n c t i o n</b></text>
<text top="851" left="163" width="361" height="17" font="22">update ( model : Model , action : Action ): Model {</text>
<text top="883" left="84" width="577" height="14" font="16">Correctly completing this function definition requires knowing the definitions of this specific</text>
<text top="901" left="69" width="79" height="14" font="16">component’s</text>
<text top="898" left="152" width="34" height="17" font="22">Model</text>
<text top="901" left="189" width="23" height="14" font="16">and</text>
<text top="898" left="216" width="40" height="17" font="22">Action</text>
<text top="901" left="260" width="401" height="14" font="16">types, which commonly appear in different files in the repository</text>
<text top="919" left="69" width="593" height="14" font="16">and therefore outside the cursor window. Various other files might also contain relevant definitions,</text>
<text top="937" left="69" width="367" height="14" font="16">e.g. other types that can be reached from the definitions of</text>
<text top="934" left="440" width="34" height="17" font="22">Model</text>
<text top="937" left="477" width="23" height="14" font="16">and</text>
<text top="934" left="504" width="40" height="17" font="22">Action</text>
<text top="937" left="545" width="116" height="14" font="16">, and useful helper</text>
<text top="955" left="69" width="592" height="14" font="16">functions for working with values of these types. Without access to these definitions, an LLM will</text>
<text top="972" left="69" width="592" height="14" font="16">either be unable to generate sufficiently probable completions (which may result in no completion</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="635" width="25" height="11" font="12">288:3</text>
<text top="131" left="69" width="592" height="14" font="16">being generated) or more typically it will hallucinate plausible-but-incorrect definitions based only</text>
<text top="149" left="69" width="166" height="14" font="16">on the provided comment <a href="output.html#30">[</a></text>
<text top="149" left="235" width="14" height="14" font="17"><a href="output.html#30">80</a></text>
<text top="149" left="249" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="149" left="256" width="14" height="14" font="17"><a href="output.html#31">85</a></text>
<text top="149" left="270" width="9" height="14" font="16"><a href="output.html#31">].</a></text>
<text top="167" left="84" width="577" height="14" font="16">To address this problem, assistant designers use various retrieval augmented generation (RAG)</text>
<text top="185" left="69" width="75" height="14" font="16">techniques <a href="output.html#27">[</a></text>
<text top="185" left="143" width="14" height="14" font="17"><a href="output.html#27">25</a></text>
<text top="185" left="157" width="503" height="14" font="16"><a href="output.html#27">] </a>to retrieve additional code from other files in the repository and external libraries</text>
<text top="203" left="69" width="592" height="14" font="16">for inclusion in the prompt. Real-world code bases often span hundreds of thousands of lines of</text>
<text top="221" left="69" width="592" height="14" font="16">code, so exhaustive retrieval quickly runs into scaling issues. While prompt (i.e. context) size limits</text>
<text top="239" left="69" width="134" height="14" font="16">continue to increase <a href="output.html#27">[</a></text>
<text top="239" left="203" width="14" height="14" font="17"><a href="output.html#27">21</a></text>
<text top="239" left="217" width="443" height="14" font="16"><a href="output.html#27">], </a>generation costs (measured in both time and energy) scale with token</text>
<text top="257" left="69" width="45" height="14" font="16">count <a href="output.html#28">[</a></text>
<text top="257" left="114" width="14" height="14" font="17"><a href="output.html#28">30</a></text>
<text top="257" left="128" width="533" height="14" font="16"><a href="output.html#28">]. </a>These costs are substantial (because LLMs typically have billions of parameters) so</text>
<text top="275" left="69" width="93" height="14" font="18">token efficiency</text>
<text top="275" left="166" width="160" height="14" font="16">remains a critical metric <a href="output.html#30">[</a></text>
<text top="275" left="326" width="14" height="14" font="17"><a href="output.html#30">66</a></text>
<text top="275" left="340" width="320" height="14" font="16"><a href="output.html#30">]. </a>Moreover, contemporary LLMs struggle to attend</text>
<text top="293" left="69" width="426" height="14" font="16">to relevant information and ignore irrelevant information (such as the</text>
<text top="291" left="499" width="34" height="17" font="22">Model</text>
<text top="293" left="536" width="22" height="14" font="16">and</text>
<text top="291" left="562" width="40" height="17" font="22">Action</text>
<text top="293" left="606" width="54" height="14" font="16">types for</text>
<text top="311" left="69" width="30" height="14" font="18">other</text>
<text top="311" left="104" width="221" height="14" font="16">GUI components) in large prompts <a href="output.html#28">[</a></text>
<text top="311" left="325" width="14" height="14" font="17"><a href="output.html#28">35</a></text>
<text top="311" left="339" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="311" left="346" width="14" height="14" font="17"><a href="output.html#28">37</a></text>
<text top="311" left="360" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="311" left="367" width="14" height="14" font="17"><a href="output.html#28">41</a></text>
<text top="311" left="381" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="311" left="388" width="14" height="14" font="17"><a href="output.html#30">79</a></text>
<text top="311" left="402" width="9" height="14" font="16"><a href="output.html#30">].</a></text>
<text top="329" left="84" width="579" height="14" font="16">Given these issues, assistant designers need retrieval techniques that prioritize task-relevant code.</text>
<text top="347" left="69" width="592" height="14" font="16">For example, Copilot retrieves code from locations in other files that the developer has recently</text>
<text top="365" left="68" width="444" height="14" font="16">visited, based on the heuristic that these are likely to be task-relevant <a href="output.html#30">[</a></text>
<text top="365" left="512" width="14" height="14" font="17"><a href="output.html#30">71</a></text>
<text top="365" left="526" width="134" height="14" font="16"><a href="output.html#30">]. </a>Another prominent</text>
<text top="383" left="69" width="267" height="14" font="16">retrieval strategy, which we will refer to as</text>
<text top="383" left="339" width="90" height="14" font="18">vector retrieval</text>
<text top="383" left="430" width="231" height="14" font="16">, involves performing a vector search</text>
<text top="400" left="69" width="592" height="14" font="16">across the repository (and perhaps beyond) to retrieve code similar to the code in the cursor</text>
<text top="418" left="68" width="59" height="14" font="16">window <a href="output.html#29">[</a></text>
<text top="418" left="127" width="14" height="14" font="17"><a href="output.html#29">44</a></text>
<text top="418" left="141" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="418" left="148" width="14" height="14" font="17"><a href="output.html#30">82</a></text>
<text top="418" left="162" width="3" height="14" font="16"><a href="output.html#30">,</a></text>
<text top="418" left="169" width="14" height="14" font="17"><a href="output.html#30">83</a></text>
<text top="418" left="183" width="324" height="14" font="16"><a href="output.html#30">], </a>as measured by a learned vector similarity metric <a href="output.html#28">[</a></text>
<text top="418" left="507" width="14" height="14" font="17"><a href="output.html#28">36</a></text>
<text top="418" left="521" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="418" left="528" width="14" height="14" font="17"><a href="output.html#29">49</a></text>
<text top="418" left="542" width="119" height="14" font="16"><a href="output.html#29">]. </a>This relies on the</text>
<text top="436" left="69" width="592" height="14" font="16">heuristic that lexically similar code is likely to be task-relevant code. In the example above, since</text>
<text top="454" left="69" width="94" height="14" font="16">the type names</text>
<text top="452" left="166" width="34" height="17" font="22">Model</text>
<text top="454" left="203" width="23" height="14" font="16">and</text>
<text top="452" left="230" width="40" height="17" font="22">Action</text>
<text top="454" left="274" width="327" height="14" font="16">appear explicitly in the cursor window, this approach</text>
<text top="454" left="605" width="27" height="14" font="18">may</text>
<text top="454" left="636" width="24" height="14" font="16">find</text>
<text top="472" left="69" width="528" height="14" font="16">their definitions. However, it may also find irrelevant definitions of other types named</text>
<text top="470" left="600" width="34" height="17" font="22">Model</text>
<text top="472" left="638" width="23" height="14" font="16">and</text>
<text top="488" left="68" width="40" height="17" font="22">Action</text>
<text top="490" left="112" width="177" height="14" font="16">and other implementations of</text>
<text top="488" left="293" width="40" height="17" font="22">update</text>
<text top="490" left="333" width="327" height="14" font="16">, e.g. those from other GUI components in this or other</text>
<text top="508" left="69" width="593" height="14" font="16">applications. It may also be less effective when the task-relevant definitions are not named explicitly,</text>
<text top="526" left="69" width="266" height="14" font="16">e.g. if the developer is later writing a call to</text>
<text top="524" left="339" width="40" height="17" font="22">update</text>
<text top="526" left="379" width="218" height="14" font="16">, the fact that the relevant types are</text>
<text top="524" left="600" width="34" height="17" font="22">Model</text>
<text top="526" left="638" width="23" height="14" font="16">and</text>
<text top="542" left="68" width="40" height="17" font="22">Action</text>
<text top="544" left="112" width="305" height="14" font="16">requires reasoning about the type signature of the</text>
<text top="542" left="422" width="40" height="17" font="22">update</text>
<text top="544" left="466" width="55" height="14" font="16">function.</text>
<text top="562" left="84" width="577" height="14" font="16">These retrieval approaches are language-agnostic, treating source code as a sequence of tokens</text>
<text top="580" left="69" width="592" height="14" font="16">like any other, so they must necessarily deploy imprecise heuristics. In this paper, we instead</text>
<text top="598" left="69" width="592" height="14" font="16">consider language-aware approaches that take advantage of the fact that in many languages, code</text>
<text top="616" left="69" width="527" height="14" font="16">is governed by a rich type and binding discipline determined by a static semantics <a href="output.html#28">[</a></text>
<text top="616" left="596" width="14" height="14" font="17"><a href="output.html#28">28</a></text>
<text top="616" left="610" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="616" left="617" width="14" height="14" font="17"><a href="output.html#29">62</a></text>
<text top="616" left="631" width="29" height="14" font="16"><a href="output.html#29">]. </a>To</text>
<text top="634" left="69" width="592" height="14" font="16">retrieve relevant semantic information and analyze candidate code completions, we rely on a</text>
<text top="652" left="69" width="152" height="14" font="16">modern language server <a href="output.html#27">[</a></text>
<text top="652" left="221" width="14" height="14" font="17"><a href="output.html#27">10</a></text>
<text top="652" left="235" width="3" height="14" font="16"><a href="output.html#27">,</a></text>
<text top="652" left="241" width="14" height="14" font="17"><a href="output.html#27">13</a></text>
<text top="652" left="255" width="116" height="14" font="16"><a href="output.html#27">] </a>to provide various</text>
<text top="652" left="375" width="101" height="14" font="18">language services</text>
<text top="652" left="475" width="185" height="14" font="16">, namely type reporting, typing</text>
<text top="669" left="69" width="592" height="14" font="16">context search, and error reporting. Integrated development environments (IDEs) interact with</text>
<text top="687" left="69" width="594" height="14" font="16">these services to drive various human-facing affordances such as type hints and hover messages.</text>
<text top="705" left="69" width="592" height="14" font="16">Here we investigate the hypothesis that LLM code completion can also benefit from interactions</text>
<text top="723" left="68" width="340" height="14" font="16">with language services. Put pithily, we hypothesize that</text>
<text top="723" left="412" width="106" height="14" font="18">AIs need IDEs, too</text>
<text top="723" left="519" width="3" height="14" font="16">.</text>
<text top="741" left="84" width="508" height="14" font="16">We investigate two language-aware approaches independently and in combination:</text>
<text top="786" left="84" width="91" height="14" font="18">Static Retrieval.</text>
<text top="786" left="180" width="194" height="14" font="16">The first approach we consider <a href="output.html#6">(</a></text>
<text top="786" left="374" width="53" height="14" font="17"><a href="output.html#6">section 2</a></text>
<text top="786" left="427" width="233" height="14" font="16"><a href="output.html#6">) </a>is static retrieval, where the language</text>
<text top="804" left="69" width="547" height="14" font="16">server is tasked to (1) determine the type and typing context of the “hole” (implicit in the</text>
<text top="802" left="620" width="40" height="17" font="22">update</text>
<text top="822" left="69" width="592" height="14" font="16">sketch above) at the cursor, and (2) transitively retrieve semantically relevant type definitions and</text>
<text top="840" left="69" width="490" height="14" font="16">function headers, from wherever they might appear, for inclusion in the prompt.</text>
<text top="858" left="84" width="35" height="14" font="16">In the</text>
<text top="855" left="122" width="40" height="17" font="22">update</text>
<text top="858" left="166" width="494" height="14" font="16">example, the hole that the language server inserts (either implicitly or explicitly) at</text>
<text top="876" left="69" width="121" height="14" font="16">the cursor is of type</text>
<text top="873" left="194" width="34" height="17" font="22">Model</text>
<text top="876" left="231" width="190" height="14" font="16">(because it is in the body of the</text>
<text top="873" left="424" width="40" height="17" font="22">update</text>
<text top="876" left="468" width="192" height="14" font="16">function, which has return type</text>
<text top="891" left="69" width="34" height="17" font="22">Model</text>
<text top="894" left="102" width="314" height="14" font="16">), and the local typing context includes the argument</text>
<text top="891" left="420" width="101" height="17" font="22">action : Action</text>
<text top="894" left="520" width="140" height="14" font="16">, so the language server</text>
<text top="912" left="69" width="204" height="14" font="16">can look up the definitions of the</text>
<text top="909" left="277" width="34" height="17" font="22">Model</text>
<text top="912" left="314" width="23" height="14" font="16">and</text>
<text top="909" left="341" width="40" height="17" font="22">Action</text>
<text top="912" left="385" width="275" height="14" font="16">types. These types might themselves refer to</text>
<text top="929" left="69" width="592" height="14" font="16">other types, so we can transitively continue type retrieval. We can also retrieve information about</text>
<text top="947" left="69" width="592" height="14" font="16">relevant helper functions in the typing context, e.g. those that operate on the types that have been</text>
<text top="965" left="69" width="327" height="14" font="16">looked up, continuing transitively up to a token limit.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="23" size="15" family="KMHYXY+LinBiolinumTI" color="#000000"/>
<text top="93" left="69" width="25" height="11" font="12">288:4</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="132" left="84" width="139" height="14" font="18">Static Error Correction.</text>
<text top="131" left="228" width="385" height="14" font="16">To further improve correctness, we combine static retrieval in</text>
<text top="131" left="617" width="46" height="14" font="17"><a href="output.html#13">subsec-</a></text>
<text top="149" left="69" width="48" height="14" font="17"><a href="output.html#13">tion 2.7</a></text>
<text top="149" left="121" width="419" height="14" font="16">with a straightforward syntactic and static error correction pass <a href="output.html#28">[</a></text>
<text top="149" left="541" width="14" height="14" font="17"><a href="output.html#28">33</a></text>
<text top="149" left="555" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="149" left="563" width="14" height="14" font="17"><a href="output.html#28">39</a></text>
<text top="149" left="577" width="83" height="14" font="16"><a href="output.html#28">]: </a>we ask the</text>
<text top="167" left="69" width="592" height="14" font="16">language server to localize and generate error messages for syntactic and static errors in the</text>
<text top="185" left="69" width="592" height="14" font="16">generated completion, then feed this information back into an instruction-tuned model, prompting</text>
<text top="203" left="69" width="575" height="14" font="16">it to correct these errors, potentially over multiple rounds (trading off latency for correctness).</text>
<text top="245" left="69" width="19" height="14" font="15">1.1</text>
<text top="245" left="103" width="144" height="14" font="15">Evaluation Overview</text>
<text top="268" left="69" width="27" height="14" font="23">1.1.1</text>
<text top="268" left="110" width="284" height="14" font="23">Programming Languages and Language Servers.</text>
<text top="268" left="400" width="260" height="14" font="16">The approaches that we investigate in this</text>
<text top="286" left="69" width="592" height="14" font="16">paper are in principle applicable to any programming language with a well-structured type and</text>
<text top="304" left="69" width="592" height="14" font="16">binding discipline. The more challenging requirement, which has limited the prior experiments in</text>
<text top="322" left="69" width="216" height="14" font="16">these directions (which we review in</text>
<text top="322" left="288" width="52" height="14" font="17"><a href="output.html#23">section 6</a></text>
<text top="322" left="340" width="322" height="14" font="16"><a href="output.html#23">), </a>is that we also need a rather capable language server.</text>
<text top="340" left="69" width="593" height="14" font="16">In particular, the language server must be capable of robust syntax error and type error recovery,</text>
<text top="357" left="69" width="453" height="14" font="16">producing a semantically meaningful program sketch (i.e. a program with</text>
<text top="358" left="525" width="30" height="14" font="18">holes</text>
<text top="357" left="555" width="105" height="14" font="16">) in any situation</text>
<text top="375" left="68" width="323" height="14" font="16">where the developer might request code completion <a href="output.html#29">[</a></text>
<text top="375" left="391" width="14" height="14" font="17"><a href="output.html#29">52</a></text>
<text top="375" left="405" width="256" height="14" font="16"><a href="output.html#29">]. </a>For instance, the example situation from</text>
<text top="393" left="69" width="100" height="14" font="16">the beginning of</text>
<text top="393" left="173" width="54" height="14" font="17"><a href="output.html#2">section 1</a></text>
<text top="393" left="231" width="430" height="14" font="16">are syntactically erroneous, because the developer has not yet closed a</text>
<text top="411" left="69" width="592" height="14" font="16">curly brace or parenthesis, so a standard compiler would simply report a syntax error and halt. In</text>
<text top="429" left="69" width="592" height="14" font="16">other cases, there may be localized type errors elsewhere in the program that would ideally not</text>
<text top="447" left="69" width="299" height="14" font="16">cause gaps in the availability of code completion.</text>
<text top="465" left="84" width="577" height="14" font="16">For this reason, we evaluate these ideas primarily by developing an AI programming assistant</text>
<text top="483" left="69" width="391" height="14" font="16">for Hazel, extending the Hazel Assistant with LLM support <a href="output.html#27">[</a></text>
<text top="483" left="459" width="14" height="14" font="17"><a href="output.html#27">12</a></text>
<text top="483" left="473" width="187" height="14" font="16"><a href="output.html#27">]. </a>Hazel is a typed functional</text>
<text top="501" left="69" width="592" height="14" font="16">programming environment designed specifically around typed holes, inserting them automatically</text>
<text top="519" left="69" width="232" height="14" font="16">to ensure total syntax error recovery <a href="output.html#29">[</a></text>
<text top="519" left="301" width="14" height="14" font="17"><a href="output.html#29">47</a></text>
<text top="519" left="315" width="194" height="14" font="16"><a href="output.html#29">] </a>and total type error recovery <a href="output.html#31">[</a></text>
<text top="519" left="509" width="14" height="14" font="17"><a href="output.html#31">87</a></text>
<text top="519" left="523" width="138" height="14" font="16"><a href="output.html#31">]. </a>Hazel is also capable</text>
<text top="537" left="69" width="222" height="14" font="16">of evaluating programs with holes <a href="output.html#29">[</a></text>
<text top="537" left="290" width="14" height="14" font="17"><a href="output.html#29">50</a></text>
<text top="537" left="304" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="537" left="311" width="14" height="14" font="17"><a href="output.html#30">81</a></text>
<text top="537" left="325" width="335" height="14" font="16"><a href="output.html#30">] </a>(including ‘non-empty’ holes inserted as membranes</text>
<text top="555" left="69" width="170" height="14" font="16">around marked type errors <a href="output.html#31">[</a></text>
<text top="555" left="239" width="14" height="14" font="17"><a href="output.html#31">87</a></text>
<text top="555" left="253" width="407" height="14" font="16"><a href="output.html#31">]), </a>which makes it possible to use unit testing to granularly evaluate</text>
<text top="573" left="69" width="592" height="14" font="16">the correctness of even locally ill-typed model outputs (rather than the more ad hoc methods that</text>
<text top="591" left="69" width="492" height="14" font="16">are common in the literature, like edit distance from a single canonical solution).</text>
<text top="609" left="84" width="577" height="14" font="16">The Hazel language is similar to Elm, OCaml, and other languages in the ML family, i.e. it is a</text>
<text top="626" left="69" width="592" height="14" font="16">pure typed functional language with support for algebraic datatypes and pattern matching. Unlike</text>
<text top="644" left="69" width="594" height="14" font="16">Elm and OCaml, contemporary LLMs have not been trained on a substantial body of Hazel code, i.e.</text>
<text top="662" left="69" width="59" height="14" font="16">Hazel is a</text>
<text top="662" left="132" width="132" height="14" font="18">low resource language</text>
<text top="662" left="264" width="399" height="14" font="16">. This presents both a challenge and an opportunity for research.</text>
<text top="680" left="68" width="592" height="14" font="16">We have found that when asked to write Hazel code, contemporary LLMs fail to follow Hazel’s</text>
<text top="698" left="69" width="594" height="14" font="16">syntax and semantics, often borrowing syntactic forms and library functions from OCaml and Elm.</text>
<text top="716" left="69" width="310" height="14" font="16">However, LLMs are capable of in-context learning <a href="output.html#27">[</a></text>
<text top="716" left="379" width="14" height="14" font="17"><a href="output.html#27">24</a></text>
<text top="716" left="393" width="3" height="14" font="16"><a href="output.html#27">,</a></text>
<text top="716" left="400" width="14" height="14" font="17"><a href="output.html#29">64</a></text>
<text top="716" left="414" width="247" height="14" font="16"><a href="output.html#29">], </a>suggesting that it is possible to include</text>
<text top="734" left="69" width="592" height="14" font="16">few-shot examples and instructions in the prompt to quickly teach contemporary LLMs about how</text>
<text top="752" left="69" width="592" height="14" font="16">Hazel differs from related higher resource languages. The error correction approach we investigate</text>
<text top="770" left="69" width="592" height="14" font="16">may also be of particular interest in preventing errors in this sort of low-resource setting, which is</text>
<text top="788" left="69" width="339" height="14" font="16">of considerable interest to the PL research community <a href="output.html#27">[</a></text>
<text top="788" left="408" width="14" height="14" font="17"><a href="output.html#27">15</a></text>
<text top="788" left="422" width="9" height="14" font="16"><a href="output.html#27">].</a></text>
<text top="806" left="84" width="577" height="14" font="16">To demonstrate that static retrieval is useful even for mainstream high resource languages, we</text>
<text top="824" left="69" width="318" height="14" font="16">also perform additional more limited experiments in</text>
<text top="824" left="390" width="54" height="14" font="17"><a href="output.html#19">section 3</a></text>
<text top="824" left="448" width="212" height="14" font="16">with TypeScript via the TypeScript</text>
<text top="842" left="69" width="411" height="14" font="16">Language Server, an instance of the Language Sever Protocol (LSP) <a href="output.html#27">[</a></text>
<text top="842" left="479" width="14" height="14" font="17"><a href="output.html#27">10</a></text>
<text top="842" left="493" width="167" height="14" font="16"><a href="output.html#27">]. </a>We find that the LSP does</text>
<text top="860" left="69" width="592" height="14" font="16">not provide simple, direct access to the sort of information that is necessary to implement static</text>
<text top="877" left="69" width="592" height="14" font="16">retrieval, so we propose a more direct interface as we introduce the various approaches throughout</text>
<text top="895" left="69" width="350" height="14" font="16">the paper, summarized as a prospective LSP extenstion in</text>
<text top="895" left="422" width="54" height="14" font="17"><a href="output.html#22">section 5</a></text>
<text top="895" left="476" width="3" height="14" font="16"><a href="output.html#22">.</a></text>
<text top="933" left="69" width="26" height="14" font="23">1.1.2</text>
<text top="933" left="110" width="35" height="14" font="23">Tasks.</text>
<text top="933" left="150" width="490" height="14" font="16">The most commonly reported LLM code completion benchmarks are HumanEval <a href="output.html#27">[</a></text>
<text top="933" left="640" width="14" height="14" font="17"><a href="output.html#27">17</a></text>
<text top="933" left="653" width="8" height="14" font="16"><a href="output.html#27">],</a></text>
<text top="951" left="69" width="60" height="14" font="16">EvalPlus <a href="output.html#28">[</a></text>
<text top="951" left="129" width="14" height="14" font="17"><a href="output.html#28">40</a></text>
<text top="951" left="143" width="57" height="14" font="16"><a href="output.html#28">], </a>MBPP <a href="output.html#26">[</a></text>
<text top="951" left="199" width="7" height="14" font="17"><a href="output.html#26">7</a></text>
<text top="951" left="206" width="139" height="14" font="16"><a href="output.html#26">], </a>and LiveCodeBench <a href="output.html#28">[</a></text>
<text top="951" left="345" width="14" height="14" font="17"><a href="output.html#28">32</a></text>
<text top="951" left="359" width="301" height="14" font="16"><a href="output.html#28">]. </a>These are unsuitable for evaluating the proposed</text>
<text top="969" left="69" width="592" height="14" font="16">approaches because they consist of single-file tasks (constructed either manually, or derived from</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="635" width="25" height="11" font="12">288:5</text>
<text top="131" left="69" width="592" height="14" font="16">public repositories or programming contests) that are low-context, i.e. they require only builtin or</text>
<text top="149" left="69" width="555" height="14" font="16">standard datatypes, and therefore do not highlight the semantic contextualization problem.</text>
<text top="167" left="84" width="95" height="14" font="18">Repository-level</text>
<text top="167" left="183" width="173" height="14" font="16">benchmarks like RepoEval <a href="output.html#30">[</a></text>
<text top="167" left="356" width="14" height="14" font="17"><a href="output.html#30">83</a></text>
<text top="167" left="370" width="91" height="14" font="16"><a href="output.html#30">], </a>RepoBench <a href="output.html#28">[</a></text>
<text top="167" left="461" width="14" height="14" font="17"><a href="output.html#28">42</a></text>
<text top="167" left="475" width="115" height="14" font="16"><a href="output.html#28">], </a>CrossCodeEval <a href="output.html#27">[</a></text>
<text top="167" left="590" width="14" height="14" font="17"><a href="output.html#27">20</a></text>
<text top="167" left="604" width="58" height="14" font="16"><a href="output.html#27">], </a>the Co-</text>
<text top="185" left="69" width="101" height="14" font="16">CoMIC dataset <a href="output.html#27">[</a></text>
<text top="185" left="170" width="14" height="14" font="17"><a href="output.html#27">19</a></text>
<text top="185" left="184" width="102" height="14" font="16"><a href="output.html#27">], </a>and defects4j <a href="output.html#28">[</a></text>
<text top="185" left="286" width="14" height="14" font="17"><a href="output.html#28">34</a></text>
<text top="185" left="300" width="361" height="14" font="16"><a href="output.html#28">] </a>are more suitable because they are high-context, i.e. they</text>
<text top="203" left="69" width="592" height="14" font="16">require completing code that depends on definitions in different files. However, these benchmarks</text>
<text top="221" left="69" width="144" height="14" font="16">also present difficulties:</text>
<text top="243" left="84" width="16" height="14" font="16">(1)</text>
<text top="243" left="105" width="141" height="14" font="19">Data Contamination</text>
<text top="243" left="247" width="414" height="14" font="16">: LLMs are known to be able to memorize code that they have seen</text>
<text top="261" left="105" width="555" height="14" font="16">during training, and evidence suggests that this data contamination issue has indeed caused</text>
<text top="279" left="105" width="356" height="14" font="16">public models to be overfitted to publicly available code <a href="output.html#28">[</a></text>
<text top="279" left="462" width="14" height="14" font="17"><a href="output.html#28">32</a></text>
<text top="279" left="475" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="279" left="483" width="14" height="14" font="17"><a href="output.html#30">65</a></text>
<text top="279" left="497" width="164" height="14" font="16"><a href="output.html#30">]. </a>All of these benchmarks</text>
<text top="297" left="105" width="555" height="14" font="16">source examples from GitHub or PyPI. Based on reported cut-off dates, the projects in these</text>
<text top="315" left="105" width="555" height="14" font="16">benchmarks will have by now likely been incorporated into the training of contemporary</text>
<text top="333" left="105" width="538" height="14" font="16">models (noting that with few exceptions discussed below, training data is not disclosed).</text>
<text top="351" left="84" width="16" height="14" font="16">(2)</text>
<text top="350" left="105" width="147" height="14" font="19">Language Exclusivity</text>
<text top="351" left="252" width="408" height="14" font="16">: None of these include Hazel code, nor is it easy to manually port</text>
<text top="369" left="105" width="555" height="14" font="16">arbitrary projects taken from GitHub or PyPI that depend on various complex libraries to</text>
<text top="386" left="105" width="557" height="14" font="16">Hazel or any other low resource language of interest to the community. Existing porting tech-</text>
<text top="404" left="105" width="306" height="14" font="16">niques have only generated low-context datasets <a href="output.html#27">[</a></text>
<text top="404" left="412" width="14" height="14" font="17"><a href="output.html#27">15</a></text>
<text top="404" left="426" width="235" height="14" font="16"><a href="output.html#27">]. </a>In addition, RepoEval and CoCoMIC</text>
<text top="422" left="105" width="431" height="14" font="16">exclusively feature Python code, which is difficult to statically analyze.</text>
<text top="440" left="84" width="16" height="14" font="16">(3)</text>
<text top="440" left="105" width="90" height="14" font="19">Missing Tests</text>
<text top="440" left="196" width="465" height="14" font="16">: None of the tasks in these benchmarks include unit tests, which means that</text>
<text top="458" left="105" width="555" height="14" font="16">we can only evaluate correctness based on brittle textual similarity metrics. We observe that</text>
<text top="476" left="105" width="555" height="14" font="16">models often produce correct output with substantial syntactic variation, similar to human</text>
<text top="494" left="105" width="91" height="14" font="16">programmers <a href="output.html#27">[</a></text>
<text top="494" left="197" width="14" height="14" font="17"><a href="output.html#27">27</a></text>
<text top="494" left="211" width="9" height="14" font="16"><a href="output.html#27">].</a></text>
<text top="516" left="84" width="508" height="14" font="16">For these reasons, we construct a repository-level benchmark suite, MVUBench, in</text>
<text top="516" left="596" width="67" height="14" font="17"><a href="output.html#14">subsubsec-</a></text>
<text top="534" left="69" width="58" height="14" font="17"><a href="output.html#14">tion 2.8.1</a></text>
<text top="534" left="126" width="534" height="14" font="16"><a href="output.html#14">, </a>that consists of various MVU web applications. Web application development is an</text>
<text top="552" left="69" width="594" height="14" font="16">important and under-studied application domain. Many visions for the future imagine LLMs gener-</text>
<text top="570" left="69" width="459" height="14" font="16">ating complete application logic, not just solving code competition problems <a href="output.html#30">[</a></text>
<text top="570" left="528" width="14" height="14" font="17"><a href="output.html#30">75</a></text>
<text top="570" left="542" width="119" height="14" font="16"><a href="output.html#30">]. </a>MVU applications</text>
<text top="588" left="69" width="592" height="14" font="16">are high-context in that they typically define a number of different datatypes which by convention</text>
<text top="606" left="69" width="526" height="14" font="16">are often located in separate files. Some of these datatypes have generic names, like</text>
<text top="603" left="599" width="34" height="17" font="22">Model</text>
<text top="606" left="637" width="23" height="14" font="16">and</text>
<text top="621" left="68" width="40" height="17" font="22">Action</text>
<text top="624" left="109" width="553" height="14" font="16">, and a single application might have multiple such types, one for each GUI component,</text>
<text top="641" left="69" width="592" height="14" font="16">presenting a significant challenge to language-agnostic techniques that do not understand binding</text>
<text top="659" left="69" width="592" height="14" font="16">structure. Indeed, it is easy to construct particularly challenging yet realistic examples simply by</text>
<text top="677" left="69" width="425" height="14" font="16">combining multiple components of MVUBench, as we demonstrate in</text>
<text top="677" left="497" width="117" height="14" font="17"><a href="output.html#15">subsubsection 2.8.5</a></text>
<text top="677" left="614" width="3" height="14" font="16"><a href="output.html#15">.</a></text>
<text top="695" left="84" width="577" height="14" font="16">We address the data contamination problem following the approach taken by HumanEval, by</text>
<text top="713" left="69" width="592" height="14" font="16">conceptualizing and implementing these applications from scratch, without directly adapting any</text>
<text top="731" left="69" width="592" height="14" font="16">code from GitHub. We will control the release of these benchmarks to limit the likelihood of future</text>
<text top="749" left="69" width="100" height="14" font="16">contamination <a href="output.html#28">[</a></text>
<text top="749" left="169" width="14" height="14" font="17"><a href="output.html#28">31</a></text>
<text top="749" left="183" width="477" height="14" font="16"><a href="output.html#28">]. </a>We address the language exclusivity problem by ensuring that these MVU</text>
<text top="767" left="69" width="592" height="14" font="16">applications do not have any external library dependencies, so it is easy to port them to languages</text>
<text top="785" left="69" width="592" height="14" font="16">beyond Hazel and TypeScript, notably including pure functional languages. New MVU examples are</text>
<text top="803" left="69" width="592" height="14" font="16">also easy to develop and add to the benchmark, because they can implement the logic of essentially</text>
<text top="821" left="69" width="592" height="14" font="16">any front-end web application or GUI component. Finally, the lack of side effects also makes it easy</text>
<text top="839" left="69" width="228" height="14" font="16">to unit test the core application logic.</text>
<text top="866" left="69" width="27" height="14" font="23">1.1.3</text>
<text top="866" left="111" width="37" height="14" font="23">LLMs.</text>
<text top="866" left="153" width="510" height="14" font="16">We selected two pre-trained language models with which to perform experiments.</text>
<text top="884" left="69" width="258" height="14" font="16">First, we selected OpenAI’s GPT-4(-0613) <a href="output.html#26">[</a></text>
<text top="884" left="327" width="7" height="14" font="17"><a href="output.html#26">1</a></text>
<text top="884" left="334" width="327" height="14" font="16"><a href="output.html#26">], </a>which is currently consistently at or near the top of</text>
<text top="902" left="69" width="592" height="14" font="16">code completion benchmarks, to evaluate whether even the most capable contemporary foundation</text>
<text top="920" left="69" width="592" height="14" font="16">models (i.e. models so large that only large organizations like OpenAI have the resources to train</text>
<text top="938" left="69" width="361" height="14" font="16">and deploy them) benefit from the approaches we consider.</text>
<text top="956" left="84" width="577" height="14" font="16">GPT-4 is a closed model and many of its specific details, including its size and training, have</text>
<text top="974" left="69" width="593" height="14" font="16">not been publicly disclosed. This presents a significant challenge to reproducibility. Consequently,</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="24" size="13" family="DQFGLI+Inconsolatazi4" color="#804cf5"/>
<image top="563" left="77" width="574" height="208" src="output-6_1.png"/>
<text top="93" left="69" width="25" height="11" font="12">288:6</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="131" left="68" width="592" height="14" font="16">we also conduct experiments using StarCoder2-15B, the most capable fully open-source model</text>
<text top="149" left="69" width="488" height="14" font="16">responsibly trained on a fully open code corpus, The Stack v2, as of this writing <a href="output.html#28">[</a></text>
<text top="149" left="557" width="14" height="14" font="17"><a href="output.html#28">43</a></text>
<text top="149" left="571" width="89" height="14" font="16"><a href="output.html#28">]. </a>The Stack v2</text>
<text top="167" left="69" width="592" height="14" font="16">has notably extensive coverage of low resource languages. StarCoder2-15B is small enough to run</text>
<text top="185" left="69" width="582" height="14" font="16">locally on sufficiently powerful workstations, so our results should be reproducible indefinitely.</text>
<text top="203" left="84" width="579" height="14" font="16">GPT-4 is an instruction-tuned model, so we are able to use it to evaluate static error correction.</text>
<text top="221" left="69" width="594" height="14" font="16">StarCoder2-15B is completion-tuned, meaning it is not designed to receive and respond to instruc-</text>
<text top="239" left="69" width="592" height="14" font="16">tions. We are not aware of a comparably powerful fully open source code-specialize model that is</text>
<text top="257" left="69" width="590" height="14" font="16">instruction-tuned as of this writing, so we do not evaluate error correction with StarCoder2-15B.</text>
<text top="290" left="69" width="8" height="14" font="15">2</text>
<text top="290" left="91" width="400" height="14" font="15">Static Retrieval and Error Correction in the Hazel Assistant</text>
<text top="312" left="68" width="595" height="14" font="16">We first introduce Hazel and the Hazel Assistant by example from the developer’s perspective.</text>
<text top="330" left="68" width="592" height="14" font="16">We continue by describing how the Hazel Assistant prompts GPT-4 and interfaces with the Hazel</text>
<text top="348" left="69" width="594" height="14" font="16">Language Server to generate code completions augmented with static retrieval and error correction.</text>
<text top="366" left="68" width="592" height="14" font="16">Then, we introduce the MVUBench benchmark suite and report the results of an ablation study of</text>
<text top="384" left="69" width="592" height="14" font="16">each of these features. We investigate their relative contributions to the overall performance of the</text>
<text top="401" left="69" width="592" height="14" font="16">assistant on these high-context MVU tasks, relative to various baselines that establish bounds on</text>
<text top="419" left="69" width="81" height="14" font="16">performance.</text>
<text top="452" left="69" width="19" height="14" font="15">2.1</text>
<text top="452" left="103" width="38" height="14" font="15">Hazel</text>
<text top="474" left="69" width="592" height="14" font="16">Hazel is a web-based live functional programming environment that features total syntax and type</text>
<text top="492" left="69" width="267" height="14" font="16">error recovery via automatic hole insertion <a href="output.html#29">[</a></text>
<text top="492" left="335" width="14" height="14" font="17"><a href="output.html#29">47</a></text>
<text top="492" left="349" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="492" left="356" width="14" height="14" font="17"><a href="output.html#31">87</a></text>
<text top="492" left="370" width="290" height="14" font="16"><a href="output.html#31">]. </a>This ensures that every editor state in Hazel is</text>
<text top="510" left="69" width="592" height="14" font="16">a semantically meaningful program sketch and that Hazel’s various editor services, include code</text>
<text top="528" left="69" width="283" height="14" font="16">completion, never experience gaps in service <a href="output.html#29">[</a></text>
<text top="528" left="351" width="14" height="14" font="17"><a href="output.html#29">52</a></text>
<text top="528" left="365" width="9" height="14" font="16"><a href="output.html#29">].</a></text>
<text top="791" left="305" width="119" height="12" font="13">Fig. 2. The Hazel IDE</text>
<text top="830" left="84" width="577" height="14" font="16">As a running example, consider a scenario where the developer is implementing EmojiPaint, a</text>
<text top="848" left="69" width="593" height="14" font="16">simplified MVU app where a user chooses an emoji from a palette and paints designs by ‘stamping’</text>
<text top="866" left="69" width="76" height="14" font="16">it on a grid.</text>
<text top="866" left="150" width="52" height="14" font="17"><a href="output.html#6">Figure 2</a></text>
<text top="866" left="207" width="263" height="14" font="16">shows the user editing the file where the</text>
<text top="864" left="475" width="40" height="17" font="22">update</text>
<text top="866" left="520" width="140" height="14" font="16">function is defined. In</text>
<text top="884" left="69" width="49" height="14" font="17"><a href="output.html#6">Figure 2</a></text>
<text top="884" left="121" width="539" height="14" font="16">the developer’s cursor is shown as a red convex triangle to the right of a hole, represented</text>
<text top="902" left="69" width="592" height="14" font="16">as a convex hexagon. The Hazel IDE interfaces with the Hazel Language Server to report static</text>
<text top="920" left="69" width="592" height="14" font="16">information which both user and model can use to inform completions. The bottom bar, called the</text>
<text top="938" left="69" width="593" height="14" font="16">Cursor Inspector, reports information on the syntax as well the expected type of the expression,</text>
<text top="956" left="69" width="241" height="14" font="16">here a typed hole of the function type</text>
<text top="954" left="314" width="161" height="17" font="24">(Model, Action) -&gt; Model</text>
<text top="956" left="476" width="185" height="14" font="16">, at the cursor. The lower left</text>
<text top="974" left="69" width="467" height="14" font="16">popup, called the Context Inspector, reports the typing context at the cursor.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="25" size="13" family="DQFGLI+Inconsolatazi4" color="#17a0dd"/>
<image top="235" left="69" width="592" height="226" src="output-7_1.png"/>
<image top="707" left="120" width="489" height="121" src="output-7_2.png"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="635" width="25" height="11" font="12">288:7</text>
<text top="131" left="84" width="23" height="14" font="16">The</text>
<text top="129" left="110" width="40" height="17" font="25">update</text>
<text top="131" left="154" width="507" height="14" font="16">function is intended to respond to EmojiPaint user actions in the GUI, represented by</text>
<text top="149" left="68" width="84" height="14" font="16">values of type</text>
<text top="147" left="156" width="40" height="17" font="24">Action</text>
<text top="149" left="196" width="398" height="14" font="16">, transforming the current GUI state, represented by values of type</text>
<text top="147" left="597" width="34" height="17" font="24">Model</text>
<text top="149" left="631" width="29" height="14" font="16">, to a</text>
<text top="167" left="69" width="164" height="14" font="16">new GUI state, also of type</text>
<text top="165" left="236" width="34" height="17" font="24">Model</text>
<text top="167" left="270" width="391" height="14" font="16">. These types and associated helper functions appear in different</text>
<text top="185" left="69" width="108" height="14" font="16">files, excerpted in</text>
<text top="185" left="181" width="50" height="14" font="17"><a href="output.html#7">Figure 3</a></text>
<text top="185" left="231" width="430" height="14" font="16"><a href="output.html#7">(</a>a-b). Algebraic datatypes (i.e. recursive sum types) are represented in</text>
<text top="203" left="69" width="212" height="14" font="16">Hazel as constructors separated by</text>
<text top="201" left="285" width="7" height="17" font="24">+</text>
<text top="203" left="295" width="73" height="14" font="16">(rather than</text>
<text top="201" left="372" width="7" height="17" font="24">|</text>
<text top="203" left="382" width="203" height="14" font="16">in similar languages like OCaml).</text>
<text top="481" left="69" width="592" height="12" font="13">Fig. 3. (a) The types relevant to the EmojiPainter MVU app. (b) An excerpt of already-implemented functions</text>
<text top="498" left="69" width="592" height="12" font="13">in another file (with definitions collapsed by Hazel’s outliner). (c) The stubbed function header, where the</text>
<text top="514" left="69" width="297" height="12" font="13">developer has requested LLM completion by inserting</text>
<text top="510" left="372" width="13" height="17" font="22">??</text>
<text top="514" left="391" width="62" height="12" font="13">in the hole.</text>
<text top="564" left="69" width="19" height="14" font="15">2.2</text>
<text top="564" left="103" width="103" height="14" font="15">Hazel Assistant</text>
<text top="586" left="68" width="594" height="14" font="16">The Hazel Assistant is a programming assistant that generates code completions by two mechanisms.</text>
<text top="604" left="68" width="571" height="14" font="16">To provide fast, local completions, the Hazel Assistant generates type-directed completions <a href="output.html#27">[</a></text>
<text top="604" left="639" width="14" height="14" font="17"><a href="output.html#27">12</a></text>
<text top="604" left="653" width="9" height="14" font="16"><a href="output.html#27">],</a></text>
<text top="622" left="69" width="592" height="14" font="16">using localized syntactic and static information to inform small completions with type-directed</text>
<text top="640" left="69" width="135" height="14" font="16">lookahead as shown in</text>
<text top="640" left="207" width="48" height="14" font="17"><a href="output.html#7">Figure 4</a></text>
<text top="640" left="256" width="405" height="14" font="16"><a href="output.html#7">(</a>a-b). This feature can be invoked even when there are syntax errors</text>
<text top="658" left="69" width="448" height="14" font="16">because Hazel tracks syntactic obligations in a backpack, e.g. as shown in</text>
<text top="658" left="521" width="50" height="14" font="17"><a href="output.html#7">Figure 4</a></text>
<text top="658" left="570" width="90" height="14" font="16"><a href="output.html#7">(</a>b) where both</text>
<text top="673" left="71" width="13" height="17" font="22">=&gt;</text>
<text top="676" left="90" width="22" height="14" font="16">and</text>
<text top="677" left="119" width="20" height="11" font="21"><b>end</b></text>
<text top="676" left="145" width="288" height="14" font="16">are necessary to complete the case expression <a href="output.html#29">[</a></text>
<text top="676" left="433" width="14" height="14" font="17"><a href="output.html#29">47</a></text>
<text top="676" left="447" width="9" height="14" font="16"><a href="output.html#29">].</a></text>
<text top="849" left="127" width="475" height="12" font="13">Fig. 4. The Hazel Assistant defaults to providing only type-directed token completion.</text>
<text top="885" left="84" width="577" height="14" font="16">To request an LLM completion from the Hazel Assistant, the developer can fill any expression</text>
<text top="903" left="69" width="59" height="14" font="16">hole with</text>
<text top="900" left="134" width="13" height="17" font="22">??</text>
<text top="903" left="154" width="246" height="14" font="16">which starts to animate as suggested in</text>
<text top="903" left="404" width="51" height="14" font="17"><a href="output.html#7">Figure 3</a></text>
<text top="903" left="455" width="206" height="14" font="16"><a href="output.html#7">(</a>c). GPT-4, our underlying model</text>
<text top="921" left="69" width="592" height="14" font="16">in this section, is not particularly fast as of this writing, so the developer can continue to edit</text>
<text top="938" left="69" width="475" height="14" font="16">elsewhere while waiting for GPT-4 to return a completion. For this example,</text>
<text top="938" left="548" width="51" height="14" font="17"><a href="output.html#8">Figure 5</a></text>
<text top="938" left="602" width="58" height="14" font="16">shows an</text>
<text top="956" left="69" width="592" height="14" font="16">example of a GPT-4-generated completion. The developer can inspect this completion (which would</text>
<text top="974" left="69" width="321" height="14" font="16">display any type errors found) and accept it with the</text>
<text top="972" left="394" width="20" height="17" font="22">Tab</text>
<text top="974" left="418" width="24" height="14" font="16">key.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="26" size="15" family="NVCMIJ+txsys" color="#000000"/>
	<fontspec id="27" size="13" family="DQFGLI+Inconsolatazi4" color="#8d8600"/>
<image top="127" left="109" width="510" height="180" src="output-8_1.png"/>
<text top="93" left="69" width="25" height="11" font="12">288:8</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="327" left="69" width="593" height="12" font="13">Fig. 5. The Hazel LLM Assistant, combining static information with generative creation via language models,</text>
<text top="343" left="69" width="281" height="12" font="13">is capable of offering more substantial completions</text>
<text top="396" left="69" width="19" height="14" font="15">2.3</text>
<text top="396" left="103" width="202" height="14" font="15">The Hazel Assistant Trialogue</text>
<text top="419" left="69" width="593" height="14" font="16">Our generative hole filling process consists of the following steps, construed here as a ‘trialogue’</text>
<text top="436" left="69" width="541" height="14" font="16">between programmer, the Hazel Language Server, and a language model. This is depicted in</text>
<text top="436" left="613" width="48" height="14" font="17"><a href="output.html#2">Figure 1</a></text>
<text top="454" left="69" width="592" height="14" font="16">as a series of chat messages. In our setup, the primary interaction is between the language model</text>
<text top="472" left="69" width="592" height="14" font="16">and the Hazel Language Server, which acts on behalf of the user in response to a request for LLM</text>
<text top="490" left="69" width="592" height="14" font="16">hole filling, kicking off the following exchange. Here we use the messaging terminology from the</text>
<text top="508" left="69" width="117" height="14" font="16">OpenAI Chat API <a href="output.html#29">[</a></text>
<text top="508" left="185" width="14" height="14" font="17"><a href="output.html#29">54</a></text>
<text top="508" left="199" width="352" height="14" font="16"><a href="output.html#29">], </a>which distinguishes System, User, and Model messages:</text>
<text top="532" left="84" width="16" height="14" font="16">(1)</text>
<text top="532" left="105" width="95" height="14" font="18">System Message</text>
<text top="532" left="200" width="273" height="14" font="16">: Hazel Crash Course and few-shot examples</text>
<text top="550" left="84" width="16" height="14" font="16">(2)</text>
<text top="550" left="105" width="79" height="14" font="18">User Message</text>
<text top="550" left="184" width="285" height="14" font="16">: Program sketch augmented by static retrieval</text>
<text top="568" left="105" width="343" height="14" font="16">(i.e. relevant semantic context from the language server)</text>
<text top="586" left="84" width="16" height="14" font="16">(3)</text>
<text top="586" left="105" width="89" height="14" font="18">Model Message</text>
<text top="586" left="194" width="139" height="14" font="16">: Suggested hole filling</text>
<text top="604" left="84" width="16" height="14" font="16">(4)</text>
<text top="604" left="105" width="79" height="14" font="18">User Message</text>
<text top="604" left="184" width="300" height="14" font="16">: Syntax and type errors in the completion, if any</text>
<text top="622" left="84" width="16" height="14" font="16">(5)</text>
<text top="622" left="105" width="89" height="14" font="18">Model Message</text>
<text top="622" left="194" width="230" height="14" font="16">: A corrected completion, if necessary</text>
<text top="646" left="84" width="577" height="14" font="16">We repeat steps 4-5, i.e. we perform syntactic and static error correction when needed, stopping</text>
<text top="664" left="69" width="265" height="14" font="16">after at most two iterations to limit latency.</text>
<text top="699" left="69" width="19" height="14" font="15">2.4</text>
<text top="699" left="103" width="281" height="14" font="15">System Message: The Hazel Crash Course</text>
<text top="721" left="68" width="594" height="14" font="16">The system message is generic, common to each prompt. For an instruction-tuned model (GPT-4),</text>
<text top="739" left="69" width="280" height="14" font="16">the system message consists of three sections:</text>
<text top="757" left="84" width="577" height="14" font="16">First, we provide a list of instructions delineating the task. In particular, we instruct the model to</text>
<text top="775" left="69" width="592" height="14" font="16">provide a code fragment to replace a sentinel value representing the target hole in the program</text>
<text top="793" left="69" width="343" height="14" font="16">sketch. For example, the model is given the instructions:</text>
<text top="817" left="92" width="7" height="13" font="26">•</text>
<text top="815" left="105" width="148" height="17" font="27">&#34;Reply only with code&#34;</text>
<text top="835" left="92" width="7" height="13" font="26">•</text>
<text top="833" left="105" width="330" height="17" font="27">&#34;DO NOT include the program sketch in your reply&#34;</text>
<text top="859" left="84" width="578" height="14" font="16">Second, an informal specification of Hazel syntax with emphasis on ‘negative characterization’,</text>
<text top="877" left="69" width="592" height="14" font="16">listing differences from syntactically-similar higher-resource languages. As this kind of ‘prompt</text>
<text top="895" left="69" width="593" height="14" font="16">engineering’ is as-yet a task-sensitive and inexact process, this section, along with the one above,</text>
<text top="913" left="68" width="594" height="14" font="16">was constructed though an ad-hoc process of discovering repeated syntactic errors in model output.</text>
<text top="931" left="69" width="79" height="14" font="16">For example:</text>
<text top="955" left="92" width="7" height="13" font="26">•</text>
<text top="953" left="105" width="484" height="17" font="27">&#34;No 'rec' keyword is necessary for 'let' to define a recursive function&#34;</text>
<text top="973" left="92" width="7" height="13" font="26">•</text>
<text top="971" left="105" width="457" height="17" font="27">&#34;There is no dot accessor notation for tuples; use pattern matching&#34;</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="1080" width="729">
<image top="477" left="69" width="591" height="330" src="output-9_1.png"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="635" width="25" height="11" font="12">288:9</text>
<text top="131" left="84" width="577" height="14" font="16">Finally, we positively characterise hazel syntax via a fixed list of input/output pairs of sketches</text>
<text top="149" left="69" width="479" height="14" font="16">and program completions (few-shot prompting). We show one example below:</text>
<text top="173" left="92" width="7" height="13" font="26">•</text>
<text top="173" left="105" width="45" height="14" font="19">Sketch</text>
<text top="198" left="111" width="22" height="11" font="21"><b>let</b></text>
<text top="194" left="143" width="305" height="17" font="22">List. length : [( String , Bool )] -&gt; Int =</text>
<text top="214" left="127" width="22" height="11" font="21"><b>fun</b></text>
<text top="210" left="159" width="63" height="17" font="22">xs -&gt; ??</text>
<text top="214" left="232" width="47" height="11" font="21"><b>end in</b></text>
<text top="240" left="92" width="7" height="13" font="26">•</text>
<text top="240" left="105" width="81" height="14" font="19">Completion</text>
<text top="265" left="111" width="30" height="11" font="21"><b>case</b></text>
<text top="262" left="151" width="14" height="17" font="22">xs</text>
<text top="278" left="110" width="71" height="17" font="22">| [] =&gt; 0</text>
<text top="295" left="110" width="241" height="17" font="22">| _:: xs =&gt; 1 + List. length (xs)</text>
<text top="315" left="111" width="22" height="11" font="21"><b>end</b></text>
<text top="347" left="84" width="577" height="14" font="16">For the smaller completion model (StarCoder2-15B) discussed below, which has a longer context</text>
<text top="364" left="68" width="594" height="14" font="16">window (16k versus 8k for GPT-4-0613) but is not instruction-tuned, we omit the first two sections,</text>
<text top="382" left="69" width="592" height="14" font="16">in lieu of providing a longer list of syntax examples, which are provided simply as a list of definitions</text>
<text top="400" left="69" width="188" height="14" font="16">rather than input-output pairs.</text>
<text top="434" left="69" width="19" height="14" font="15">2.5</text>
<text top="434" left="103" width="99" height="14" font="15">Type Retrieval</text>
<text top="827" left="69" width="322" height="12" font="13">Fig. 6. A programmer requests a hole filling (A) by typing</text>
<text top="823" left="396" width="13" height="17" font="22">??</text>
<text top="827" left="412" width="251" height="12" font="13">, either intentionally or in a fit of frustration.</text>
<text top="843" left="68" width="592" height="12" font="13">The Hazel Language Server provides codebase-wide (B) semantic information relevant to the hole, collecting</text>
<text top="859" left="69" width="592" height="12" font="13">types based on the expected type (C) and selecting type-relevant headers from the context (D). These are</text>
<text top="876" left="69" width="573" height="12" font="13">combined into a contextualized text prompt (E) which is sent (F) to the LLM resulting in hole filling (G).</text>
<text top="918" left="84" width="407" height="14" font="16">The base EmojiPaint update function program sketch is as follows:</text>
<text top="940" left="74" width="450" height="17" font="20">(* Update the EmojiPaint app model based on an action *)</text>
<text top="960" left="74" width="22" height="11" font="21"><b>let</b></text>
<text top="956" left="106" width="297" height="17" font="22">update : (Model , Action ) -&gt; Model = ??</text>
<text top="960" left="413" width="14" height="11" font="21"><b>in</b></text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="1080" width="729">
<image top="593" left="137" width="455" height="138" src="output-10_1.png"/>
<text top="93" left="69" width="30" height="11" font="12">288:10</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="131" left="84" width="577" height="14" font="16">We augment this sketch with additional static information obtained via the Hazel Language</text>
<text top="149" left="69" width="592" height="14" font="16">Server, serialized into text, displayed as a kind of projected view of the codebase – a static program</text>
<text top="167" left="69" width="592" height="14" font="16">slice contextualized to the relevant program hole. Specifically, we retrieve the following static</text>
<text top="185" left="69" width="173" height="14" font="16">information (diagrammed in</text>
<text top="185" left="245" width="50" height="14" font="17"><a href="output.html#9">Figure 6</a></text>
<text top="185" left="295" width="8" height="14" font="16"><a href="output.html#9">):</a></text>
<text top="207" left="92" width="7" height="13" font="26">•</text>
<text top="207" left="105" width="82" height="14" font="18">Type Retrieval</text>
<text top="207" left="189" width="472" height="14" font="16">: The expected type at the cursor, along with the definitions of any types aliases</text>
<text top="225" left="105" width="555" height="14" font="16">occurring in that type, and the definitions of aliases occurring in that definition, and so on</text>
<text top="242" left="105" width="247" height="14" font="16">recursively until we arrive at base types.</text>
<text top="260" left="92" width="7" height="13" font="26">•</text>
<text top="261" left="105" width="99" height="14" font="18">Header Retrieval</text>
<text top="260" left="205" width="456" height="14" font="16">: A selection of values, annotated with their types, filtered from the typing</text>
<text top="278" left="105" width="557" height="14" font="16">context based on a type-directed metric of relatedness to the expected type described below.</text>
<text top="300" left="84" width="577" height="14" font="16">While we use Hazel to illustrate our approach, our goal is to outline an approximate API which</text>
<text top="318" left="69" width="592" height="14" font="16">could be implemented by any language server for a typed language which could drive a similar</text>
<text top="336" left="69" width="592" height="14" font="16">system in another language. We’ll define the approximate methods for such an API as we go, and</text>
<text top="354" left="69" width="122" height="14" font="16">later collect them in</text>
<text top="354" left="195" width="54" height="14" font="17"><a href="output.html#22">section 5</a></text>
<text top="354" left="249" width="3" height="14" font="16"><a href="output.html#22">.</a></text>
<text top="381" left="69" width="27" height="14" font="23">2.5.1</text>
<text top="381" left="111" width="158" height="14" font="23">Relevant Type Definitions.</text>
<text top="381" left="273" width="387" height="14" font="16">Given the above program sketch, the expected type of the hole</text>
<text top="396" left="71" width="13" height="17" font="22">??</text>
<text top="399" left="90" width="10" height="14" font="16">is</text>
<text top="396" left="104" width="161" height="17" font="24">(Model, Action) -&gt; Model</text>
<text top="399" left="266" width="395" height="14" font="16">. While in this example, adding the expected type to the prompt</text>
<text top="417" left="69" width="592" height="14" font="16">is strictly redundant, as it already appears as the function’s type annotation, in general Hazel’s</text>
<text top="434" left="69" width="160" height="14" font="16">bidirectional type system <a href="output.html#29">[</a></text>
<text top="434" left="229" width="14" height="14" font="17"><a href="output.html#29">51</a></text>
<text top="434" left="243" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="434" left="249" width="14" height="14" font="17"><a href="output.html#31">87</a></text>
<text top="434" left="263" width="397" height="14" font="16"><a href="output.html#31">] </a>allows a similar expected type to be extracted in any position for</text>
<text top="452" left="68" width="592" height="14" font="16">which there exists type constraints, such as in function argument position, or in a module signature</text>
<text top="470" left="69" width="58" height="14" font="16">including</text>
<text top="468" left="130" width="40" height="17" font="22">update</text>
<text top="470" left="170" width="3" height="14" font="16">.</text>
<text top="488" left="84" width="578" height="14" font="16">Absent this sort of context, this type is elucidatory on its own. Based on the provided comment,</text>
<text top="506" left="69" width="592" height="14" font="16">a language model might and likely will ‘guess’ that these refer to the state and state changes of an</text>
<text top="524" left="69" width="592" height="14" font="16">Model-View-Update application. But as we shall see, it is unlikely to guess the precise structures of</text>
<text top="542" left="69" width="592" height="14" font="16">the types the programmer has actually used. An example demonstrating the common case is show</text>
<text top="560" left="69" width="12" height="14" font="16">in</text>
<text top="560" left="85" width="50" height="14" font="17"><a href="output.html#10">Figure 7</a></text>
<text top="560" left="134" width="4" height="14" font="16"><a href="output.html#10">:</a></text>
<text top="751" left="69" width="592" height="12" font="13">Fig. 7. A typical completion with no static retrieval. Here, the language model hallucinates plausible but</text>
<text top="767" left="69" width="592" height="12" font="13">incorrect constructors for the Action type, and hallucinates Model as a record type using syntax not supported</text>
<text top="784" left="69" width="48" height="12" font="13">in Hazel.</text>
<text top="821" left="84" width="578" height="14" font="16">Hence we do automatically what a programmer in an unfamiliar codebase might do manually:</text>
<text top="838" left="69" width="592" height="14" font="16">recursively pursue type definitions to unwind the local semantic context hinted at by the type</text>
<text top="856" left="69" width="592" height="14" font="16">expectation. Providing this list to a language model is analogous to a human using the IDE to hover</text>
<text top="874" left="69" width="545" height="14" font="16">over types and jump iteratively to their definitions. First, we extract relevant type aliases:</text>
<text top="896" left="92" width="7" height="13" font="26">•</text>
<text top="893" left="105" width="34" height="17" font="24">Model</text>
<text top="913" left="92" width="7" height="13" font="26">•</text>
<text top="911" left="105" width="40" height="17" font="24">Action</text>
<text top="935" left="84" width="212" height="14" font="16">Then, we retrieve their definitions:</text>
<text top="956" left="92" width="7" height="13" font="26">•</text>
<text top="958" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="954" left="136" width="34" height="17" font="25">Model</text>
<text top="954" left="173" width="7" height="17" font="22">=</text>
<text top="954" left="184" width="148" height="17" font="24">(Grid, Emoji, [Emoji])</text>
<text top="974" left="92" width="7" height="13" font="26">•</text>
<text top="976" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="972" left="136" width="40" height="17" font="25">Action</text>
<text top="972" left="180" width="7" height="17" font="22">=</text>
<text top="972" left="191" width="316" height="17" font="24">SelectEmoji(Emoji) + StampEmoji(Row, Col) + ...</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="28" size="15" family="QIZVEJ+LibertineMathMI" color="#000000"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:11</text>
<text top="131" left="84" width="577" height="14" font="16">And finally, we transitively complete this process, retrieving any additional aliases which occur</text>
<text top="149" left="69" width="190" height="14" font="16">in those definitions: the aliases</text>
<text top="147" left="263" width="27" height="17" font="24">Grid</text>
<text top="149" left="294" width="23" height="14" font="16">and</text>
<text top="147" left="320" width="34" height="17" font="24">Emoji</text>
<text top="149" left="358" width="53" height="14" font="16">from the</text>
<text top="147" left="415" width="34" height="17" font="24">Model</text>
<text top="149" left="452" width="154" height="14" font="16">definition and the aliases</text>
<text top="147" left="610" width="20" height="17" font="24">Row</text>
<text top="149" left="630" width="30" height="14" font="16">, and</text>
<text top="165" left="69" width="20" height="17" font="24">Col</text>
<text top="167" left="93" width="53" height="14" font="16">from the</text>
<text top="165" left="149" width="40" height="17" font="24">Action</text>
<text top="167" left="193" width="63" height="14" font="16">definition:</text>
<text top="189" left="92" width="7" height="13" font="26">•</text>
<text top="190" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="187" left="136" width="34" height="17" font="25">Emoji</text>
<text top="187" left="173" width="7" height="17" font="22">=</text>
<text top="187" left="184" width="40" height="17" font="24">String</text>
<text top="207" left="92" width="7" height="13" font="26">•</text>
<text top="208" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="205" left="136" width="20" height="17" font="25">Row</text>
<text top="205" left="160" width="7" height="17" font="22">=</text>
<text top="205" left="170" width="20" height="17" font="24">Int</text>
<text top="225" left="92" width="7" height="13" font="26">•</text>
<text top="226" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="223" left="136" width="20" height="17" font="25">Col</text>
<text top="223" left="160" width="7" height="17" font="22">=</text>
<text top="223" left="170" width="20" height="17" font="24">Int</text>
<text top="243" left="92" width="7" height="13" font="26">•</text>
<text top="244" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="240" left="136" width="27" height="17" font="25">Grid</text>
<text top="240" left="167" width="7" height="17" font="22">=</text>
<text top="240" left="177" width="61" height="17" font="24">[[Emoji]]</text>
<text top="264" left="84" width="578" height="14" font="16">Note that even though these type definitions are, from the point of view of the Language Server,</text>
<text top="282" left="69" width="592" height="14" font="16">abstract entries in the typing context, we are specifically electing to reproduce them in format</text>
<text top="300" left="69" width="592" height="14" font="16">resembling their original lexical concrete syntax. We have noticed that attempting this kind of</text>
<text top="318" left="69" width="593" height="14" font="16">naturalistic reproduction increases that chance that language model generations stay on-task,</text>
<text top="336" left="69" width="584" height="14" font="16">generating code in the relevant concrete syntax without reverting to prose or ill-formed syntax.</text>
<text top="354" left="84" width="577" height="14" font="16">To support the above method, a language server could implement the following methods, which</text>
<text top="372" left="69" width="588" height="14" font="16">may be implementable as thin glosses on top of existing methods such as ’Go to type definition’:</text>
<text top="401" left="92" width="7" height="13" font="26">•</text>
<text top="399" left="105" width="108" height="17" font="22">getExpectedType:</text>
<text top="399" left="217" width="229" height="17" font="24">(Program, LexicalLocation) -&gt; Type</text>
<text top="419" left="92" width="7" height="13" font="26">•</text>
<text top="417" left="105" width="101" height="17" font="22">extractAliases:</text>
<text top="417" left="210" width="94" height="17" font="24">Type -&gt; [Type]</text>
<text top="437" left="92" width="7" height="13" font="26">•</text>
<text top="435" left="105" width="121" height="17" font="22">getTypeDefinition:</text>
<text top="435" left="230" width="114" height="17" font="24">TypeAlias -&gt; Type</text>
<text top="466" left="68" width="557" height="14" font="16">To briefly contrast this process to embedding-vector-based retrieval augmented generation:</text>
<text top="488" left="92" width="7" height="13" font="26">•</text>
<text top="488" left="105" width="329" height="14" font="16">While vector retrieval might flag these definitions as</text>
<text top="488" left="438" width="48" height="14" font="18">possibly</text>
<text top="488" left="491" width="170" height="14" font="16">relevant, note that they are</text>
<text top="506" left="105" width="66" height="14" font="18">necessarily</text>
<text top="506" left="176" width="485" height="14" font="16">relevant. Our knowledge of the language semantics means we know that any</text>
<text top="524" left="105" width="69" height="14" font="16">completion</text>
<text top="524" left="178" width="30" height="14" font="18">must</text>
<text top="524" left="212" width="448" height="14" font="16">respect these types, an assurance which allows us to offload burden from</text>
<text top="542" left="105" width="327" height="14" font="16">the more expensive and imprecise associative lookup.</text>
<text top="559" left="92" width="7" height="13" font="26">•</text>
<text top="559" left="105" width="555" height="14" font="16">This necessary relevance also increases the chance that subsequent recursive retrievals will</text>
<text top="577" left="105" width="253" height="14" font="16">be relevant, addressing the issue of reliable</text>
<text top="577" left="361" width="105" height="14" font="18">multi-hop lookups</text>
<text top="577" left="470" width="191" height="14" font="16">noted by industry implementers</text>
<text top="595" left="105" width="5" height="14" font="16"><a href="output.html#26">[</a></text>
<text top="595" left="111" width="7" height="14" font="17"><a href="output.html#26">6</a></text>
<text top="595" left="118" width="5" height="14" font="16"><a href="output.html#26">]</a></text>
<text top="613" left="92" width="7" height="13" font="26">•</text>
<text top="613" left="105" width="557" height="14" font="16">Static retrieval necessarily respects scope. Vector retrieval may return related-seeming defi-</text>
<text top="631" left="105" width="555" height="14" font="16">nitions, but without exact knowledge of the language semantics, there is no guarantee that</text>
<text top="649" left="105" width="77" height="14" font="16">these will be</text>
<text top="649" left="186" width="18" height="14" font="18">the</text>
<text top="649" left="208" width="256" height="14" font="16">definitions relevant to this lexical context.</text>
<text top="681" left="69" width="19" height="14" font="15">2.6</text>
<text top="681" left="103" width="291" height="14" font="15">Relevant Headers from the Typing Context</text>
<text top="703" left="69" width="592" height="14" font="16">In addition to relevant type definitions, we augment the prompt with the names and types (which</text>
<text top="721" left="69" width="130" height="14" font="16">together we term the</text>
<text top="721" left="202" width="45" height="14" font="18">headers</text>
<text top="721" left="248" width="414" height="14" font="16">) of relevant values – typically functions – from the typing context.</text>
<text top="739" left="69" width="552" height="14" font="16">From a user interface perspective, this is analogous to a type-directed autocomplete menu.</text>
<text top="757" left="84" width="295" height="14" font="16">Our extraction method divides into three stages:</text>
<text top="779" left="84" width="348" height="14" font="16">(1) Use the expected type to identify a list of target types</text>
<text top="797" left="84" width="577" height="14" font="16">(2) Filter the typing context for values with types related in a certain way to these target types</text>
<text top="815" left="84" width="577" height="14" font="16">(3) Assign scores to each element of the resulting list, and return the prefix of that list truncated</text>
<text top="833" left="105" width="501" height="14" font="16">at some scoring and length thresholds (here, score &gt; 0.0 and 10 items respectively)</text>
<text top="854" left="84" width="577" height="14" font="16">The resulting context entries are formatted as code sketches, again to facilitate language model</text>
<text top="872" left="69" width="198" height="14" font="16">ingestion. For example the pair (</text>
<text top="870" left="267" width="87" height="17" font="22">string_of_int</text>
<text top="872" left="354" width="3" height="14" font="16">,</text>
<text top="870" left="361" width="87" height="17" font="24">Int -&gt; String</text>
<text top="872" left="448" width="102" height="14" font="16">) is formatted as:</text>
<text top="904" left="106" width="22" height="11" font="21"><b>let</b></text>
<text top="901" left="139" width="248" height="17" font="22">string_of_int : Int -&gt; String =</text>
<text top="904" left="405" width="14" height="11" font="21"><b>in</b></text>
<text top="938" left="84" width="562" height="14" font="16">Here, the body of the definition is simply omitted. Interestingly, we originally used ellipsis (</text>
<text top="942" left="646" width="11" height="7" font="28">...</text>
<text top="938" left="657" width="4" height="14" font="16">)</text>
<text top="956" left="69" width="592" height="14" font="16">in place of the body, but this resulted in an increased chance the model (especially the smaller</text>
<text top="974" left="69" width="282" height="14" font="16">StarCoder2 model) would itself emit the token</text>
<text top="978" left="355" width="11" height="7" font="28">...</text>
<text top="974" left="370" width="165" height="14" font="16">in lieu of a full completion.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="30" height="11" font="12">288:12</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="132" left="69" width="26" height="14" font="23">2.6.1</text>
<text top="132" left="110" width="174" height="14" font="23">Identification of Target Types.</text>
<text top="131" left="289" width="372" height="14" font="16">First, we deconstructing the expected type to identify relevant</text>
<text top="149" left="69" width="592" height="14" font="16">sub-components which could be used, in conjunction with their relevant elimination forms, to</text>
<text top="167" left="69" width="479" height="14" font="16">construct the target. Our initial target type is simply the type of the hole itself:</text>
<text top="194" left="84" width="83" height="14" font="19">Target types</text>
<text top="194" left="171" width="8" height="14" font="16">=</text>
<text top="192" left="183" width="161" height="17" font="24">(Model, Action) -&gt; Model</text>
<text top="221" left="84" width="577" height="14" font="16">Then, if that type is a compound type, we consider its components. In particular, if the type is a</text>
<text top="239" left="69" width="592" height="14" font="16">product type, we consider its components to be targets, and if the type is an arrow type (as it is</text>
<text top="257" left="69" width="290" height="14" font="16">here), we consider its return type to be a target.</text>
<text top="284" left="84" width="83" height="14" font="19">Target types</text>
<text top="284" left="171" width="8" height="14" font="16">=</text>
<text top="282" left="183" width="242" height="17" font="24">(Model, Action) -&gt; Model, Model, ...</text>
<text top="311" left="84" width="577" height="14" font="16">In principle, we could continue this deconstruction recursively indefinitely, but for our immediate</text>
<text top="329" left="69" width="593" height="14" font="16">purpose of identifying likely-relevant types, we’ve found it suffices to extend one more iteration;</text>
<text top="347" left="69" width="592" height="14" font="16">that is, product/arrow types containing product/arrow types. It simplifies our calculations to</text>
<text top="365" left="69" width="592" height="14" font="16">internally normalize all type definitions (Hazel is structurally typed). Here, we will only do so</text>
<text top="383" left="69" width="268" height="14" font="16">opportunistically for clarity of presentation:</text>
<text top="409" left="84" width="85" height="14" font="19">Type of hole</text>
<text top="409" left="172" width="8" height="14" font="16">=</text>
<text top="407" left="184" width="457" height="17" font="24">((String, (Grid, Emoji, [Emoji])), Action) -&gt; (Grid, Emoji, [Emoji])</text>
<text top="427" left="84" width="83" height="14" font="19">Target types</text>
<text top="427" left="171" width="8" height="14" font="16">=</text>
<text top="425" left="183" width="356" height="17" font="24">(Model, Action) -&gt; Model, Model, Grid, Emoji, [Emoji]</text>
<text top="454" left="84" width="579" height="14" font="16">One can likely see other ways of extending target type extraction. Possibilities included destruc-</text>
<text top="472" left="69" width="592" height="14" font="16">turing more compound types such as records, or for function types, also considering the input</text>
<text top="490" left="69" width="592" height="14" font="16">types as a kind of negative target, in that we may want to prioritize types that consume a relevant</text>
<text top="508" left="69" width="513" height="14" font="16">type from the local context. For now we proceed with the simple approach outlined.</text>
<text top="526" left="84" width="350" height="14" font="16">We do not, however, return unaliased base types such as</text>
<text top="524" left="438" width="27" height="17" font="24">Bool</text>
<text top="526" left="469" width="13" height="14" font="16">or</text>
<text top="524" left="486" width="40" height="17" font="24">String</text>
<text top="526" left="530" width="131" height="14" font="16">as target types. Early</text>
<text top="544" left="69" width="592" height="14" font="16">experimentation indicated that, given that there are typically many standard library functions on</text>
<text top="562" left="69" width="592" height="14" font="16">base types, often with no a priori way to distinguish their relevance based on types, such functions</text>
<text top="580" left="68" width="592" height="14" font="16">would often act as confounders, since which happened to be included was incidental. In practice, a</text>
<text top="598" left="69" width="592" height="14" font="16">standard library would already be well-understood by an LLM from the pre-training or fine-tuning</text>
<text top="616" left="69" width="528" height="14" font="16">step. For Hazel, we replicate much of the OCaml standard library to sidestep this need.</text>
<text top="649" left="69" width="27" height="14" font="23">2.6.2</text>
<text top="649" left="111" width="129" height="14" font="23">Filtering the Context.</text>
<text top="649" left="245" width="415" height="14" font="16">For each target type, we filter the typing context to retrieve types</text>
<text top="667" left="68" width="594" height="14" font="16">which can be used, again in conjunction with appropriate elimination forms, to produce the target.</text>
<text top="685" left="84" width="577" height="14" font="16">This is essentially similar to target type extraction. In particular, we return types which are</text>
<text top="703" left="69" width="592" height="14" font="16">consistent with the target, arrow types whose return type is consistent with the target, and product</text>
<text top="721" left="69" width="437" height="14" font="16">types whose have a component consistent with the target. For example:</text>
<text top="747" left="84" width="77" height="14" font="19">Target type</text>
<text top="745" left="164" width="27" height="17" font="24">Grid</text>
<text top="747" left="195" width="40" height="14" font="19">yields</text>
<text top="775" left="92" width="7" height="13" font="26">•</text>
<text top="773" left="105" width="74" height="17" font="22">updateGrid:</text>
<text top="773" left="183" width="208" height="17" font="24">(Grid, Row, Col, Emoji) -&gt; Grid</text>
<text top="793" left="92" width="7" height="13" font="26">•</text>
<text top="791" left="105" width="67" height="17" font="22">clearGrid:</text>
<text top="791" left="176" width="81" height="17" font="24">Grid -&gt; Grid</text>
<text top="811" left="92" width="7" height="13" font="26">•</text>
<text top="809" left="105" width="94" height="17" font="22">fillRowInGrid:</text>
<text top="809" left="203" width="175" height="17" font="24">(Grid, Row, Emoji) -&gt; Grid</text>
<text top="864" left="69" width="26" height="14" font="23">2.6.3</text>
<text top="864" left="110" width="230" height="14" font="23">Sorting and scoring the filtered context.</text>
<text top="864" left="345" width="74" height="14" font="16">Prior work <a href="output.html#27">[</a></text>
<text top="864" left="419" width="14" height="14" font="17"><a href="output.html#27">12</a></text>
<text top="864" left="433" width="227" height="14" font="16"><a href="output.html#27">] </a>has surveyed various ways in which</text>
<text top="881" left="69" width="592" height="14" font="16">semantic information can be used to sort typing-context-originating suggestions for relevance. For</text>
<text top="899" left="69" width="592" height="14" font="16">our purposes here we use a simple scheme intended as a proof-of-concept to establish a baseline</text>
<text top="917" left="69" width="196" height="14" font="16">for more sophisticated methods.</text>
<text top="935" left="84" width="577" height="14" font="16">By default, Hazel context entries are sorted by locality of definition, which provides a reasonable</text>
<text top="953" left="69" width="592" height="14" font="16">default for relevance. Thus we sort stably with respect to the locality ordering for context entries</text>
<text top="971" left="69" width="139" height="14" font="16">having the same score.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:13</text>
<text top="131" left="84" width="577" height="14" font="16">By default, all entries are assigned a score of 1.0. However, if a type contains the (gradual)</text>
<text top="149" left="69" width="94" height="14" font="16">unknown type (</text>
<text top="147" left="163" width="7" height="17" font="24">?</text>
<text top="149" left="170" width="490" height="14" font="16">), a multiplier is applied based on the ratio of unknown to known type constructors</text>
<text top="167" left="69" width="202" height="14" font="16">in the type (for example, the type</text>
<text top="165" left="275" width="20" height="17" font="24">[?]</text>
<text top="167" left="299" width="363" height="14" font="16">– a list of unknown type – would receive a multiplier of 0.5,</text>
<text top="185" left="69" width="593" height="14" font="16">since the list constructor is known). This acts simply to de-prioritize incomplete implementations,</text>
<text top="203" left="69" width="480" height="14" font="16">about which not enough information is available to make it a good suggestion.</text>
<text top="221" left="84" width="378" height="14" font="16">Here are the relevant headers from the EmojiPainter example:</text>
<text top="253" left="74" width="507" height="17" font="27">&#34; Consider using these variables relevant to the expected type :&#34;</text>
<text top="273" left="74" width="22" height="11" font="21"><b>let</b></text>
<text top="269" left="106" width="151" height="17" font="22">model_init : Model =</text>
<text top="273" left="276" width="14" height="11" font="21"><b>in</b></text>
<text top="290" left="74" width="22" height="11" font="21"><b>let</b></text>
<text top="286" left="107" width="361" height="17" font="22">fillRowInGrid : (( Grid , Row , Emoji ) -&gt; Grid ) =</text>
<text top="290" left="485" width="14" height="11" font="21"><b>in</b></text>
<text top="306" left="74" width="22" height="11" font="21"><b>let</b></text>
<text top="302" left="106" width="216" height="17" font="22">clearGrid : (Grid -&gt; Grid) =</text>
<text top="306" left="340" width="14" height="11" font="21"><b>in</b></text>
<text top="322" left="74" width="22" height="11" font="21"><b>let</b></text>
<text top="319" left="106" width="377" height="17" font="22">updateGrid : (( Grid , Row , Col , Emoji ) -&gt; Grid) =</text>
<text top="322" left="502" width="14" height="11" font="21"><b>in</b></text>
<text top="359" left="84" width="577" height="14" font="16">In order to implement relevant header extraction in an arbitrarily language server, one could</text>
<text top="377" left="69" width="191" height="14" font="16">provide the following methods:</text>
<text top="411" left="92" width="7" height="13" font="26">•</text>
<text top="409" left="105" width="101" height="17" font="22">getTargetTypes:</text>
<text top="409" left="210" width="94" height="17" font="24">Type -&gt; [Type]</text>
<text top="429" left="92" width="7" height="13" font="26">•</text>
<text top="427" left="105" width="94" height="17" font="22">filterContext:</text>
<text top="427" left="203" width="208" height="17" font="24">Context, Type -&gt; [(Name, Type)]</text>
<text top="447" left="92" width="7" height="13" font="26">•</text>
<text top="445" left="105" width="74" height="17" font="22">scoreEntry:</text>
<text top="445" left="183" width="141" height="17" font="24">(Name, Type) -&gt; Float</text>
<text top="482" left="69" width="19" height="14" font="15">2.7</text>
<text top="482" left="103" width="275" height="14" font="15">Syntactic and Semantic Error Correction</text>
<text top="504" left="68" width="592" height="14" font="16">The use of instruction-tuned language models makes available a lightweight form of program</text>
<text top="522" left="69" width="592" height="14" font="16">repair based on an iterative loop of generating completions and retrieving error messages from</text>
<text top="540" left="69" width="592" height="14" font="16">compilers or static analyzers. The general technique of looping LLM code generation on compiler</text>
<text top="558" left="69" width="544" height="14" font="16">errors appears to have emerged in tandem with early LLM code generation experiments <a href="output.html#29">[</a></text>
<text top="558" left="613" width="14" height="14" font="17"><a href="output.html#29">59</a></text>
<text top="558" left="627" width="14" height="14" font="16"><a href="output.html#29">] </a><a href="output.html#31">[</a></text>
<text top="558" left="641" width="14" height="14" font="17"><a href="output.html#31">84</a></text>
<text top="558" left="655" width="5" height="14" font="16"><a href="output.html#31">]</a></text>
<text top="576" left="69" width="338" height="14" font="16">and has been examined in greater detail by Joshi et al. <a href="output.html#28">[</a></text>
<text top="576" left="407" width="14" height="14" font="17"><a href="output.html#28">33</a></text>
<text top="576" left="420" width="9" height="14" font="16"><a href="output.html#28">].</a></text>
<text top="594" left="84" width="577" height="14" font="16">After receiving a response from the model, we substitute the received completion into the</text>
<text top="612" left="69" width="594" height="14" font="16">original program sketch. We then query the Hazel Language Server to parse the resulting program.</text>
<text top="630" left="69" width="592" height="14" font="16">Hazel parsing is strongly incremental, enabling the (partial) type-checking of programs even in the</text>
<text top="648" left="69" width="592" height="14" font="16">presence of unrecognized or missing delimiters. We then query the language server for a list of</text>
<text top="666" left="69" width="592" height="14" font="16">static errors, which include syntax and type errors. If there are any such errors, we serialize them</text>
<text top="684" left="69" width="302" height="14" font="16">to a string, and send them to the language model.</text>
<text top="702" left="84" width="577" height="14" font="16">In order to maintain model context, we append the errors to a growing log of messages beginning</text>
<text top="720" left="68" width="592" height="14" font="16">with the original prompt. The number of correction rounds which can be performed in this way</text>
<text top="738" left="69" width="592" height="14" font="16">is thus limited by the length of the context window; in our case, using the 8k token window of</text>
<text top="756" left="69" width="592" height="14" font="16">GPT4-0613, we are effectively capped at 5 rounds. However, we have noticed that 2 rounds are</text>
<text top="773" left="69" width="592" height="14" font="16">often sufficient to eliminate static errors, and that rounds in excess of 2 tend to show diminishing</text>
<text top="791" left="69" width="397" height="14" font="16">returns, so we have capped the maximum number of rounds at 2.</text>
<text top="809" left="84" width="578" height="14" font="16">To support this in another language, its language server must be able to localize static errors,</text>
<text top="827" left="69" width="592" height="14" font="16">reporting locations and error messages. Ideally, it would produce a list of errors, rather than just</text>
<text top="845" left="69" width="592" height="14" font="16">the first error encountered, as is supported by Hazel’s total type error localization and recovery</text>
<text top="863" left="69" width="52" height="14" font="16">system <a href="output.html#31">[</a></text>
<text top="863" left="120" width="14" height="14" font="17"><a href="output.html#31">87</a></text>
<text top="863" left="134" width="398" height="14" font="16"><a href="output.html#31">]. </a>This could be achieved by implementing the following method:</text>
<text top="897" left="92" width="7" height="13" font="26">•</text>
<text top="895" left="105" width="108" height="17" font="22">getStaticErrors:</text>
<text top="895" left="217" width="161" height="17" font="24">Program -&gt; [StaticError]</text>
<text top="932" left="69" width="19" height="14" font="15">2.8</text>
<text top="932" left="103" width="169" height="14" font="15">Experimental Evaluation</text>
<text top="955" left="68" width="595" height="14" font="16">We now evaluate the effectiveness of this method of proactive static contextualization and retro-</text>
<text top="972" left="69" width="277" height="14" font="16">spective correction for LLM code completion.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="29" size="15" family="IXRNWO+LinLibertineTBI" color="#000000"/>
<text top="93" left="69" width="30" height="11" font="12">288:14</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="132" left="69" width="27" height="14" font="23">2.8.1</text>
<text top="132" left="111" width="73" height="14" font="23">MVUBench.</text>
<text top="131" left="188" width="472" height="14" font="16">Hazel is a low-resource language, so we are unable to conduct an at-scale</text>
<text top="149" left="69" width="592" height="14" font="16">evaluation in this context. Instead, as previously motivated, we construct a benchmark suite of five</text>
<text top="167" left="69" width="502" height="14" font="16">MVU applications including the EmojiPainter example from the previous sections:</text>
<text top="194" left="92" width="7" height="13" font="26">•</text>
<text top="194" left="105" width="42" height="14" font="19">Todo (</text>
<text top="194" left="148" width="20" height="14" font="29">TO</text>
<text top="194" left="168" width="5" height="14" font="19">)</text>
<text top="194" left="173" width="152" height="14" font="16">: Maintains a list of tasks</text>
<text top="212" left="92" width="7" height="13" font="26">•</text>
<text top="212" left="105" width="110" height="14" font="19">Room Booking (</text>
<text top="212" left="216" width="20" height="14" font="29">BO</text>
<text top="212" left="236" width="5" height="14" font="19">)</text>
<text top="212" left="241" width="219" height="14" font="16">: Manages a room booking schedule</text>
<text top="230" left="92" width="7" height="13" font="26">•</text>
<text top="230" left="105" width="102" height="14" font="19">Emoji Painter (</text>
<text top="230" left="208" width="22" height="14" font="29">EM</text>
<text top="230" left="230" width="5" height="14" font="19">)</text>
<text top="230" left="235" width="240" height="14" font="16">: Paints emoji stamps on a small canvas</text>
<text top="248" left="92" width="7" height="13" font="26">•</text>
<text top="248" left="105" width="123" height="14" font="19">Playlist Manager (</text>
<text top="248" left="228" width="17" height="14" font="29">PL</text>
<text top="248" left="245" width="5" height="14" font="19">)</text>
<text top="248" left="250" width="160" height="14" font="16">: Manages a music playlist</text>
<text top="266" left="92" width="7" height="13" font="26">•</text>
<text top="266" left="105" width="195" height="14" font="19">Password Strength Checker (</text>
<text top="266" left="300" width="19" height="14" font="29">PA</text>
<text top="266" left="319" width="5" height="14" font="19">)</text>
<text top="266" left="323" width="304" height="14" font="16">: Rates a password via a dynamic set of properties</text>
<text top="292" left="84" width="577" height="14" font="16">The baseline program sketch provided to the language model for each of these programs is</text>
<text top="310" left="69" width="404" height="14" font="16">simply the type-annotated function header for its corresponding</text>
<text top="308" left="477" width="40" height="17" font="22">update</text>
<text top="310" left="522" width="139" height="14" font="16">function, along with a</text>
<text top="328" left="69" width="592" height="14" font="16">single-line comment describing that function’s purpose, including the name of the application, in</text>
<text top="346" left="69" width="189" height="14" font="16">line with the running example.</text>
<text top="364" left="84" width="577" height="14" font="16">Each application also comes with a simulated repository containing relevant (and less relevant)</text>
<text top="382" left="69" width="221" height="14" font="16">type and utility function definitions.</text>
<text top="400" left="84" width="577" height="14" font="16">We also provide a small test suite for each example, consisting of 10-15 tests ensuring that each</text>
<text top="418" left="69" width="537" height="14" font="16">MVU action behaves as a user might reasonably expect without additional specification.</text>
<text top="436" left="84" width="532" height="14" font="16">In such a situation, a naive language model completion would be informed only by the</text>
<text top="434" left="620" width="40" height="17" font="22">update</text>
<text top="454" left="69" width="370" height="14" font="16">function type aliases (which are often generic terms such as</text>
<text top="452" left="442" width="34" height="17" font="22">Model</text>
<text top="454" left="476" width="185" height="14" font="16">) and the single-line comment</text>
<text top="472" left="68" width="592" height="14" font="16">(which only hints at the intended functionality). While it is still possible that in very typical</text>
<text top="490" left="69" width="592" height="14" font="16">situations, the model might correctly guess appropriate types and names, more likely (as we shall</text>
<text top="508" left="69" width="592" height="14" font="16">see) it will hallucinate plausible-but-incorrect completions. By varying the methods through which</text>
<text top="526" left="69" width="592" height="14" font="16">additional context is provided, and the corrective methods applied to resulting completions, we</text>
<text top="543" left="69" width="592" height="14" font="16">provide a baseline analysis for the relative effects and interactions of these methods on LLM code</text>
<text top="561" left="69" width="72" height="14" font="16">completion.</text>
<text top="594" left="69" width="26" height="14" font="23">2.8.2</text>
<text top="594" left="110" width="171" height="14" font="23">Feature Ablation Experiment.</text>
<text top="594" left="286" width="374" height="14" font="16">Our main experiment consisted of 320 completions trials, each</text>
<text top="612" left="69" width="592" height="14" font="16">of which makes between one and three calls to the language model. These 320 trials divide as</text>
<text top="629" left="69" width="48" height="14" font="16">follows:</text>
<text top="656" left="92" width="7" height="13" font="26">•</text>
<text top="656" left="105" width="222" height="14" font="19">8 feature ablation configurations</text>
<text top="674" left="104" width="8" height="14" font="19">–</text>
<text top="674" left="118" width="85" height="14" font="18">Type Retrieval</text>
<text top="674" left="203" width="340" height="14" font="16">: Whether to include expected type and type definitions</text>
<text top="692" left="104" width="8" height="14" font="19">–</text>
<text top="692" left="118" width="98" height="14" font="18">Header Retrieval</text>
<text top="692" left="217" width="379" height="14" font="16">: Whether to include relevant headers from the typing context</text>
<text top="710" left="104" width="8" height="14" font="19">–</text>
<text top="710" left="118" width="77" height="14" font="18">Error Rounds</text>
<text top="710" left="196" width="314" height="14" font="16">: Whether to perform up to 2 static error correction</text>
<text top="728" left="92" width="7" height="13" font="26">•</text>
<text top="728" left="105" width="274" height="14" font="19">5 program sketches (TO, BO, EM, PL, PA)</text>
<text top="746" left="92" width="7" height="13" font="26">•</text>
<text top="746" left="105" width="251" height="14" font="19">20 completion trials per combination</text>
<text top="746" left="360" width="250" height="14" font="16">(to account for model non-determinism <a href="output.html#29">[</a></text>
<text top="746" left="610" width="14" height="14" font="17"><a href="output.html#29">56</a></text>
<text top="746" left="624" width="37" height="14" font="16"><a href="output.html#29">]). </a>We</text>
<text top="764" left="105" width="555" height="14" font="16">ran these experiments at temperature 0.6 (a hyperparameter effecting the stochasticity of</text>
<text top="782" left="105" width="555" height="14" font="16">token sampling), selected based on trial experiments as a balance between noisy variance</text>
<text top="800" left="105" width="362" height="14" font="16">and producing a range of interestingly distinct completions</text>
<text top="832" left="69" width="27" height="14" font="23">2.8.3</text>
<text top="832" left="110" width="215" height="14" font="23">Comparison Baseline 1: No Context.</text>
<text top="832" left="331" width="329" height="14" font="16">The ablation configurations lacking all static retrieval</text>
<text top="850" left="69" width="592" height="14" font="16">feature serves as a lower bound baseline – without any context except the brief comment on</text>
<text top="868" left="69" width="20" height="14" font="16">the</text>
<text top="865" left="93" width="40" height="17" font="22">update</text>
<text top="868" left="138" width="522" height="14" font="16">function, we would expect even high-performing models to perform poorly due to</text>
<text top="886" left="69" width="592" height="14" font="16">lack of context. This is the current reality for AI programming assistants that do not attempt</text>
<text top="904" left="69" width="155" height="14" font="16">repository-level retrieval.</text>
<text top="936" left="69" width="27" height="14" font="23">2.8.4</text>
<text top="936" left="110" width="268" height="14" font="23">Comparison Baseline 2: Exhaustive Retrieval.</text>
<text top="936" left="383" width="277" height="14" font="16">An additional baseline configuration, beyond</text>
<text top="954" left="69" width="592" height="14" font="16">those outlined above, is to perform exhaustive retrieval of all application code, excluding tests, up</text>
<text top="972" left="69" width="563" height="14" font="16">to the context window limit. This serves as a token-inefficient upper bound on performance.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="1080" width="729">
<image top="785" left="88" width="553" height="161" src="output-15_1.png"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:15</text>
<text top="132" left="69" width="26" height="14" font="23">2.8.5</text>
<text top="132" left="110" width="338" height="14" font="23">Comparison Baseline 3: Vector Retrieval with Confounds.</text>
<text top="131" left="453" width="207" height="14" font="16">Finally, we compare our approach</text>
<text top="149" left="69" width="592" height="14" font="16">to vector retrieval. Given that our test corpus consists of 5 relatively small programs, we have</text>
<text top="167" left="69" width="592" height="14" font="16">emulated a larger more realistic codebase by combining those five programs, minus tests and</text>
<text top="185" left="69" width="592" height="14" font="16">update functions, along with Hazel’s standard library, to create a 1000-line simulated codebase from</text>
<text top="203" left="68" width="592" height="14" font="16">which context can be drawn. Combining these programs has the effect of creating some possible</text>
<text top="221" left="69" width="592" height="14" font="16">lexical confounders, e.g. two types having the same name; we contend that this construction, albeit</text>
<text top="239" left="69" width="592" height="14" font="16">synthetic, nonetheless emulates a legitimate source of confusion for a scope-unaware method like</text>
<text top="257" left="68" width="97" height="14" font="16">vector retrieval.</text>
<text top="275" left="84" width="579" height="14" font="16">We have used the simplest standard RAG strategy, uniformly dividing the codebase into 150-</text>
<text top="293" left="69" width="592" height="14" font="16">character chunks, which were submitted to OpenAI’s Ada (text-embedding-ada-002), a commercial</text>
<text top="311" left="69" width="120" height="14" font="16">embeddings model <a href="output.html#29">[</a></text>
<text top="311" left="188" width="14" height="14" font="17"><a href="output.html#29">49</a></text>
<text top="311" left="202" width="460" height="14" font="16"><a href="output.html#29">]. </a>The retrieved 1536-element vectors, along with their associated text chunks,</text>
<text top="329" left="69" width="426" height="14" font="16">are then stored locally in a JSON file acting as a basic vector database.</text>
<text top="347" left="84" width="578" height="14" font="16">In order to retrieve chunks relevant to a provided sketch (our function headers and comments),</text>
<text top="365" left="68" width="592" height="14" font="16">we submit that sketch to the same API endpoint, and then search our vector database for the top 6</text>
<text top="383" left="69" width="261" height="14" font="16">chunks with the highest cosine similarity <a href="output.html#29">[</a></text>
<text top="383" left="330" width="14" height="14" font="17"><a href="output.html#29">49</a></text>
<text top="383" left="344" width="9" height="14" font="16"><a href="output.html#29">].</a></text>
<text top="400" left="84" width="577" height="14" font="16">The above parameters (150 character chunks, 6 entries) are chosen so that the total (900 characters)</text>
<text top="418" left="69" width="592" height="14" font="16">lines up with the average length of the total static retrieval context (types + relevant context) for</text>
<text top="436" left="69" width="592" height="14" font="16">our 5 examples, with the chunk size being set as small as possible while still being able to fully</text>
<text top="454" left="69" width="267" height="14" font="16">contain most type definitions in our corpus.</text>
<text top="472" left="84" width="577" height="14" font="16">It should be noted that there exist a variety of more advanced chunking strategies which may</text>
<text top="490" left="69" width="571" height="14" font="16">yield better results, including overlapping windows, chunks aligned to inferred authorial intent <a href="output.html#30">[</a></text>
<text top="490" left="640" width="14" height="14" font="17"><a href="output.html#30">76</a></text>
<text top="490" left="653" width="8" height="14" font="16"><a href="output.html#30">],</a></text>
<text top="508" left="69" width="592" height="14" font="16">and semantic chunking which takes into account source syntax. However, all these strategies have</text>
<text top="526" left="69" width="592" height="14" font="16">complex trade-offs which take us beyond our immediate comparative goals; for example, chunking</text>
<text top="544" left="69" width="592" height="14" font="16">by top-level definitions (a language-aware approach) might prevent issues with a poorly-truncated</text>
<text top="562" left="69" width="592" height="14" font="16">definition being included in a prompt, but seeing as definitions can range widely in size, being</text>
<text top="580" left="69" width="592" height="14" font="16">forced to include an entire definition may prevent multiple chunks which are together more relevant</text>
<text top="598" left="69" width="126" height="14" font="16">from being included.</text>
<text top="616" left="84" width="577" height="14" font="16">As such, we have elected to leave the RAG baseline structurally agnostic, so as to more cleanly</text>
<text top="634" left="69" width="592" height="14" font="16">contrast it with semantic methods, while noting it is likely that ultimately these two methods are</text>
<text top="652" left="69" width="592" height="14" font="16">not exclusive and can be used synergistically in a production setting (for example, balancing the</text>
<text top="669" left="69" width="592" height="14" font="16">ratio of typed semantic versus associative RAG depending on the amount of static information</text>
<text top="687" left="69" width="386" height="14" font="16">available at a given lexical location). We return to this theme in</text>
<text top="687" left="459" width="54" height="14" font="17"><a href="output.html#23">section 6</a></text>
<text top="687" left="513" width="3" height="14" font="16"><a href="output.html#23">.</a></text>
<text top="727" left="69" width="19" height="14" font="15">2.9</text>
<text top="727" left="103" width="136" height="14" font="15">Hazel GPT-4 Results</text>
<text top="967" left="140" width="450" height="12" font="13">Fig. 8. Hazel GPT-4: Results for guided completion (20 trials per, temperature 0.6)</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="16" position="absolute" top="0" left="0" height="1080" width="729">
<image top="304" left="69" width="592" height="247" src="output-16_1.png"/>
<text top="93" left="69" width="30" height="11" font="12">288:16</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="131" left="69" width="51" height="14" font="17"><a href="output.html#15">Figure 8</a></text>
<text top="131" left="124" width="536" height="14" font="16">shows the results of our evaluation for GPT-4. We see a clear trend of more semantic</text>
<text top="149" left="69" width="592" height="14" font="16">information yielding better results on the held-out tests. The no-context baseline (no/no/no) alone</text>
<text top="167" left="69" width="592" height="14" font="16">does not suffice to yield meaningful generations, often returning syntactically incorrect code as</text>
<text top="185" left="69" width="592" height="14" font="16">the model hallucinates data types and syntax (such as OCaml-style records) which do not exist in</text>
<text top="203" left="69" width="335" height="14" font="16">Hazel, despite the inclusion of the Hazel Crash Course.</text>
<text top="221" left="84" width="577" height="14" font="16">Including type definitions seem absolutely necessary to allow the model to scaffold the update</text>
<text top="239" left="69" width="594" height="14" font="16">function. Without this scaffolding, relevant function headers alone show little effect on correctness.</text>
<text top="257" left="69" width="592" height="14" font="16">However, in combination with types, function headers have a large multiplicative effect, increasing</text>
<text top="275" left="69" width="166" height="14" font="16">test performance threefold.</text>
<text top="275" left="238" width="50" height="14" font="17"><a href="output.html#16">Figure 9</a></text>
<text top="275" left="291" width="285" height="14" font="16">provides concrete examples of this interaction:</text>
<text top="571" left="69" width="592" height="12" font="13">Fig. 9. Some sample completions for various configurations. In (a), without any supporting context, we see</text>
<text top="587" left="69" width="255" height="12" font="13">reasonable-but-incorrect guesses at both the</text>
<text top="584" left="328" width="40" height="17" font="22">Action</text>
<text top="587" left="373" width="119" height="12" font="13">constructors and the</text>
<text top="584" left="495" width="34" height="17" font="22">Model</text>
<text top="587" left="533" width="127" height="12" font="13">type; furthermore, the</text>
<text top="604" left="69" width="592" height="12" font="13">model completion uses record syntax which does not exist in Hazel. (b) uses the provided types correctly</text>
<text top="620" left="69" width="592" height="12" font="13">but hallucinates helper names. In (c) we see uses of appropriate helpers, but (mostly) incorrect guesses for</text>
<text top="633" left="68" width="40" height="17" font="22">Action</text>
<text top="636" left="112" width="448" height="12" font="13">constructors. (d) exploits the provided context to produce a fully correct solution.</text>
<text top="669" left="84" width="577" height="14" font="16">Similarly, error rounds on their own are ineffective on code consisting largely of hallucinated types</text>
<text top="687" left="69" width="593" height="14" font="16">and functions. But given the scaffolding effect of relevant static information, they act multiplicatively,</text>
<text top="705" left="69" width="592" height="14" font="16">increasing performance by a factor of 4 for types without headers, and a factor of 1.5 for both types</text>
<text top="723" left="69" width="592" height="14" font="16">and headers. Error rounds were particularly effective at transforming almost-correct completions</text>
<text top="741" left="69" width="202" height="14" font="16">to fully correct ones, as shown in</text>
<text top="741" left="275" width="56" height="14" font="17"><a href="output.html#17">Figure 10</a></text>
<text top="741" left="331" width="3" height="14" font="16"><a href="output.html#17">.</a></text>
<text top="759" left="84" width="577" height="14" font="16">One phenomenon of note was that sometimes even poor error messages proved effective; the</text>
<text top="777" left="69" width="46" height="14" font="16">error in</text>
<text top="777" left="118" width="55" height="14" font="17"><a href="output.html#17">Figure 11</a></text>
<text top="777" left="177" width="483" height="14" font="16">is an at-most partially accurate characterization of the syntax error, but knowing</text>
<text top="795" left="69" width="592" height="14" font="16">there was a syntax error proved sufficient for the model to correct it, perhaps due to the additional</text>
<text top="813" left="69" width="270" height="14" font="16">context provided in the Hazel Crash Course.</text>
<text top="831" left="84" width="578" height="14" font="16">The combination of types and headers performed well against the Vector Retrieval baseline,</text>
<text top="849" left="69" width="592" height="14" font="16">though it should be noted that this was disproportionately due to a single confounding chunk</text>
<text top="867" left="68" width="592" height="14" font="16">which was retrieved for each example, even though it is only relevant to the Todo application (see</text>
<text top="885" left="69" width="55" height="14" font="17"><a href="output.html#17">Figure 12</a></text>
<text top="885" left="124" width="536" height="14" font="16"><a href="output.html#17">). </a>We believe that, due to the fact that this chunk coincidentally includes the word symbol</text>
<text top="900" left="69" width="34" height="17" font="24">Model</text>
<text top="903" left="107" width="97" height="14" font="16">twice alongside</text>
<text top="900" left="208" width="40" height="17" font="24">Action</text>
<text top="903" left="248" width="187" height="14" font="16">, it is deemed relevant to each</text>
<text top="900" left="439" width="40" height="17" font="22">update</text>
<text top="903" left="484" width="177" height="14" font="16">sketch. The inclusion of this</text>
<text top="921" left="69" width="592" height="14" font="16">snippet often resulted in the language model attempting to implement a Todo application, or some</text>
<text top="938" left="69" width="592" height="14" font="16">hybrid thereof. We debated refining the chunking strategy to remove this confounder, but found it</text>
<text top="956" left="69" width="592" height="14" font="16">easy to inadvertently create similar scenarios; ultimately, it is a representative artefact of a process</text>
<text top="974" left="68" width="280" height="14" font="16">which is fundamentally non-scope-aware. See</text>
<text top="974" left="352" width="54" height="14" font="17"><a href="output.html#21">section 4</a></text>
<text top="974" left="410" width="135" height="14" font="16">for further discussion.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="17" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="30" size="13" family="KMHYXY+LinBiolinumTI" color="#000000"/>
<image top="127" left="69" width="591" height="262" src="output-17_1.png"/>
<image top="481" left="69" width="592" height="180" src="output-17_2.png"/>
<image top="754" left="258" width="213" height="148" src="output-17_3.png"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:17</text>
<text top="409" left="69" width="592" height="12" font="13">Fig. 10. Error rounds were generally very effective at correcting an almost-correct program. Here, the error</text>
<text top="425" left="69" width="286" height="12" font="13">round reply included a type inconsistency error on</text>
<text top="422" left="358" width="34" height="17" font="22">model</text>
<text top="425" left="395" width="187" height="12" font="13">and an unbound variable error in</text>
<text top="422" left="586" width="27" height="17" font="22">grid</text>
<text top="425" left="613" width="47" height="12" font="13">, both of</text>
<text top="442" left="68" width="232" height="12" font="13">which were corrected in the model’s reply</text>
<text top="682" left="69" width="312" height="12" font="13">Fig. 11. Here, a parse error (match/with used instead of</text>
<text top="678" left="384" width="27" height="17" font="22">case</text>
<text top="682" left="411" width="249" height="12" font="13">) was corrected, even though the Hazel error</text>
<text top="698" left="69" width="236" height="12" font="13">message in this case is somewhat unclear:</text>
<text top="698" left="308" width="256" height="13" font="30">“The parser has detected unmatched delimiters:</text>
<text top="694" left="570" width="13" height="17" font="22">=&gt;</text>
<text top="698" left="586" width="3" height="13" font="30">,</text>
<text top="694" left="594" width="13" height="17" font="22">=&gt;</text>
<text top="698" left="610" width="3" height="13" font="30">,</text>
<text top="694" left="619" width="13" height="17" font="22">=&gt;</text>
<text top="698" left="634" width="3" height="13" font="30">,</text>
<text top="694" left="643" width="13" height="17" font="22">=&gt;</text>
<text top="698" left="659" width="3" height="13" font="30">.</text>
<text top="714" left="69" width="93" height="13" font="30">The presence of a</text>
<text top="711" left="167" width="13" height="17" font="22">=&gt;</text>
<text top="714" left="186" width="167" height="13" font="30">in the list likely indicates that a</text>
<text top="711" left="357" width="13" height="17" font="22">-&gt;</text>
<text top="714" left="378" width="224" height="13" font="30">was mistakenly used in a case expression.”</text>
<text top="922" left="170" width="389" height="12" font="13">Fig. 12. A confounding snippet commonly retrieved by vector retrieval</text>
<text top="973" left="84" width="21" height="14" font="16">See</text>
<text top="973" left="108" width="56" height="14" font="17"><a href="output.html#18">Figure 13</a></text>
<text top="973" left="168" width="328" height="14" font="16">for additional examples of more atypical completions.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="18" position="absolute" top="0" left="0" height="1080" width="729">
<image top="127" left="69" width="591" height="195" src="output-18_1.png"/>
<image top="596" left="99" width="531" height="155" src="output-18_2.png"/>
<text top="93" left="69" width="30" height="11" font="12">288:18</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="342" left="69" width="592" height="12" font="13">Fig. 13. Some more exotic completions: (a) is an excerpt of a very long solution which, not having access to</text>
<text top="358" left="69" width="592" height="12" font="13">headers, almost successfully managed to re-implement the required logic in-line. In (b) we see an example of</text>
<text top="375" left="69" width="593" height="12" font="13">a completion containing explicit holes, likely due to their presence in our few-shot example sketches. In (c),</text>
<text top="391" left="69" width="541" height="12" font="13">the LLM somewhat quixotically suggests substituting a different emoji in lieu of the empty string.</text>
<text top="440" left="84" width="577" height="14" font="16">It is worth nothing that although the results for types + headers are similar to those for exhaustive</text>
<text top="458" left="69" width="592" height="14" font="16">retrieval, with exhaustive retrieval performing somewhat better, our experiments are not powerful</text>
<text top="476" left="69" width="592" height="14" font="16">enough to significantly distinguish between these cases, as the sizes of our programs are small</text>
<text top="494" left="69" width="592" height="14" font="16">enough that the context size delta is not reflective of real-world use cases. Specifically, the size of</text>
<text top="511" left="69" width="592" height="14" font="16">the retrieval context averaged 890 characters for our programs, whereas the exhaustive context</text>
<text top="529" left="69" width="592" height="14" font="16">averaged 1370 characters. As it stands the performance delta seems to compare positively to the</text>
<text top="547" left="69" width="527" height="14" font="16">context length (and hence cost) delta, but more data is needed to make this conclusive.</text>
<text top="770" left="120" width="489" height="12" font="13">Fig. 14. Hazel GPT-4: Time elapsed for guided completion (20 trials per, temperature 0.6)</text>
<text top="812" left="69" width="27" height="14" font="23">2.9.1</text>
<text top="812" left="110" width="178" height="14" font="23">Token and Time Performance.</text>
<text top="812" left="294" width="57" height="14" font="17"><a href="output.html#18">Figure 14</a></text>
<text top="812" left="354" width="306" height="14" font="16">shows the time taken in seconds for all trials. The</text>
<text top="830" left="69" width="592" height="14" font="16">time taken is dominated by the number of round trips through the API, with each round scaling in</text>
<text top="848" left="69" width="592" height="14" font="16">proportion to the sum of the length of the context and the length of the generation. Generally these</text>
<text top="866" left="69" width="592" height="14" font="16">times are too long for use in a practical completion setting; our intention is to determine a ceiling</text>
<text top="884" left="69" width="592" height="14" font="16">on current performance with respect to correctness rather than present a practical system. Note</text>
<text top="902" left="69" width="592" height="14" font="16">however that these times will likely decrease quickly with hardware and software advances. As of</text>
<text top="920" left="69" width="112" height="14" font="16">May 2024 GPT<a href="output.html#29">-4o[</a></text>
<text top="920" left="181" width="14" height="14" font="17"><a href="output.html#29">53</a></text>
<text top="920" left="194" width="466" height="14" font="16"><a href="output.html#29">] </a>performs on average twice as fast as the GPT-4-0613 model checkpoint used</text>
<text top="938" left="69" width="592" height="14" font="16">for our experiments. However, the long worst-case times for error rounds suggests that capping at</text>
<text top="955" left="69" width="592" height="14" font="16">a single correction round may be more practical, or motivate the use of summarization to reduce</text>
<text top="973" left="69" width="201" height="14" font="16">token count during error rounds.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="19" position="absolute" top="0" left="0" height="1080" width="729">
<image top="127" left="69" width="592" height="142" src="output-19_1.png"/>
<image top="446" left="139" width="451" height="109" src="output-19_2.png"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:19</text>
<text top="290" left="123" width="484" height="12" font="13">Fig. 15. Hazel GPT-4: Tokens used for guided completion (20 trials per, temperature 0.6)</text>
<text top="347" left="84" width="40" height="14" font="16">Figure</text>
<text top="347" left="127" width="58" height="14" font="17"><a href="output.html#19">Figure 15</a></text>
<text top="347" left="188" width="472" height="14" font="16">shows the total tokens used, both sent and received from the API. These are</text>
<text top="365" left="69" width="507" height="14" font="16">roughly proportional to the time taken, and precisely proportional to the total cost.</text>
<text top="401" left="69" width="27" height="14" font="15">2.10</text>
<text top="401" left="110" width="203" height="14" font="15">Hazel StarCoder2-15B Results</text>
<text top="576" left="122" width="485" height="12" font="13">Fig. 16. Hazel StarCoder2: Results for guided completion (20 trials per, temperature 0.6)</text>
<text top="627" left="84" width="577" height="14" font="16">To assess the effectiveness of static retrieval with smaller completion models, we conducted tests</text>
<text top="645" left="69" width="592" height="14" font="16">using StarCoder2-15B, a model small enough to be run locally on consumer hardware. The average</text>
<text top="663" left="69" width="368" height="14" font="16">percentage of tests passed, shown in the rightmost column of</text>
<text top="663" left="440" width="55" height="14" font="17"><a href="output.html#19">Figure 16</a></text>
<text top="663" left="496" width="165" height="14" font="16"><a href="output.html#19">, </a>exhibits a consistent trend</text>
<text top="681" left="68" width="592" height="14" font="16">with the GPT-4 results. In the absence of any type or header information, StarCoder2 performed</text>
<text top="699" left="69" width="594" height="14" font="16">poorly. The addition of type information drastically improves performance, increasing the percent-</text>
<text top="717" left="69" width="592" height="14" font="16">age of correct solutions by an order of magnitude. Furthermore, incorporating headers leads to an</text>
<text top="735" left="69" width="292" height="14" font="16">additional 50% increase in relative performance.</text>
<text top="753" left="84" width="149" height="14" font="16">However, two examples,</text>
<text top="753" left="236" width="21" height="14" font="19">BO</text>
<text top="753" left="261" width="23" height="14" font="16">and</text>
<text top="753" left="287" width="21" height="14" font="19">TO</text>
<text top="753" left="307" width="353" height="14" font="16">, experienced degraded performance after the inclusion of</text>
<text top="771" left="69" width="592" height="14" font="16">headers. After close examination of the headers and the output programs, we discovered that the</text>
<text top="789" left="69" width="592" height="14" font="16">completions tending to use type-appropriate but in-fact irrelevant retrieved headers. We hypothesize</text>
<text top="807" left="69" width="592" height="14" font="16">that smaller completion models, such as StarCoder2, are more sensitive to code that appears near the</text>
<text top="825" left="69" width="594" height="14" font="16">end of the context window, making them more susceptible to the influence of irrelevant information.</text>
<text top="843" left="68" width="433" height="14" font="16">We touch on this failure mode again when we consider related work in</text>
<text top="843" left="505" width="54" height="14" font="17"><a href="output.html#23">section 6</a></text>
<text top="843" left="559" width="3" height="14" font="16"><a href="output.html#23">.</a></text>
<text top="861" left="84" width="577" height="14" font="16">Vector retrieval baseline performance was significantly worse (in absolute and relative terms)</text>
<text top="878" left="69" width="592" height="14" font="16">than with the larger model. We conjecture that this is due to a heightened sensitivity to erroneous</text>
<text top="896" left="69" width="308" height="14" font="16">syntax in the prompt created by chunk truncation.</text>
<text top="932" left="69" width="8" height="14" font="15">3</text>
<text top="932" left="91" width="198" height="14" font="15">Static Retrieval in TypeScript</text>
<text top="954" left="68" width="592" height="14" font="16">To confirm that the above results are not an artefact of using a low-resource language, we also</text>
<text top="972" left="69" width="296" height="14" font="16">experimented with static retrieval in TypeScript.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="20" position="absolute" top="0" left="0" height="1080" width="729">
<image top="274" left="152" width="425" height="99" src="output-20_1.png"/>
<text top="93" left="69" width="30" height="11" font="12">288:20</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="132" left="69" width="19" height="14" font="15">3.1</text>
<text top="132" left="103" width="168" height="14" font="15">TypeScript Methodology</text>
<text top="154" left="69" width="593" height="14" font="16">Our methodology roughly follows the Hazel experiments. As TypeScript is a high resource language,</text>
<text top="172" left="68" width="592" height="14" font="16">well-represented in training sets, we did not need to provide a syntax crash course as we did for</text>
<text top="190" left="69" width="592" height="14" font="16">Hazel. TypeScript lacks the explicit support for typed holes and thus a convenient way to extract</text>
<text top="208" left="69" width="536" height="14" font="16">semantic information. We emulated typed holes using a previously established approach <a href="output.html#27">[</a></text>
<text top="208" left="605" width="14" height="14" font="17"><a href="output.html#27">14</a></text>
<text top="208" left="619" width="41" height="14" font="16"><a href="output.html#27">] </a>using</text>
<text top="226" left="69" width="114" height="14" font="16">generic functions <a href="output.html#20">(</a></text>
<text top="226" left="183" width="56" height="14" font="17"><a href="output.html#20">Figure 17</a></text>
<text top="226" left="239" width="8" height="14" font="16"><a href="output.html#20">).</a></text>
<text top="394" left="192" width="345" height="12" font="13">Fig. 17. Hovering over a simulated program hole in TypeScript</text>
<text top="446" left="84" width="357" height="14" font="16">Specifically, we prefix the sketch file with the declaration:</text>
<text top="444" left="444" width="47" height="17" font="22">declare</text>
<text top="447" left="498" width="54" height="11" font="21"><b>function</b></text>
<text top="444" left="559" width="61" height="17" font="22">_&lt;T&gt;(): T</text>
<text top="446" left="619" width="43" height="14" font="16">. Then,</text>
<text top="464" left="68" width="423" height="14" font="16">we represent a program hole as an application of that generic function:</text>
<text top="462" left="496" width="20" height="17" font="22">_()</text>
<text top="464" left="520" width="141" height="14" font="16">. Calling the TypeScript</text>
<text top="482" left="69" width="592" height="14" font="16">language server’s hover method on the hole gives us a corresponding type signature. It should be</text>
<text top="500" left="69" width="592" height="14" font="16">noted that this method of emulating typed holes is not fully general. While it works consistently</text>
<text top="518" left="69" width="592" height="14" font="16">for holes replacing the bodies of function definitions, it fails in some syntactic positions, including</text>
<text top="536" left="69" width="198" height="14" font="16">as an operand of infix operators.</text>
<text top="554" left="84" width="577" height="14" font="16">Static retrieval of type definitions is performed via the TypeScript language server. In particular</text>
<text top="572" left="68" width="192" height="14" font="16">we use coordinated calls to the</text>
<text top="572" left="265" width="130" height="14" font="18">Go to Type Definition</text>
<text top="572" left="398" width="23" height="14" font="16">and</text>
<text top="572" left="425" width="36" height="14" font="18">Hover</text>
<text top="572" left="466" width="195" height="14" font="16">methods to recursively retrieve</text>
<text top="590" left="69" width="243" height="14" font="16">relevant types from the source lexically.</text>
<text top="607" left="84" width="577" height="14" font="16">There does not appear to be any direct way of retrieving a typing context given a lexical</text>
<text top="625" left="69" width="592" height="14" font="16">location, or even a complete list of variables in scope using the TypeScript language server. We</text>
<text top="643" left="69" width="592" height="14" font="16">experimented with different methods to retrieve relevant headers, including scanning the repository</text>
<text top="661" left="69" width="592" height="14" font="16">using CodeQL, but were did not find a fully satisfactory general approach. Rather than incurring</text>
<text top="679" left="69" width="592" height="14" font="16">the engineering cost of a compiler-level intervention, we simulated the retrieval of relevant headers</text>
<text top="697" left="69" width="592" height="14" font="16">manually, emulating the same methodology as the Hazel Language Server. As such, our TypeScript</text>
<text top="715" left="69" width="592" height="14" font="16">implementation should be considered a rough proof-of-concept; our experience here motivated our</text>
<text top="733" left="69" width="230" height="14" font="16">prospective LSP extension outlined in</text>
<text top="733" left="303" width="54" height="14" font="17"><a href="output.html#22">section 5</a></text>
<text top="733" left="357" width="3" height="14" font="16"><a href="output.html#22">.</a></text>
<text top="751" left="84" width="476" height="14" font="16">We used the TypeScript compiler to collate static errors for correction rounds.</text>
<text top="769" left="84" width="417" height="14" font="16">Adapting MVUBench to TypeScript was done with the aid of Claude <a href="output.html#26">[</a></text>
<text top="769" left="501" width="7" height="14" font="17"><a href="output.html#26">4</a></text>
<text top="769" left="508" width="152" height="14" font="16"><a href="output.html#26">], </a>an LLM chat agent (See</text>
<text top="787" left="69" width="53" height="14" font="17"><a href="output.html#26">section 9</a></text>
<text top="787" left="125" width="535" height="14" font="16">for more about our supporting LLM usage). Transliterated code was manually adjusted to</text>
<text top="805" left="69" width="593" height="14" font="16">establish basic conformance to TypeScript idioms, for example adding elements to array at the end,</text>
<text top="823" left="68" width="592" height="14" font="16">versus at the start is standard for linked lists in functional languages like Hazel. Our experience</text>
<text top="841" left="69" width="548" height="14" font="16">here suggests that MVUBench can be ported with relative ease to other similar languages.</text>
<text top="878" left="69" width="19" height="14" font="15">3.2</text>
<text top="878" left="103" width="171" height="14" font="15">TypeScript GPT-4 Results</text>
<text top="900" left="69" width="235" height="14" font="16">In broad strokes the TypeScript results <a href="output.html#21">(</a></text>
<text top="900" left="304" width="55" height="14" font="17"><a href="output.html#21">Figure 18</a></text>
<text top="900" left="359" width="302" height="14" font="16"><a href="output.html#21">) </a>are similar to the Hazel results. We see, somewhat</text>
<text top="918" left="69" width="592" height="14" font="16">unsurprisingly, that a higher-resource language, well represented in the training set, achieves better</text>
<text top="936" left="69" width="592" height="14" font="16">overall completions from the language model. Unlike with Hazel, some trials passed some tests</text>
<text top="954" left="69" width="592" height="14" font="16">even with no type information provided. With type definitions included, the TypeScript results are</text>
<text top="972" left="69" width="177" height="14" font="16">flatter than the Hazel results.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="21" position="absolute" top="0" left="0" height="1080" width="729">
<image top="127" left="88" width="553" height="157" src="output-21_1.png"/>
<image top="598" left="139" width="451" height="110" src="output-21_2.png"/>
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:21</text>
<text top="304" left="123" width="484" height="12" font="13">Fig. 18. TypeScript GPT-4: Results for guided completion (20 trials per, temperature 0.6)</text>
<text top="357" left="84" width="577" height="14" font="16">The ratio of tests passed with-versus-without headers is 3 for Hazel, and 1.5 for TypeScript. From</text>
<text top="375" left="69" width="592" height="14" font="16">examining the generated completions, we see that the model, when not provided with relevant</text>
<text top="393" left="69" width="594" height="14" font="16">headers, is significantly more able to produce equivalent working logic inline than it was in Hazel.</text>
<text top="411" left="84" width="577" height="14" font="16">The TypeScript performance proved less dependent on error rounds. In Hazel, the ratio of tests</text>
<text top="429" left="69" width="593" height="14" font="16">passing with-versus-without error rounds was about 2, whereas for TypeScript it is about 1.2. Again,</text>
<text top="447" left="69" width="592" height="14" font="16">this is likely due to the fact that the model is far more familiar with TypeScript syntax, and unlikely</text>
<text top="465" left="69" width="592" height="14" font="16">to make the kind of syntax errors which the error rounds were vital for correcting in the Hazel</text>
<text top="482" left="69" width="73" height="14" font="16">experiment.</text>
<text top="500" left="84" width="579" height="14" font="16">Performance relative to the exhaustive and vector retrieval baselines, including the high per-</text>
<text top="518" left="69" width="451" height="14" font="16">example variance of the latter, are relatively in line with the Hazel results.</text>
<text top="553" left="69" width="19" height="14" font="15">3.3</text>
<text top="553" left="103" width="237" height="14" font="15">TypeScript StarCoder2-15B Results</text>
<text top="728" left="108" width="512" height="12" font="13">Fig. 19. TypeScript StarCoder2: Results for guided completion (20 trials per, temperature 0.6)</text>
<text top="773" left="84" width="225" height="14" font="16">The TypeScript StarCoder2 results <a href="output.html#21">(</a></text>
<text top="773" left="309" width="58" height="14" font="17"><a href="output.html#21">Figure 19</a></text>
<text top="773" left="367" width="293" height="14" font="16"><a href="output.html#21">) </a>appear roughly in line with the Hazel results</text>
<text top="791" left="69" width="308" height="14" font="16">modulo the considerations of the previous section.</text>
<text top="825" left="69" width="8" height="14" font="15">4</text>
<text top="825" left="91" width="125" height="14" font="15">Threats to Validity</text>
<text top="847" left="68" width="592" height="14" font="16">The improvement seen from the inclusion of relevant function headers is highly contingent on</text>
<text top="865" left="69" width="592" height="14" font="16">the fact that many relevant functions have already been implemented. While we believe that this</text>
<text top="883" left="69" width="592" height="14" font="16">approximates a common case in programming practice for which naive contextualization strategies</text>
<text top="901" left="69" width="592" height="14" font="16">fail, validating this claim would require larger-scale study, using at-scale programs which are more</text>
<text top="919" left="69" width="111" height="14" font="16">neutrally selected.</text>
<text top="937" left="84" width="577" height="14" font="16">More broadly, MVUBench is not (and is not meant to) be representative of all coding tasks, but</text>
<text top="955" left="69" width="592" height="14" font="16">rather to present a challenge to contemporary techniques and help evaluate approaches to semantic</text>
<text top="973" left="69" width="368" height="14" font="16">contextualization (e.g. vector retrieval, which we evaluate in</text>
<text top="973" left="440" width="117" height="14" font="17"><a href="output.html#15">subsubsection 2.8.5</a></text>
<text top="973" left="557" width="8" height="14" font="16"><a href="output.html#15">).</a></text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="22" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="30" height="11" font="12">288:22</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="131" left="84" width="577" height="14" font="16">Our TypeScript MVUBench is a very close translation of the Hazel code; although the MVU</text>
<text top="149" left="69" width="271" height="14" font="16">paradigm is in use in the TypeScript world <a href="output.html#26">[</a></text>
<text top="149" left="340" width="7" height="14" font="17"><a href="output.html#26">8</a></text>
<text top="149" left="347" width="313" height="14" font="16"><a href="output.html#26">], </a>there is a question as to the applicability of these</text>
<text top="167" left="69" width="383" height="14" font="16">methods to a broader range of TypeScript programming styles.</text>
<text top="185" left="84" width="577" height="14" font="16">The appropriateness of our baselines is arguable. This is an idealized setup in which the baseline</text>
<text top="203" left="69" width="592" height="14" font="16">case is to provide no information beyond the function header; it is unsurprising that adding related</text>
<text top="221" left="69" width="592" height="14" font="16">context drastically improves the result. In many real cases the cursor window would contain a</text>
<text top="239" left="69" width="592" height="14" font="16">large amount of relevant code. We have chosen here to focus on the situation where the window</text>
<text top="257" left="69" width="592" height="14" font="16">does not contain much relevant code, but it remains to validate the relative rate of occurrence of</text>
<text top="275" left="69" width="165" height="14" font="16">these scenarios in the wild.</text>
<text top="293" left="84" width="579" height="14" font="16">Our RAG baseline is relatively simplistic, and practical implementations are increasingly inte-</text>
<text top="311" left="69" width="592" height="14" font="16">grating more sophisticated methods which may more closely approximate static retrieval. The fact</text>
<text top="329" left="69" width="592" height="14" font="16">that we compensated for the small size of our examples by creating a conjoined codebase to create</text>
<text top="347" left="69" width="594" height="14" font="16">our embedding vector database may not be adequately representative of a real large-scale codebase.</text>
<text top="389" left="69" width="8" height="14" font="15">5</text>
<text top="389" left="91" width="58" height="14" font="15">ChatLSP</text>
<text top="412" left="69" width="594" height="14" font="16">Here we sketch a conservative extension to the Language Server Protocol to support static con-</text>
<text top="430" left="69" width="592" height="14" font="16">textualization, motivated in part the awkwardness of implementing static contextualization in</text>
<text top="448" left="68" width="592" height="14" font="16">TypeScript using its existing language server. The interface differs somewhat from the API we</text>
<text top="466" left="69" width="154" height="14" font="16">sketched incrementally in</text>
<text top="466" left="226" width="53" height="14" font="17"><a href="output.html#6">section 2</a></text>
<text top="466" left="279" width="381" height="14" font="16"><a href="output.html#6">, </a>as the LSP is presentation-centric, operating in terms of strings</text>
<text top="484" left="69" width="406" height="14" font="16">and affordances rather than language-specific semantic data types.</text>
<text top="501" left="84" width="436" height="14" font="16">Immediately following, we will sketch how one might implement this</text>
<text top="502" left="524" width="52" height="14" font="18">ChatLSP</text>
<text top="501" left="581" width="79" height="14" font="16">API in terms</text>
<text top="519" left="69" width="38" height="14" font="16">of our</text>
<text top="519" left="110" width="145" height="14" font="18">Static Contextualization</text>
<text top="519" left="259" width="401" height="14" font="16">API, the latter serving more as an internal interface for language</text>
<text top="537" left="69" width="128" height="14" font="16">server implementers.</text>
<text top="580" left="69" width="19" height="14" font="15">5.1</text>
<text top="580" left="103" width="150" height="14" font="15">ChatLSP API Methods</text>
<text top="607" left="84" width="16" height="14" font="16">(1)</text>
<text top="607" left="105" width="66" height="14" font="19">aiTutorial</text>
<text top="607" left="172" width="489" height="14" font="16">: A constant (lexical-context-independent) method for low resource languages (like</text>
<text top="625" left="105" width="555" height="14" font="16">Hazel) to specify a textual tutorial intended for LLMs having robust support for in-context</text>
<text top="643" left="105" width="555" height="14" font="16">learning. For high resource languages, the default implementation will simply return a string</text>
<text top="661" left="105" width="199" height="14" font="16">stating which language is in use.</text>
<text top="679" left="84" width="16" height="14" font="16">(2)</text>
<text top="678" left="105" width="93" height="14" font="19">expectedType</text>
<text top="679" left="199" width="437" height="14" font="16">: Returns a string specifying the expected type at the cursor, if available</text>
<text top="697" left="84" width="16" height="14" font="16">(3)</text>
<text top="696" left="105" width="152" height="14" font="19">retrieveRelevantTypes</text>
<text top="697" left="258" width="403" height="14" font="16">: Returns a string containing type definitions that may be relevant</text>
<text top="715" left="105" width="130" height="14" font="16">at the cursor location</text>
<text top="732" left="84" width="16" height="14" font="16">(4)</text>
<text top="732" left="105" width="166" height="14" font="19">retrieveRelevantHeaders</text>
<text top="732" left="271" width="389" height="14" font="16">: Returns a string containing headers that may be relevant at the</text>
<text top="750" left="105" width="92" height="14" font="16">cursor location</text>
<text top="768" left="84" width="16" height="14" font="16">(5)</text>
<text top="768" left="105" width="83" height="14" font="19">errorReport</text>
<text top="768" left="188" width="472" height="14" font="16">: Returns an error report that can be used to determine if an error round is</text>
<text top="786" left="105" width="417" height="14" font="16">needed, and if so, how the feedback should be presented to the LLM.</text>
<text top="824" left="84" width="577" height="14" font="16">This API gives leeway to the language server to decide how to implement these commands. For a</text>
<text top="842" left="69" width="594" height="14" font="16">language with a rich static analyzer, e.g. GHC (Haskell) with its support for hole-oriented program-</text>
<text top="860" left="69" width="566" height="14" font="16">ming and existing functionality to retrieve relevant headers (e.g. see the work of <a href="output.html#27">Gissurarson[</a></text>
<text top="860" left="635" width="14" height="14" font="17"><a href="output.html#27">26</a></text>
<text top="860" left="649" width="13" height="14" font="16"><a href="output.html#27">]),</a></text>
<text top="877" left="69" width="529" height="14" font="16">it should be very straightforward to implement these five ChatLSP-specific commands.</text>
<text top="895" left="84" width="381" height="14" font="16">To sketch the language server side of this interface, we collect the</text>
<text top="895" left="468" width="52" height="14" font="17"><a href="output.html#6">section 2</a></text>
<text top="895" left="522" width="138" height="14" font="16">static contextualization</text>
<text top="913" left="68" width="332" height="14" font="16">API below. First, we define the following types aliases:</text>
<text top="951" left="92" width="7" height="13" font="26">•</text>
<text top="952" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="948" left="136" width="40" height="17" font="25">Header</text>
<text top="948" left="180" width="7" height="17" font="22">=</text>
<text top="948" left="191" width="81" height="17" font="24">(Name, Type)</text>
<text top="969" left="92" width="7" height="13" font="26">•</text>
<text top="970" left="105" width="27" height="11" font="21"><b>type</b></text>
<text top="966" left="136" width="47" height="17" font="25">Context</text>
<text top="966" left="187" width="7" height="17" font="22">=</text>
<text top="966" left="197" width="54" height="17" font="24">[Header]</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="23" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:23</text>
<text top="132" left="69" width="19" height="14" font="15">5.2</text>
<text top="132" left="103" width="310" height="14" font="15">Static Contextualization Language Server API</text>
<text top="154" left="92" width="7" height="13" font="26">•</text>
<text top="152" left="105" width="108" height="17" font="22">getExpectedType:</text>
<text top="152" left="217" width="229" height="17" font="24">(Program, LexicalLocation) -&gt; Type</text>
<text top="172" left="92" width="7" height="13" font="26">•</text>
<text top="170" left="105" width="114" height="17" font="22">getTypingContext:</text>
<text top="170" left="223" width="249" height="17" font="24">(Program, LexicalLocation) -&gt; Context</text>
<text top="190" left="92" width="7" height="13" font="26">•</text>
<text top="187" left="105" width="101" height="17" font="22">extractAliases:</text>
<text top="187" left="210" width="128" height="17" font="24">Type -&gt; [TypeAlias]</text>
<text top="208" left="92" width="7" height="13" font="26">•</text>
<text top="205" left="105" width="121" height="17" font="22">getTypeDefinition:</text>
<text top="205" left="230" width="114" height="17" font="24">TypeAlias -&gt; Type</text>
<text top="226" left="92" width="7" height="13" font="26">•</text>
<text top="223" left="105" width="101" height="17" font="22">getTargetTypes:</text>
<text top="223" left="210" width="94" height="17" font="24">Type -&gt; [Type]</text>
<text top="243" left="92" width="7" height="13" font="26">•</text>
<text top="241" left="105" width="94" height="17" font="22">filterContext:</text>
<text top="241" left="203" width="161" height="17" font="24">Context, Type -&gt; Context</text>
<text top="261" left="92" width="7" height="13" font="26">•</text>
<text top="259" left="105" width="74" height="17" font="22">scoreEntry:</text>
<text top="259" left="183" width="101" height="17" font="24">Header -&gt; Float</text>
<text top="279" left="92" width="7" height="13" font="26">•</text>
<text top="277" left="105" width="108" height="17" font="22">getStaticErrors:</text>
<text top="277" left="217" width="161" height="17" font="24">Program -&gt; [StaticError]</text>
<text top="306" left="84" width="340" height="14" font="16">ChatLSP API methods (2) and (5) correspond directly to</text>
<text top="304" left="427" width="101" height="17" font="22">getExpectedType</text>
<text top="306" left="532" width="23" height="14" font="16">and</text>
<text top="304" left="558" width="101" height="17" font="22">getStaticErrors</text>
<text top="306" left="659" width="3" height="14" font="16">.</text>
<text top="324" left="68" width="592" height="14" font="16">The following pseudocode outlines how methods (3) and (4) could be implemented using the Static</text>
<text top="342" left="69" width="245" height="14" font="16">Contextualization Language Server API:</text>
<text top="366" left="74" width="167" height="17" font="22">retrieveRelevantTypes</text>
<text top="369" left="253" width="3" height="13" font="3">:</text>
<text top="366" left="268" width="30" height="17" font="22">Type</text>
<text top="369" left="304" width="14" height="12" font="5">→</text>
<text top="366" left="324" width="47" height="17" font="22">[Type]</text>
<text top="382" left="74" width="345" height="17" font="22">retrieveRelevantTypes t = concatMap (\ alias</text>
<text top="386" left="425" width="14" height="12" font="5">→</text>
<text top="403" left="90" width="22" height="11" font="21"><b>let</b></text>
<text top="399" left="122" width="232" height="17" font="22">def = getTypeDefinition alias</text>
<text top="419" left="90" width="14" height="11" font="21"><b>in</b></text>
<text top="415" left="114" width="370" height="17" font="22">def : getRelevantTypes def) ( extractAliases t)</text>
<text top="448" left="74" width="183" height="17" font="22">retrieveRelevantHeaders</text>
<text top="451" left="269" width="3" height="13" font="3">:</text>
<text top="448" left="284" width="30" height="17" font="22">Type</text>
<text top="451" left="320" width="14" height="12" font="5">→</text>
<text top="448" left="340" width="54" height="17" font="22">Context</text>
<text top="451" left="401" width="14" height="12" font="5">→</text>
<text top="448" left="421" width="63" height="17" font="22">[ Header ]</text>
<text top="465" left="74" width="280" height="17" font="22">retrieveRelevantHeaders t context =</text>
<text top="485" left="90" width="22" height="11" font="21"><b>let</b></text>
<text top="481" left="123" width="313" height="17" font="22">relevantTypes = retrieveRelevantTypes t</text>
<text top="497" left="123" width="522" height="17" font="22">filteredHeaders = concatMap ( filterContext context ) relevantTypes</text>
<text top="514" left="123" width="393" height="17" font="22">sortedHeaders = sortBy scoreEntry filteredHeaders</text>
<text top="534" left="98" width="14" height="11" font="21"><b>in</b></text>
<text top="530" left="122" width="232" height="17" font="22">take NUMHEADERS sortedHeaders</text>
<text top="563" left="74" width="386" height="17" font="20">-- Usage ( given a Program and a LexicalLocation )</text>
<text top="580" left="74" width="515" height="17" font="22">retrieveRelevantTypes ( getExpectedType (Program , LexicalLocation ))</text>
<text top="596" left="74" width="328" height="17" font="22">relevantHeaders = retrieveRelevantHeaders</text>
<text top="613" left="90" width="330" height="17" font="22">( getExpectedType Program LexicalLocation )</text>
<text top="629" left="90" width="338" height="17" font="22">( getTypingContext Program LexicalLocation )</text>
<text top="681" left="69" width="8" height="14" font="15">6</text>
<text top="681" left="91" width="91" height="14" font="15">Related work</text>
<text top="703" left="68" width="592" height="14" font="16">The introduction covered the broader literature on LLMs for code, so we focus here specifically on</text>
<text top="721" left="69" width="522" height="14" font="16">other methods for semantic contextualization of LLM-based code generation systems.</text>
<text top="739" left="84" width="577" height="14" font="16">Error correction using instruction-tuned models is a widespread technique and not itself a novel</text>
<text top="757" left="69" width="592" height="14" font="16">contribution of this paper, e.g. much work on program repair with LLMs is fundamentally rooted</text>
<text top="775" left="69" width="78" height="14" font="16">in this idea <a href="output.html#28">[</a></text>
<text top="775" left="146" width="14" height="14" font="17"><a href="output.html#28">33</a></text>
<text top="775" left="160" width="3" height="14" font="16"><a href="output.html#28">,</a></text>
<text top="775" left="167" width="14" height="14" font="17"><a href="output.html#29">63</a></text>
<text top="775" left="181" width="479" height="14" font="16"><a href="output.html#29">]. </a>The contribution of this paper is the observation that error looping alone is</text>
<text top="792" left="69" width="592" height="14" font="16">not sufficient in a context-poor setting, and that error looping together with contextualization is</text>
<text top="810" left="69" width="492" height="14" font="16">the most effective technique, particularly for a low-resource language like Hazel.</text>
<text top="828" left="84" width="577" height="14" font="16">The observation that LLMs perform poorly when they lack repository-level context has been</text>
<text top="846" left="69" width="592" height="14" font="16">made in a number of recent papers, which have approached it in a variety of ways. We discussed</text>
<text top="864" left="69" width="235" height="14" font="16">the benchmarks used in these papers in</text>
<text top="864" left="307" width="114" height="14" font="17"><a href="output.html#4">subsubsection 1.1.2</a></text>
<text top="864" left="425" width="237" height="14" font="16">so we do not repeat the discussion here.</text>
<text top="882" left="84" width="75" height="14" font="16">RepoCoder <a href="output.html#30">[</a></text>
<text top="882" left="159" width="14" height="14" font="17"><a href="output.html#30">83</a></text>
<text top="882" left="173" width="488" height="14" font="16"><a href="output.html#30">] </a>uses vector retrieval to contextualize Python code. Our experiments demonstrate</text>
<text top="900" left="69" width="538" height="14" font="16">that vector retrieval is sensitive to semantic confounds easily handled by static retrieval.</text>
<text top="918" left="84" width="213" height="14" font="16">The Repo-Level Prompt Generator <a href="output.html#30">[</a></text>
<text top="918" left="296" width="14" height="14" font="17"><a href="output.html#30">67</a></text>
<text top="918" left="310" width="350" height="14" font="16"><a href="output.html#30">] </a>uses machine learning to decide how to construct a useful</text>
<text top="936" left="69" width="592" height="14" font="16">prompt, drawing information from coarse-grained static information like imports and parent-child</text>
<text top="954" left="69" width="592" height="14" font="16">relationships between classes. Even this level of contextualization showed substantial promise</text>
<text top="972" left="69" width="124" height="14" font="16">relative to baselines.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="24" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="30" height="11" font="12">288:24</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="131" left="84" width="61" height="14" font="16">Pei et al. <a href="output.html#29">[</a></text>
<text top="131" left="144" width="14" height="14" font="17"><a href="output.html#29">60</a></text>
<text top="131" left="158" width="502" height="14" font="16"><a href="output.html#29">] </a>tackle the difficult problem of contextualizing Python function calls using a static</text>
<text top="149" left="69" width="594" height="14" font="16">analyzer from Python, which can provide function implementations and function usage examples.</text>
<text top="167" left="68" width="592" height="14" font="16">Again, even this level of contextualization is quite helpful. Our focus here was on gradually typed</text>
<text top="185" left="69" width="592" height="14" font="16">languages, and we did not include function implementations or usage examples, suggesting potential</text>
<text top="203" left="69" width="76" height="14" font="16">future work.</text>
<text top="221" left="84" width="68" height="14" font="16">CodeTrek <a href="output.html#29">[</a></text>
<text top="221" left="151" width="14" height="14" font="17"><a href="output.html#29">58</a></text>
<text top="221" left="165" width="495" height="14" font="16"><a href="output.html#29">] </a>also uses program analyses, generated from task- and error-relevant queries and</text>
<text top="239" left="69" width="594" height="14" font="16">expressed in CodeQL, to generate semantic contextualization for program repair tasks in Python.</text>
<text top="257" left="68" width="592" height="14" font="16">This too was quite effective and suggests that richer static analyses might be of interest in particular</text>
<text top="275" left="69" width="593" height="14" font="16">settings. For hole filling, however, it may be that lightweight static methods, like type checking,</text>
<text top="293" left="69" width="564" height="14" font="16">are more efficient. However, we look forward to future direct comparisons of these methods.</text>
<text top="311" left="84" width="58" height="14" font="16">Li et al. <a href="output.html#28">[</a></text>
<text top="311" left="142" width="14" height="14" font="17"><a href="output.html#28">38</a></text>
<text top="311" left="155" width="505" height="14" font="16"><a href="output.html#28">] </a>also identify the semantic contextualization problem and propose IDECoder, a</text>
<text top="329" left="69" width="592" height="14" font="16">system that uses the static information tracked by an IDE or language server to contextualize LLM</text>
<text top="347" left="69" width="592" height="14" font="16">code completion. This is an outline of early experiments in this direction which have not yet been</text>
<text top="365" left="69" width="592" height="14" font="16">fully evaluated, but we agree with the thrusts of the argument made here and look forward to</text>
<text top="383" left="69" width="384" height="14" font="16">additional experimentation in this direction by the community.</text>
<text top="400" left="84" width="72" height="14" font="16">CoCoMIC <a href="output.html#27">[</a></text>
<text top="400" left="156" width="14" height="14" font="17"><a href="output.html#27">19</a></text>
<text top="400" left="170" width="493" height="14" font="16"><a href="output.html#27">] </a>is a framework that learns in-file and cross-file context jointly atop an LLM.</text>
<text top="418" left="68" width="592" height="14" font="16">This differs from our approach in that it deploys a learning step to decide which cross-file context</text>
<text top="436" left="69" width="592" height="14" font="16">to attend to, which may be subject to similar issues as vector retrieval approaches when given</text>
<text top="454" left="69" width="592" height="14" font="16">confounding contexts. However, this represents a fascinating future direction when combined with</text>
<text top="472" left="69" width="560" height="14" font="16">static retrieval, which can often lead to too much information to include in a token window.</text>
<text top="490" left="84" width="176" height="14" font="16">In a similar vein, RLCoder <a href="output.html#30">[</a></text>
<text top="490" left="260" width="14" height="14" font="17"><a href="output.html#30">76</a></text>
<text top="490" left="274" width="387" height="14" font="16"><a href="output.html#30">] </a>uses reinforcement learning to rank retrieved code snippets</text>
<text top="508" left="69" width="592" height="14" font="16">for repository-level code completion. Seemingly uniquely, they do not simply return the top k</text>
<text top="526" left="69" width="592" height="14" font="16">candidates, but impose a stop threshold, which may result in no candidates being added to the</text>
<text top="544" left="69" width="592" height="14" font="16">prompt if they are deemed of negative worth. Our StarCoder results suggest smaller models are</text>
<text top="562" left="69" width="594" height="14" font="16">especially sensitive to plausible but irrelevant inclusions, further supporting this line of investigation.</text>
<text top="580" left="68" width="594" height="14" font="16">A similar RL-based approach using statically derived candidates seems a promising future direction.</text>
<text top="598" left="84" width="102" height="14" font="16">Dehallucinator <a href="output.html#27">[</a></text>
<text top="598" left="186" width="14" height="14" font="17"><a href="output.html#27">22</a></text>
<text top="598" left="200" width="460" height="14" font="16"><a href="output.html#27">] </a>is an approach that performs semantic lookup after an initial generation</text>
<text top="616" left="69" width="592" height="14" font="16">phase to lookup potentially relevant definitions that were invalid, e.g. not in scope. This is a</text>
<text top="634" left="69" width="592" height="14" font="16">more sophisticated form of error correction and could be combined with the kind of proactive</text>
<text top="652" left="69" width="238" height="14" font="16">contextualization that we’ve described.</text>
<text top="669" left="84" width="98" height="14" font="16">Agrawal et al. <a href="output.html#26">[</a></text>
<text top="669" left="182" width="7" height="14" font="17"><a href="output.html#26">2</a></text>
<text top="669" left="189" width="107" height="14" font="16"><a href="output.html#26">] </a>and Wei et al. <a href="output.html#30">[</a></text>
<text top="669" left="296" width="14" height="14" font="17"><a href="output.html#30">77</a></text>
<text top="669" left="310" width="351" height="14" font="16"><a href="output.html#30">] </a>propose an approach that modifies token sampling by</text>
<text top="687" left="69" width="592" height="14" font="16">leveraging the semantic code completion systems already available in modern IDEs, which implicitly</text>
<text top="705" left="69" width="592" height="14" font="16">provide some context. One issue with this approach is that they can only sample from tokens that</text>
<text top="723" left="69" width="592" height="14" font="16">the model has assigned some baseline level of probability, but without semantic context this may</text>
<text top="741" left="69" width="592" height="14" font="16">not be the case. There is likely substantial room for future work in combining static retrieval with</text>
<text top="759" left="69" width="592" height="14" font="16">this sort of structure-guided sampling, and perhaps with providing more fine-grained retrieval at</text>
<text top="777" left="69" width="370" height="14" font="16">each token rather than once at the onset of code completion.</text>
<text top="795" left="84" width="64" height="14" font="16">Zan et al. <a href="output.html#30">[</a></text>
<text top="795" left="147" width="14" height="14" font="17"><a href="output.html#30">82</a></text>
<text top="795" left="161" width="499" height="14" font="16"><a href="output.html#30">] </a>retrieves potentially relevant code from API documentation, then further proposes</text>
<text top="813" left="69" width="593" height="14" font="16">a continuous training approach to incorporate this information into the model weights. In contrast,</text>
<text top="831" left="69" width="592" height="14" font="16">our approach is focused on black-box pre-trained models. In the future, incorporating commonly</text>
<text top="849" left="69" width="592" height="14" font="16">used private APIs into a continuous training loop would improve token efficiency, leaving more</text>
<text top="867" left="69" width="285" height="14" font="16">room in the context for truly novel definitions.</text>
<text top="885" left="84" width="82" height="14" font="16">Zhang et al. <a href="output.html#31">[</a></text>
<text top="885" left="165" width="14" height="14" font="17"><a href="output.html#31">86</a></text>
<text top="885" left="179" width="481" height="14" font="16"><a href="output.html#31">] </a>builds a prompt context for program repair by retrieving class signatures and</text>
<text top="903" left="69" width="592" height="14" font="16">method implementations based on model-extracted keywords from GitHub issue descriptions. This</text>
<text top="921" left="69" width="592" height="14" font="16">is similar (and likely complementary) to our approach in that the authors define an LSP-like API for</text>
<text top="938" left="69" width="592" height="14" font="16">retrieval, but base this retrieval on inferring intent from unstructured text rather than cursor-local</text>
<text top="956" left="69" width="113" height="14" font="16">derived semantics.</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="25" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:25</text>
<text top="131" left="84" width="116" height="14" font="16">Chakraborty et al. <a href="output.html#27">[</a></text>
<text top="131" left="200" width="14" height="14" font="17"><a href="output.html#27">16</a></text>
<text top="131" left="214" width="446" height="14" font="16"><a href="output.html#27">] </a>uses RAG-based methods to retrieve relevant types from a large corpus to</text>
<text top="149" left="69" width="592" height="14" font="16">support synthesis of programs/proofs in the dependently-typed F* language. Corpus-based RAG on</text>
<text top="167" left="69" width="592" height="14" font="16">types is complementary to our approach, as it provides an avenue to retrieve semantically-similar</text>
<text top="185" left="69" width="420" height="14" font="16">code in cases where there are no local values with appropriate types.</text>
<text top="203" left="84" width="102" height="14" font="16">Parasaram et al. <a href="output.html#29">[</a></text>
<text top="203" left="185" width="14" height="14" font="17"><a href="output.html#29">57</a></text>
<text top="203" left="199" width="463" height="14" font="16"><a href="output.html#29">] </a>examines the issue of ‘fact selection’ for program repair prompt construction:</text>
<text top="221" left="69" width="592" height="14" font="16">How to decide which context to include and how that decision effects performance. They consider</text>
<text top="239" left="69" width="593" height="14" font="16">multiple types of static and dynamic information, with particular focus on localized dynamics,</text>
<text top="257" left="69" width="474" height="14" font="16">complementary to our more specific treatment of localized static information.</text>
<text top="275" left="84" width="65" height="14" font="16">Liu et al. <a href="output.html#28">[</a></text>
<text top="275" left="149" width="14" height="14" font="17"><a href="output.html#28">39</a></text>
<text top="275" left="162" width="498" height="14" font="16"><a href="output.html#28">] </a>have very recently proposed a general framework for applying static analysis</text>
<text top="293" left="69" width="593" height="14" font="16">to repository-level code completion. They consider integration across three phases: prompting,</text>
<text top="311" left="69" width="592" height="14" font="16">decoding, and post-processing, the first and last corresponding to our static contextualization</text>
<text top="329" left="69" width="592" height="14" font="16">and correction approaches. In particular, their ‘token-level dependency analysis’, which uses</text>
<text top="347" left="69" width="592" height="14" font="16">Java/Python static analyzers to add a list of plausible next tokens to the prompt, is similar to our</text>
<text top="365" left="69" width="152" height="14" font="16">header retrieval strategy.</text>
<text top="383" left="84" width="577" height="14" font="16">Significant industry work in contextualizing code generation includes the now-standard keyword</text>
<text top="400" left="69" width="501" height="14" font="16">and vector embeddings approaches (as used for example by Sourcegraph Cody <a href="output.html#30">[</a></text>
<text top="400" left="570" width="14" height="14" font="17"><a href="output.html#30">70</a></text>
<text top="400" left="584" width="77" height="14" font="16"><a href="output.html#30">]), </a>but many</text>
<text top="418" left="69" width="592" height="14" font="16">recognize new approaches are needed: the authors of the Cursor AI Code Editor call for better</text>
<text top="436" left="69" width="126" height="14" font="16">multi-hop retrieval <a href="output.html#26">[</a></text>
<text top="436" left="195" width="7" height="14" font="17"><a href="output.html#26">6</a></text>
<text top="436" left="202" width="461" height="14" font="16"><a href="output.html#26">], </a>a natural fit for structured scope-and-semantics-aware contextualization.</text>
<text top="454" left="68" width="592" height="14" font="16">The Zed editor features affordances for programmers to manually build and inspect prompt contexts</text>
<text top="472" left="69" width="5" height="14" font="16"><a href="output.html#30">[</a></text>
<text top="472" left="74" width="14" height="14" font="17"><a href="output.html#30">69</a></text>
<text top="472" left="88" width="575" height="14" font="16"><a href="output.html#30">] </a>which may facilitate exploration of the relative benefits of different contextualization methods.</text>
<text top="490" left="68" width="592" height="14" font="16">The Aider ‘AI pair programmer’ uses Tree-sitter ASTs to augment prompts with a condensed</text>
<text top="508" left="68" width="136" height="14" font="16">whole-codebase map <a href="output.html#26">[</a></text>
<text top="508" left="204" width="7" height="14" font="17"><a href="output.html#26">3</a></text>
<text top="508" left="211" width="449" height="14" font="16"><a href="output.html#26">], </a>an approach we believe may synergize with using cursor-local semantic</text>
<text top="526" left="69" width="360" height="14" font="16">information to control the granularity of such a projection.</text>
<text top="544" left="84" width="578" height="14" font="16">Finally, we note that there is also a vast literature on non-LLM-based code generation systems,</text>
<text top="562" left="69" width="349" height="14" font="16">some of which also use types to restrict the search space <a href="output.html#29">[</a></text>
<text top="562" left="418" width="14" height="14" font="17"><a href="output.html#29">55</a></text>
<text top="562" left="432" width="229" height="14" font="16"><a href="output.html#29">]. </a>Our approach helps bring these two</text>
<text top="580" left="68" width="594" height="14" font="16">worlds together, e.g. by using a form of typed term enumeration to generate the relevant headers.</text>
<text top="598" left="68" width="592" height="14" font="16">We hope that our results will lead to more interactions between the programming languages and</text>
<text top="616" left="69" width="124" height="14" font="16">the AI communities.</text>
<text top="647" left="69" width="8" height="14" font="15">7</text>
<text top="647" left="91" width="183" height="14" font="15">Discussion and Conclusion</text>
<text top="669" left="68" width="592" height="14" font="16">An AI model, no matter how powerful, cannot determine a human’s intent without access to</text>
<text top="687" left="69" width="593" height="14" font="16">necessary context. Most existing attempts to provide this contextualization are lexically grounded,</text>
<text top="705" left="69" width="592" height="14" font="16">deriving from loose, associative methods developed for natural language. We believe that typed</text>
<text top="723" left="69" width="593" height="14" font="16">holes provide a bridge between local expressions of human intent and broader semantic context,</text>
<text top="741" left="69" width="592" height="14" font="16">and that type theory provides a formal characterization of contextualization, rooted fundamentally</text>
<text top="759" left="69" width="100" height="14" font="16">in the notion of</text>
<text top="759" left="174" width="93" height="14" font="18">typing contexts</text>
<text top="759" left="266" width="347" height="14" font="16">. In particular, contextual modal type theory (CMTT) <a href="output.html#29">[</a></text>
<text top="759" left="613" width="14" height="14" font="17"><a href="output.html#29">48</a></text>
<text top="759" left="627" width="33" height="14" font="16"><a href="output.html#29">] </a>and</text>
<text top="777" left="69" width="128" height="14" font="16">gradual type theory <a href="output.html#30">[</a></text>
<text top="777" left="197" width="14" height="14" font="17"><a href="output.html#30">68</a></text>
<text top="777" left="210" width="450" height="14" font="16"><a href="output.html#30">] </a>provide a foundation for program sketching with holes, where expression</text>
<text top="795" left="69" width="592" height="14" font="16">holes corresponding to metavariables with a corresponding type and typing context and type holes</text>
<text top="813" left="69" width="592" height="14" font="16">correspond to unknown types. The Hazel programming environment, with its roots in gradual</text>
<text top="831" left="69" width="48" height="14" font="16">CMTT <a href="output.html#29">[</a></text>
<text top="831" left="117" width="14" height="14" font="17"><a href="output.html#29">50</a></text>
<text top="831" left="131" width="530" height="14" font="16"><a href="output.html#29">] </a>as a foundational theory of holes and its support for total syntax and type error recovery</text>
<text top="849" left="68" width="76" height="14" font="16">with holes <a href="output.html#29">[</a></text>
<text top="849" left="144" width="14" height="14" font="17"><a href="output.html#29">47</a></text>
<text top="849" left="158" width="3" height="14" font="16"><a href="output.html#29">,</a></text>
<text top="849" left="166" width="14" height="14" font="17"><a href="output.html#31">87</a></text>
<text top="849" left="180" width="288" height="14" font="16"><a href="output.html#31">], </a>therefore presents an ideal environment for</text>
<text top="849" left="473" width="188" height="14" font="18">statically contextualizing large</text>
<text top="867" left="69" width="207" height="14" font="18">language models with typed holes</text>
<text top="867" left="276" width="386" height="14" font="16">. Our results demonstrate that this form of contextualization,</text>
<text top="885" left="69" width="592" height="14" font="16">together with some in-context prompting about the specific choices made in Hazel, a low-resource</text>
<text top="903" left="69" width="592" height="14" font="16">language, can take a model incapable of even basic MVU tasks up to, or nearly up to, the performance</text>
<text top="921" left="69" width="592" height="14" font="16">observed in a fully contextualized setting for a high resource language like TypeScript. These ideas</text>
<text top="938" left="69" width="478" height="14" font="16">have been realized in a functional programming assistant, the Hazel Assistant.</text>
<text top="956" left="84" width="577" height="14" font="16">These ideas can also be ported directly to other languages, like TypeScript, albeit with some</text>
<text top="974" left="69" width="348" height="14" font="16">difficulty due to limitations of standard language servers.</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="26" position="absolute" top="0" left="0" height="1080" width="729">
	<fontspec id="31" size="15" family="JZXWNF+LinLibertineT" color="#155195"/>
	<fontspec id="32" size="12" family="JZXWNF+LinLibertineT" color="#155195"/>
	<fontspec id="33" size="12" family="BQBJUC+LinLibertineTI" color="#000000"/>
<text top="93" left="69" width="30" height="11" font="12">288:26</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="131" left="84" width="577" height="14" font="16">Our comparisons to vector retrieval, a language-agnostic approach, suggests that language-aware</text>
<text top="149" left="69" width="592" height="14" font="16">programming assistants may significantly outperform language-agnostic retrieval systems in the</text>
<text top="167" left="69" width="349" height="14" font="16">short- and medium-term, and perhaps far into the future.</text>
<text top="185" left="84" width="577" height="14" font="16">Additional forms of semantic contextualization, e.g. using dynamic test results passed backwards</text>
<text top="203" left="69" width="57" height="14" font="16">to holes <a href="output.html#29">[</a></text>
<text top="203" left="126" width="14" height="14" font="17"><a href="output.html#29">45</a></text>
<text top="203" left="140" width="521" height="14" font="16"><a href="output.html#29">], </a>the results of various static and dynamic analyses, and the result of library searches</text>
<text top="221" left="69" width="518" height="14" font="16">to find helpers that may not yet be imported are interesting avenues for future work.</text>
<text top="259" left="69" width="8" height="14" font="15">8</text>
<text top="259" left="91" width="114" height="14" font="15">Data Availability</text>
<text top="281" left="68" width="79" height="14" font="16">An artefact <a href="output.html#27">[</a></text>
<text top="281" left="147" width="14" height="14" font="17"><a href="output.html#27">11</a></text>
<text top="281" left="161" width="500" height="14" font="16"><a href="output.html#27">] </a>containing the MVUBench program sketches and solutions, the raw data of our</text>
<text top="299" left="69" width="592" height="14" font="16">experiments, our testing harness, the source of the Hazel IDE and Language Server, and a copy of</text>
<text top="317" left="69" width="592" height="14" font="16">the StarCoder2 model used is available on Zenodo. The artefact is password-protected to prevent</text>
<text top="335" left="69" width="594" height="14" font="16">automatic scrapping of the benchmark suite; the password can be found in the artefact description.</text>
<text top="353" left="69" width="201" height="14" font="16">Hazel can be accessed online at</text>
<text top="353" left="275" width="102" height="14" font="31"><a href="https://hazel.org">https://hazel.org</a></text>
<text top="353" left="377" width="160" height="14" font="16"><a href="https://hazel.org">, </a>with source available at</text>
<text top="353" left="541" width="120" height="14" font="31"><a href="https://github.com/hazelgrove/hazel/">https://github.com/</a></text>
<text top="371" left="69" width="108" height="14" font="31"><a href="https://github.com/hazelgrove/hazel/">hazelgrove/hazel/</a></text>
<text top="371" left="176" width="3" height="14" font="16"><a href="https://github.com/hazelgrove/hazel/">.</a></text>
<text top="408" left="69" width="8" height="14" font="15">9</text>
<text top="408" left="91" width="134" height="14" font="15">Acknowledgements</text>
<text top="430" left="68" width="593" height="14" font="16">We would like to thank our referees for their helpful feedback, and our artefact reviewers for their</text>
<text top="448" left="69" width="93" height="14" font="16">diligent efforts.</text>
<text top="466" left="84" width="264" height="14" font="16">The (public domain) programmer photo in</text>
<text top="466" left="352" width="51" height="14" font="17"><a href="output.html#2">Figure 1</a></text>
<text top="466" left="406" width="23" height="14" font="16">and</text>
<text top="466" left="433" width="51" height="14" font="17"><a href="output.html#9">Figure 6</a></text>
<text top="466" left="487" width="173" height="14" font="16">depicts ENIAC programmer</text>
<text top="484" left="69" width="114" height="14" font="16">Ruth Teitelbaum <a href="output.html#30">[</a></text>
<text top="484" left="182" width="14" height="14" font="17"><a href="output.html#30">72</a></text>
<text top="484" left="196" width="464" height="14" font="16"><a href="output.html#30">]. </a>The language server and language model images were prompted by the</text>
<text top="502" left="69" width="554" height="14" font="16">authors using the Bing AI Image Creator; Microsoft claims no copyright over generations <a href="output.html#29">[</a></text>
<text top="502" left="623" width="14" height="14" font="17"><a href="output.html#29">46</a></text>
<text top="502" left="637" width="9" height="14" font="16"><a href="output.html#29">].</a></text>
<text top="520" left="84" width="577" height="14" font="16">Claude and ChatGPT were used to author scripts for our testing harness and data processing</text>
<text top="538" left="69" width="592" height="14" font="16">pipeline, and aid in the transliteration of the MVUBench suite to TypeScript. In so doing we are</text>
<text top="556" left="69" width="535" height="14" font="16">putting faith in stated Anthropic policy of not including prompts in future training data <a href="output.html#26">[</a></text>
<text top="556" left="604" width="7" height="14" font="17"><a href="output.html#26">5</a></text>
<text top="556" left="611" width="49" height="14" font="16"><a href="output.html#26">], </a>which</text>
<text top="574" left="69" width="328" height="14" font="16">could be a source of data contamination as described in</text>
<text top="574" left="400" width="53" height="14" font="17"><a href="output.html#2">section 1</a></text>
<text top="574" left="453" width="208" height="14" font="16"><a href="output.html#2">. </a>After some discussion we decided</text>
<text top="592" left="69" width="592" height="14" font="16">that absolute purity was a losing battle, as there was already a near-certainty that the code was</text>
<text top="610" left="69" width="592" height="14" font="16">opened and edited in a Copilot-enabled IDE; true clean-room behavior with respect to benchmark</text>
<text top="628" left="69" width="564" height="14" font="16">data seems likely to prove increasingly difficult as LLM integration becomes more prevalent.</text>
<text top="646" left="84" width="527" height="14" font="16">This work was partially funded by the National Science Foundation (Award #2238744).</text>
<text top="683" left="69" width="75" height="14" font="15">References</text>
<text top="704" left="74" width="587" height="11" font="9">[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida,</text>
<text top="719" left="94" width="465" height="11" font="9">Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. GPT-4 technical report. <a href="https://arxiv.org/abs/2303.08774">arXiv:</a></text>
<text top="719" left="559" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2303.08774">2303.08774</a></text>
<text top="719" left="615" width="33" height="11" font="9">[cs.AI]</text>
<text top="734" left="74" width="586" height="11" font="9">[2] Lakshya A Agrawal, Aditya Kanade, Navin Goyal, Shuvendu Lahiri, and Sriram Rajamani. 2023. Monitor-Guided</text>
<text top="749" left="94" width="326" height="11" font="9">Decoding of Code LMs with Static Analysis of Repository Context. In</text>
<text top="749" left="422" width="237" height="11" font="33">Advances in Neural Information Processing Systems</text>
<text top="749" left="659" width="3" height="11" font="9">,</text>
<text top="764" left="94" width="103" height="11" font="9">Vol. 36. 32270–32298.</text>
<text top="764" left="204" width="458" height="11" font="32"><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/662b1774ba8845fc1fa3d1fc0177ceeb-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2023/file/662b1774ba8845fc1fa3d1fc0177ceeb-</a></text>
<text top="779" left="94" width="107" height="11" font="32"><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/662b1774ba8845fc1fa3d1fc0177ceeb-Paper-Conference.pdf">Paper-Conference.pdf</a></text>
<text top="794" left="74" width="316" height="11" font="9">[3] Aider. 2023. Building a better repository map with tree sitter.</text>
<text top="794" left="399" width="209" height="11" font="32"><a href="https://aider.chat/2023/10/22/repomap.html">https://aider.chat/2023/10/22/repomap.html</a></text>
<text top="794" left="612" width="48" height="11" font="9">[Accessed</text>
<text top="809" left="94" width="84" height="11" font="9">August 31, 2024].</text>
<text top="824" left="74" width="313" height="11" font="9">[4] Anthropic. 2024. Introducing the next generation of Claude.</text>
<text top="824" left="396" width="246" height="11" font="32"><a href="https://www.anthropic.com/news/claude-3-family">https://www.anthropic.com/news/claude-3-family</a></text>
<text top="839" left="74" width="335" height="11" font="9">[5] Antropic. 2024. How do you use personal data in model training?</text>
<text top="839" left="418" width="244" height="11" font="32"><a href="https://support.anthropic.com/en/articles/7996885-how-do-you-use-personal-data-in-model-training">https://support.anthropic.com/en/articles/7996885-</a></text>
<text top="854" left="94" width="248" height="11" font="32"><a href="https://support.anthropic.com/en/articles/7996885-how-do-you-use-personal-data-in-model-training">how-do-you-use-personal-data-in-model-training</a></text>
<text top="854" left="347" width="147" height="11" font="9">[Accessed September 1, 2024].</text>
<text top="869" left="74" width="218" height="11" font="9">[6] Anysphere. 2024. Cursor Problems 2024.</text>
<text top="869" left="301" width="219" height="11" font="32"><a href="https://www.cursor.com/blog/problems-2024">https://www.cursor.com/blog/problems-2024</a></text>
<text top="869" left="524" width="135" height="11" font="9">[Accessed August 31, 2024].</text>
<text top="884" left="74" width="587" height="11" font="9">[7] Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang,</text>
<text top="899" left="94" width="568" height="11" font="9">Carrie J. Cai, Michael Terry, Quoc V. Le, and Charles Sutton. 2021. Program Synthesis with Large Language Models.</text>
<text top="914" left="94" width="26" height="11" font="33">CoRR</text>
<text top="914" left="124" width="142" height="11" font="9">abs/2108.07732 (2021). <a href="https://arxiv.org/abs/2108.07732">arXiv:</a></text>
<text top="914" left="265" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2108.07732">2108.07732</a></text>
<text top="929" left="74" width="388" height="11" font="9">[8] Thomas Bandt. 2020. Pragmatic MVU With React And TypeScript. (2020).</text>
<text top="929" left="470" width="192" height="11" font="32"><a href="https://thomasbandt.com/model-view-update-with-react-and-typescript">https://thomasbandt.com/model-view-</a></text>
<text top="944" left="94" width="166" height="11" font="32"><a href="https://thomasbandt.com/model-view-update-with-react-and-typescript">update-with-react-and-typescript</a></text>
<text top="944" left="260" width="3" height="11" font="9"><a href="https://thomasbandt.com/model-view-update-with-react-and-typescript">.</a></text>
<text top="958" left="74" width="586" height="11" font="9">[9] Shraddha Barke, Michael B. James, and Nadia Polikarpova. 2023. Grounded Copilot: How Programmers Interact with</text>
<text top="973" left="94" width="125" height="11" font="9">Code-Generating Models.</text>
<text top="973" left="224" width="126" height="11" font="33">Proc. ACM Program. Lang.</text>
<text top="973" left="353" width="135" height="11" font="9">7, OOPSLA1 (2023), 85–111.</text>
<text top="973" left="495" width="152" height="11" font="32"><a href="https://doi.org/10.1145/3586030">https://doi.org/10.1145/3586030</a></text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="27" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:27</text>
<text top="134" left="69" width="592" height="11" font="9">[10] Djonathan Barros, Sven Peldszus, Wesley K. G. Assunção, and Thorsten Berger. 2022. Editing support for software</text>
<text top="149" left="94" width="335" height="11" font="9">languages: implementation practices in language server protocols. In</text>
<text top="149" left="432" width="228" height="11" font="33">Proceedings of the 25th International Conference</text>
<text top="164" left="94" width="321" height="11" font="33">on Model Driven Engineering Languages and Systems (MODELS ’22)</text>
<text top="163" left="415" width="247" height="11" font="9">. Association for Computing Machinery, New York,</text>
<text top="178" left="94" width="91" height="11" font="9">NY, USA, 232–243.</text>
<text top="178" left="194" width="194" height="11" font="32"><a href="https://doi.org/10.1145/3550355.3552452">https://doi.org/10.1145/3550355.3552452</a></text>
<text top="193" left="69" width="379" height="11" font="9">[11] andrew blinn, Xiang Li, June Hyung (Jacob) Kim, and Cyrus Omar. 2024.</text>
<text top="193" left="452" width="209" height="11" font="33">Artifact for Statically Contextualizing Large</text>
<text top="208" left="94" width="167" height="11" font="33">Language Models with Typed Holes</text>
<text top="208" left="261" width="3" height="11" font="9">.</text>
<text top="208" left="271" width="196" height="11" font="32"><a href="https://doi.org/10.5281/zenodo.12669479">https://doi.org/10.5281/zenodo.12669479</a></text>
<text top="223" left="69" width="592" height="11" font="9">[12] Andrew Blinn, David Moon, Eric Griffis, and Cyrus Omar. 2022. An Integrative Human-Centered Architecture for</text>
<text top="238" left="94" width="195" height="11" font="9">Interactive Programming Assistants. In</text>
<text top="238" left="293" width="368" height="11" font="33">2022 IEEE Symposium on Visual Languages and Human-Centric Computing</text>
<text top="253" left="94" width="47" height="11" font="33">(VL/HCC)</text>
<text top="253" left="141" width="26" height="11" font="9">. 1–5.</text>
<text top="253" left="174" width="250" height="11" font="32"><a href="https://doi.org/10.1109/VL/HCC53370.2022.9833110">https://doi.org/10.1109/VL/HCC53370.2022.9833110</a></text>
<text top="268" left="69" width="593" height="11" font="9">[13] Frédéric Bour, Thomas Refis, and Gabriel Scherer. 2018. Merlin: a language server for OCaml (experience report).</text>
<text top="283" left="94" width="249" height="11" font="33">Proceedings of the ACM on Programming Languages</text>
<text top="283" left="346" width="99" height="11" font="9">2, ICFP (2018), 1–15.</text>
<text top="298" left="69" width="245" height="11" font="9">[14] Giulio Canti. 2019. Type holes in TypeScript.</text>
<text top="298" left="322" width="247" height="11" font="32"><a href="https://dev.to/gcanti/type-holes-in-typescript-2lck">https://dev.to/gcanti/type-holes-in-typescript-2lck</a></text>
<text top="298" left="574" width="87" height="11" font="9">[Accessed August</text>
<text top="313" left="94" width="46" height="11" font="9">31, 2024].</text>
<text top="328" left="69" width="593" height="11" font="9">[15] Federico Cassano, John Gouwar, Francesca Lucchetti, Claire Schlesinger, Anders Freeman, Carolyn Jane Anderson,</text>
<text top="343" left="94" width="568" height="11" font="9">Molly Q Feldman, Michael Greenberg, Abhinav Jangda, and Arjun Guha. 2024. Knowledge Transfer from High-</text>
<text top="358" left="94" width="322" height="11" font="9">Resource to Low-Resource Programming Languages for Code LLMs.</text>
<text top="358" left="420" width="240" height="11" font="33">Proceedings of the ACM on Programming Languages</text>
<text top="373" left="94" width="122" height="11" font="33">(PACMPL), Issue OOPSLA</text>
<text top="373" left="219" width="66" height="11" font="9">(2024). <a href="https://arxiv.org/abs/2308.09895">arXiv:</a></text>
<text top="373" left="285" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2308.09895">2308.09895</a></text>
<text top="373" left="341" width="33" height="11" font="9">[cs.PL]</text>
<text top="388" left="69" width="592" height="11" font="9">[16] Saikat Chakraborty, Gabriel Ebner, Siddharth Bhat, Sarah Fakhoury, Sakina Fatima, Shuvendu Lahiri, and Nikhil</text>
<text top="403" left="94" width="446" height="11" font="9">Swamy. 2024. Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming. In</text>
<text top="403" left="544" width="117" height="11" font="33">International Conference</text>
<text top="418" left="94" width="148" height="11" font="33">on Software Engineering (ICSE)</text>
<text top="418" left="243" width="37" height="11" font="9">. <a href="https://arxiv.org/abs/2405.01787">arXiv:</a></text>
<text top="418" left="279" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2405.01787">2405.01787</a></text>
<text top="418" left="335" width="33" height="11" font="9">[cs.PL]</text>
<text top="432" left="69" width="592" height="11" font="9">[17] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé de Oliveira Pinto, Jared Kaplan, Harrison</text>
<text top="447" left="94" width="566" height="11" font="9">Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy</text>
<text top="462" left="94" width="566" height="11" font="9">Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz</text>
<text top="477" left="94" width="567" height="11" font="9">Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert,</text>
<text top="492" left="94" width="567" height="11" font="9">Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak,</text>
<text top="507" left="94" width="566" height="11" font="9">Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan</text>
<text top="522" left="94" width="567" height="11" font="9">Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati,</text>
<text top="537" left="94" width="568" height="11" font="9">Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba.</text>
<text top="552" left="94" width="288" height="11" font="9">2021. Evaluating Large Language Models Trained on Code.</text>
<text top="552" left="387" width="26" height="11" font="33">CoRR</text>
<text top="552" left="416" width="142" height="11" font="9">abs/2107.03374 (2021). <a href="https://arxiv.org/abs/2107.03374">arXiv:</a></text>
<text top="552" left="558" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2107.03374">2107.03374</a></text>
<text top="567" left="69" width="260" height="11" font="9">[18] Czaplicki, Evan. 2022. Elm Architecture. (2022).</text>
<text top="567" left="336" width="197" height="11" font="32"><a href="https://guide.elm-lang.org/architecture/">https://guide.elm-lang.org/architecture/</a></text>
<text top="567" left="537" width="124" height="11" font="9">[Accessed September 1st,</text>
<text top="582" left="94" width="29" height="11" font="9">2024].</text>
<text top="597" left="69" width="592" height="11" font="9">[19] Yangruibo Ding, Zijian Wang, Wasi Ahmad, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan</text>
<text top="612" left="94" width="566" height="11" font="9">Roth, and Bing Xiang. 2024. CoCoMIC: Code Completion by Jointly Modeling In-file and Cross-file Context. In</text>
<text top="627" left="94" width="566" height="11" font="33">Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation</text>
<text top="642" left="94" width="103" height="11" font="33">(LREC-COLING 2024)</text>
<text top="642" left="197" width="59" height="11" font="9">. 3433–3445.</text>
<text top="642" left="263" width="213" height="11" font="32"><a href="https://aclanthology.org/2024.lrec-main.305">https://aclanthology.org/2024.lrec-main.305</a></text>
<text top="657" left="69" width="593" height="11" font="9">[20] Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad, Hantian Ding, Ming Tan, Nihal Jain, Murali Krishna Ramanathan,</text>
<text top="672" left="94" width="566" height="11" font="9">Ramesh Nallapati, Parminder Bhatia, Dan Roth, and Bing Xiang. 2023. CrossCodeEval: A Diverse and Multilingual</text>
<text top="687" left="94" width="232" height="11" font="9">Benchmark for Cross-File Code Completion. In</text>
<text top="687" left="330" width="330" height="11" font="33">Thirty-seventh Conference on Neural Information Processing Systems</text>
<text top="702" left="94" width="152" height="11" font="33">Datasets and Benchmarks Track</text>
<text top="701" left="246" width="3" height="11" font="9">.</text>
<text top="701" left="256" width="233" height="11" font="32"><a href="https://openreview.net/forum?id=wgDcbBMSfh">https://openreview.net/forum?id=wgDcbBMSfh</a></text>
<text top="716" left="69" width="593" height="11" font="9">[21] Yiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu, Fan Yang, and Mao Yang.</text>
<text top="731" left="94" width="411" height="11" font="9">2024. LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens. <a href="https://arxiv.org/abs/2402.13753">arXiv:</a></text>
<text top="731" left="506" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2402.13753">2402.13753</a></text>
<text top="731" left="561" width="35" height="11" font="9">[cs.CL]</text>
<text top="746" left="69" width="593" height="11" font="9">[22] Aryaz Eghbali and Michael Pradel. 2024. De-Hallucinator: Iterative Grounding for LLM-Based Code Completion.</text>
<text top="761" left="94" width="30" height="11" font="9"><a href="https://arxiv.org/abs/2401.01701">arXiv:</a></text>
<text top="761" left="124" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2401.01701">2401.01701</a></text>
<text top="761" left="180" width="33" height="11" font="9">[cs.SE]</text>
<text top="776" left="69" width="418" height="11" font="9">[23] Nat Friedman. 2021. Introducing GitHub Copilot: your AI pair programmer.</text>
<text top="776" left="506" width="155" height="11" font="32"><a href="https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/">https://github.blog/2021-06-29-</a></text>
<text top="791" left="94" width="239" height="11" font="32"><a href="https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/">introducing-github-copilot-ai-pair-programmer/</a></text>
<text top="791" left="338" width="135" height="11" font="9">[Accessed August 31, 2024].</text>
<text top="806" left="69" width="592" height="11" font="9">[24] Shuzheng Gao, Xin-Cheng Wen, Cuiyun Gao, Wenxuan Wang, Hongyu Zhang, and Michael R. Lyu. 2023. What</text>
<text top="821" left="94" width="403" height="11" font="9">Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs?. In</text>
<text top="821" left="500" width="160" height="11" font="33">2023 38th IEEE/ACM International</text>
<text top="836" left="94" width="256" height="11" font="33">Conference on Automated Software Engineering (ASE)</text>
<text top="836" left="350" width="32" height="11" font="9">. IEEE.</text>
<text top="836" left="389" width="212" height="11" font="32"><a href="https://doi.org/10.1109/ase56229.2023.00109">https://doi.org/10.1109/ase56229.2023.00109</a></text>
<text top="851" left="69" width="593" height="11" font="9">[25] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang,</text>
<text top="866" left="94" width="463" height="11" font="9">and Haofen Wang. 2023. Retrieval-Augmented Generation for Large Language Models: A Survey.</text>
<text top="866" left="561" width="25" height="11" font="33">CoRR</text>
<text top="866" left="589" width="71" height="11" font="9">abs/2312.10997</text>
<text top="881" left="94" width="32" height="11" font="9">(2023).</text>
<text top="881" left="133" width="208" height="11" font="32"><a href="https://doi.org/10.48550/ARXIV.2312.10997">https://doi.org/10.48550/ARXIV.2312.10997</a></text>
<text top="881" left="344" width="30" height="11" font="9"><a href="https://arxiv.org/abs/2312.10997">arXiv:</a></text>
<text top="881" left="374" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2312.10997">2312.10997</a></text>
<text top="896" left="69" width="184" height="11" font="9">[26] Matthías Páll Gissurarson. 2022.</text>
<text top="896" left="257" width="239" height="11" font="33">The Hole Story: Type-Driven Synthesis and Repair</text>
<text top="896" left="496" width="93" height="11" font="9">. Licentiate Thesis.</text>
<text top="896" left="597" width="65" height="11" font="32"><a href="https://www.mpg.is/papers/gissurarson2022licentiate.pdf">https://www.</a></text>
<text top="911" left="94" width="214" height="11" font="32"><a href="https://www.mpg.is/papers/gissurarson2022licentiate.pdf">mpg.is/papers/gissurarson2022licentiate.pdf</a></text>
<text top="926" left="69" width="592" height="11" font="9">[27] Elena L. Glassman, Jeremy Scott, Rishabh Singh, Philip J. Guo, and Robert C. Miller. 2015. OverCode: Visualizing</text>
<text top="941" left="94" width="319" height="11" font="9">Variation in Student Solutions to Programming Problems at Scale.</text>
<text top="941" left="417" width="171" height="11" font="33">ACM Trans. Comput.-Hum. Interact.</text>
<text top="941" left="591" width="69" height="11" font="9">22, 2, Article 7</text>
<text top="956" left="94" width="54" height="11" font="9">(mar 2015).</text>
<text top="956" left="157" width="152" height="11" font="32"><a href="https://doi.org/10.1145/2699751">https://doi.org/10.1145/2699751</a></text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="28" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="30" height="11" font="12">288:28</text>
<text top="93" left="371" width="290" height="11" font="12">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</text>
<text top="134" left="69" width="130" height="11" font="9">[28] Robert Harper. 2016.</text>
<text top="134" left="207" width="300" height="11" font="33">Practical Foundations for Programming Languages (2nd. Ed.)</text>
<text top="134" left="507" width="155" height="11" font="9">. Cambridge University Press.</text>
<text top="149" left="94" width="241" height="11" font="32"><a href="https://www.cs.cmu.edu/%7Erwh/pfpl/index.html">https://www.cs.cmu.edu/%7Erwh/pfpl/index.html</a></text>
<text top="163" left="69" width="593" height="11" font="9">[29] Abram Hindle, Earl T Barr, Mark Gabel, Zhendong Su, and Premkumar Devanbu. 2016. On the naturalness of software.</text>
<text top="178" left="94" width="74" height="11" font="33">Commun. ACM</text>
<text top="178" left="172" width="103" height="11" font="9">59, 5 (2016), 122–131.</text>
<text top="178" left="282" width="230" height="11" font="32"><a href="https://dl.acm.org/doi/10.5555/2337223.2337322">https://dl.acm.org/doi/10.5555/2337223.2337322</a></text>
<text top="193" left="69" width="592" height="11" font="9">[30] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de</text>
<text top="208" left="94" width="566" height="11" font="9">Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George</text>
<text top="223" left="94" width="568" height="11" font="9">van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Oriol Vinyals, Jack W.</text>
<text top="238" left="94" width="393" height="11" font="9">Rae, and Laurent Sifre. 2024. Training compute-optimal large language models. In</text>
<text top="238" left="490" width="170" height="11" font="33">Proceedings of the 36th International</text>
<text top="253" left="94" width="303" height="11" font="33">Conference on Neural Information Processing Systems (NIPS ’22)</text>
<text top="253" left="398" width="67" height="11" font="9">. Article 2176.</text>
<text top="253" left="472" width="190" height="11" font="32"><a href="https://dl.acm.org/doi/10.5555/3600270.3602446">https://dl.acm.org/doi/10.5555/3600270.</a></text>
<text top="268" left="94" width="39" height="11" font="32"><a href="https://dl.acm.org/doi/10.5555/3600270.3602446">3602446</a></text>
<text top="283" left="69" width="592" height="11" font="9">[31] Alon Jacovi, Avi Caciularu, Omer Goldman, and Yoav Goldberg. 2023. Stop Uploading Test Data in Plain Text: Practical</text>
<text top="298" left="94" width="380" height="11" font="9">Strategies for Mitigating Data Contamination by Evaluation Benchmarks. In</text>
<text top="298" left="477" width="183" height="11" font="33">Proceedings of the 2023 Conference on</text>
<text top="313" left="94" width="241" height="11" font="33">Empirical Methods in Natural Language Processing</text>
<text top="313" left="335" width="325" height="11" font="9">, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for</text>
<text top="328" left="94" width="243" height="11" font="9">Computational Linguistics, Singapore, 5075–5084.</text>
<text top="328" left="345" width="239" height="11" font="32"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.308">https://doi.org/10.18653/v1/2023.emnlp-main.308</a></text>
<text top="343" left="69" width="592" height="11" font="9">[32] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik</text>
<text top="358" left="94" width="566" height="11" font="9">Sen, and Ion Stoica. 2024. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for</text>
<text top="373" left="94" width="28" height="11" font="9">Code.</text>
<text top="373" left="126" width="26" height="11" font="33">CoRR</text>
<text top="373" left="156" width="108" height="11" font="9">abs/2403.07974 (2024).</text>
<text top="373" left="270" width="208" height="11" font="32"><a href="https://doi.org/10.48550/ARXIV.2403.07974">https://doi.org/10.48550/ARXIV.2403.07974</a></text>
<text top="373" left="482" width="30" height="11" font="9"><a href="https://arxiv.org/abs/2403.07974">arXiv:</a></text>
<text top="373" left="511" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2403.07974">2403.07974</a></text>
<text top="388" left="69" width="592" height="11" font="9">[33] Harshit Joshi, José Cambronero Sanchez, Sumit Gulwani, Vu Le, Ivan Radiček, and Gust Verbruggen. 2023. Repair</text>
<text top="403" left="94" width="316" height="11" font="9">is nearly generation: multilingual program repair with LLMs. In</text>
<text top="403" left="413" width="247" height="11" font="33">Proceedings of the Thirty-Seventh AAAI Conference</text>
<text top="418" left="94" width="566" height="11" font="33">on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth</text>
<text top="433" left="94" width="439" height="11" font="33">Symposium on Educational Advances in Artificial Intelligence (AAAI’23/IAAI’23/EAAI’23)</text>
<text top="432" left="533" width="129" height="11" font="9">. AAAI Press, Article 573,</text>
<text top="447" left="94" width="44" height="11" font="9">10 pages.</text>
<text top="447" left="147" width="192" height="11" font="32"><a href="https://doi.org/10.1609/aaai.v37i4.25642">https://doi.org/10.1609/aaai.v37i4.25642</a></text>
<text top="462" left="69" width="592" height="11" font="9">[34] René Just, Darioush Jalali, and Michael D. Ernst. 2014. Defects4J: a database of existing faults to enable controlled</text>
<text top="477" left="94" width="173" height="11" font="9">testing studies for Java programs. In</text>
<text top="477" left="270" width="391" height="11" font="33">International Symposium on Software Testing and Analysis, ISSTA ’14, San Jose, CA,</text>
<text top="492" left="94" width="112" height="11" font="33">USA - July 21 - 26, 2014</text>
<text top="492" left="207" width="79" height="11" font="9">. ACM, 437–440.</text>
<text top="492" left="293" width="194" height="11" font="32"><a href="https://doi.org/10.1145/2610384.2628055">https://doi.org/10.1145/2610384.2628055</a></text>
<text top="507" left="69" width="592" height="11" font="9">[35] Mosh Levy, Alon Jacoby, and Yoav Goldberg. 2024. Same Task, More Tokens: the Impact of Input Length on the</text>
<text top="522" left="94" width="267" height="11" font="9">Reasoning Performance of Large Language Models. In</text>
<text top="522" left="364" width="296" height="11" font="33">Proceedings of the 62nd Annual Meeting of the Association for</text>
<text top="537" left="94" width="246" height="11" font="33">Computational Linguistics (Volume 1: Long Papers)</text>
<text top="537" left="340" width="286" height="11" font="9">. Association for Computational Linguistics, 15339–15353.</text>
<text top="537" left="634" width="28" height="11" font="32"><a href="https://aclanthology.org/2024.acl-long.818">https:</a></text>
<text top="552" left="94" width="178" height="11" font="32"><a href="https://aclanthology.org/2024.acl-long.818">//aclanthology.org/2024.acl-long.818</a></text>
<text top="567" left="69" width="593" height="11" font="9">[36] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler,</text>
<text top="582" left="94" width="566" height="11" font="9">Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-augmented generation</text>
<text top="597" left="94" width="182" height="11" font="9">for knowledge-intensive NLP tasks. In</text>
<text top="597" left="280" width="381" height="11" font="33">Proceedings of the 34th International Conference on Neural Information Processing</text>
<text top="612" left="94" width="88" height="11" font="33">Systems (NIPS ’20)</text>
<text top="612" left="182" width="61" height="11" font="9">. Article 793.</text>
<text top="612" left="251" width="250" height="11" font="32"><a href="https://dl.acm.org/doi/abs/10.5555/3495724.3496517">https://dl.acm.org/doi/abs/10.5555/3495724.3496517</a></text>
<text top="627" left="69" width="592" height="11" font="9">[37] Jiaqi Li, Mengmeng Wang, Zilong Zheng, and Muhan Zhang. 2024. LooGLE: Can Long-Context Language Models</text>
<text top="642" left="94" width="149" height="11" font="9">Understand Long Contexts?. In</text>
<text top="642" left="246" width="414" height="11" font="33">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</text>
<text top="657" left="94" width="114" height="11" font="33">(Volume 1: Long Papers)</text>
<text top="657" left="208" width="283" height="11" font="9">. Association for Computational Linguistics, 16304–16333.</text>
<text top="657" left="498" width="164" height="11" font="32"><a href="https://aclanthology.org/2024.acl-long.859">https://aclanthology.org/2024.acl-</a></text>
<text top="672" left="94" width="41" height="11" font="32"><a href="https://aclanthology.org/2024.acl-long.859">long.859</a></text>
<text top="687" left="69" width="592" height="11" font="9">[38] Yichen Li, Yun Peng, Yintong Huo, and Michael R. Lyu. 2024. Enhancing LLM-Based Coding Tools through Native</text>
<text top="701" left="94" width="219" height="11" font="9">Integration of IDE-Derived Static Context. In</text>
<text top="702" left="317" width="101" height="11" font="33">LLM4Code Workshop</text>
<text top="701" left="417" width="37" height="11" font="9">. <a href="https://arxiv.org/abs/2402.03630">arXiv:</a></text>
<text top="701" left="454" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2402.03630">2402.03630</a></text>
<text top="701" left="510" width="33" height="11" font="9">[cs.SE]</text>
<text top="716" left="69" width="592" height="11" font="9">[39] Junwei Liu, Yixuan Chen, Mingwei Liu, Xin Peng, and Yiling Lou. 2024. STALL+: Boosting LLM-based Repository-level</text>
<text top="731" left="94" width="189" height="11" font="9">Code Completion with Static Analysis.</text>
<text top="731" left="288" width="26" height="11" font="33">CoRR</text>
<text top="731" left="317" width="142" height="11" font="9">abs/2406.10018 (2024). <a href="https://arxiv.org/abs/2406.10018">arXiv:</a></text>
<text top="731" left="458" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2406.10018">2406.10018</a></text>
<text top="746" left="69" width="592" height="11" font="9">[40] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2024. Is your code generated by ChatGPT really</text>
<text top="761" left="94" width="386" height="11" font="9">correct? rigorous evaluation of large language models for code generation. In</text>
<text top="761" left="483" width="177" height="11" font="33">Proceedings of the 37th International</text>
<text top="776" left="94" width="306" height="11" font="33">Conference on Neural Information Processing Systems (NIPS ’23)</text>
<text top="776" left="401" width="62" height="11" font="9">. Article 943.</text>
<text top="776" left="470" width="192" height="11" font="32"><a href="https://dl.acm.org/doi/10.5555/3666122.3667065">https://dl.acm.org/doi/10.5555/3666122.</a></text>
<text top="791" left="94" width="39" height="11" font="32"><a href="https://dl.acm.org/doi/10.5555/3666122.3667065">3667065</a></text>
<text top="806" left="69" width="592" height="11" font="9">[41] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost</text>
<text top="821" left="94" width="263" height="11" font="9">in the middle: How language models use long contexts.</text>
<text top="821" left="362" width="285" height="11" font="33">Transactions of the Association for Computational Linguistics</text>
<text top="821" left="649" width="11" height="11" font="9">12</text>
<text top="836" left="94" width="78" height="11" font="9">(2024), 157–173.</text>
<text top="836" left="179" width="186" height="11" font="32"><a href="https://aclanthology.org/2024.tacl-1.9/">https://aclanthology.org/2024.tacl-1.9/</a></text>
<text top="851" left="69" width="594" height="11" font="9">[42] Tianyang Liu, Canwen Xu, and Julian McAuley. 2024. RepoBench: Benchmarking Repository-Level Code Auto-</text>
<text top="866" left="94" width="118" height="11" font="9">Completion Systems. In</text>
<text top="866" left="216" width="319" height="11" font="33">The Twelfth International Conference on Learning Representations</text>
<text top="866" left="535" width="3" height="11" font="9">.</text>
<text top="866" left="545" width="116" height="11" font="32"><a href="https://openreview.net/forum?id=pPjZIOuQuF">https://openreview.net/</a></text>
<text top="881" left="94" width="113" height="11" font="32"><a href="https://openreview.net/forum?id=pPjZIOuQuF">forum?id=pPjZIOuQuF</a></text>
<text top="896" left="69" width="592" height="11" font="9">[43] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro</text>
<text top="911" left="94" width="566" height="11" font="9">Pykhtar, Jiawei Liu, Yuxiang Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian</text>
<text top="926" left="94" width="566" height="11" font="9">Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue</text>
<text top="941" left="94" width="567" height="11" font="9">Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He,</text>
<text top="956" left="94" width="567" height="11" font="9">Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher Akiki,</text>
<text top="970" left="94" width="566" height="11" font="9">Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas</text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="29" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:29</text>
<text top="134" left="94" width="566" height="11" font="9">Patry, Canwen Xu, Julian McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane</text>
<text top="149" left="94" width="566" height="11" font="9">Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz Ferrandis, Lingming</text>
<text top="163" left="94" width="566" height="11" font="9">Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. 2024. StarCoder 2 and The</text>
<text top="178" left="94" width="188" height="11" font="9">Stack v2: The Next Generation. <a href="https://arxiv.org/abs/2402.19173">arXiv:</a></text>
<text top="178" left="282" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2402.19173">2402.19173</a></text>
<text top="178" left="338" width="33" height="11" font="9">[cs.SE]</text>
<text top="193" left="69" width="594" height="11" font="9">[44] Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, and Alexey Svyatkovskiy. 2022. ReACC: A Retrieval-</text>
<text top="208" left="93" width="213" height="11" font="9">Augmented Code Completion Framework. In</text>
<text top="208" left="309" width="351" height="11" font="33">Proceedings of the 60th Annual Meeting of the Association for Computational</text>
<text top="223" left="94" width="168" height="11" font="33">Linguistics (Volume 1: Long Papers)</text>
<text top="223" left="262" width="59" height="11" font="9">. 6227–6240.</text>
<text top="223" left="329" width="219" height="11" font="32"><a href="https://doi.org/10.18653/v1/2022.acl-long.431">https://doi.org/10.18653/v1/2022.acl-long.431</a></text>
<text top="238" left="69" width="593" height="11" font="9">[45] Justin Lubin, Nick Collins, Cyrus Omar, and Ravi Chugh. 2020. Program Sketching with Live Bidirectional Evaluation.</text>
<text top="253" left="94" width="249" height="11" font="33">Proceedings of the ACM on Programming Languages</text>
<text top="253" left="346" width="99" height="11" font="9">4, ICFP (2020), 1–29.</text>
<text top="253" left="452" width="188" height="11" font="32"><a href="https://dl.acm.org/doi/10.1145/3408991">https://dl.acm.org/doi/10.1145/3408991</a></text>
<text top="268" left="69" width="320" height="11" font="9">[46] Microsoft. 2024. Bing Image Creator from Designer Terms.</text>
<text top="268" left="400" width="261" height="11" font="32"><a href="https://www.bing.com/new/termsofuseimagecreator">https://www.bing.com/new/termsofuseimagecreator</a></text>
<text top="283" left="94" width="135" height="11" font="9">[Accessed August 30, 2024].</text>
<text top="298" left="69" width="464" height="11" font="9">[47] D. Moon, A. Blinn, and C. Omar. 2023. Gradual Structure Editing with Obligations. In</text>
<text top="298" left="536" width="124" height="11" font="33">2023 IEEE Symposium on</text>
<text top="313" left="94" width="290" height="11" font="33">Visual Languages and Human-Centric Computing (VL/HCC)</text>
<text top="313" left="384" width="278" height="11" font="9">. IEEE Computer Society, Los Alamitos, CA, USA, 71–81.</text>
<text top="328" left="94" width="240" height="11" font="32"><a href="https://doi.org/10.1109/VL-HCC57772.2023.00016">https://doi.org/10.1109/VL-HCC57772.2023.00016</a></text>
<text top="343" left="69" width="488" height="11" font="9">[48] Aleksandar Nanevski, Frank Pfenning, and Brigitte Pientka. 2008. Contextual modal type theory.</text>
<text top="343" left="560" width="100" height="11" font="33">ACM Transactions on</text>
<text top="358" left="94" width="138" height="11" font="33">Computational Logic (TOCL)</text>
<text top="358" left="235" width="81" height="11" font="9">9, 3 (2008), 1–49.</text>
<text top="358" left="323" width="230" height="11" font="32"><a href="https://dl.acm.org/doi/10.1145/1352582.1352591">https://dl.acm.org/doi/10.1145/1352582.1352591</a></text>
<text top="373" left="69" width="593" height="11" font="9">[49] Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak,</text>
<text top="388" left="94" width="566" height="11" font="9">Jong Wook Kim, Chris Hallacy, Johannes Heidecke, Pranav Shyam, Boris Power, Tyna Eloundou Nekoul, Girish</text>
<text top="403" left="94" width="567" height="11" font="9">Sastry, Gretchen Krueger, David Schnurr, Felipe Petroski Such, Kenny Hsu, Madeleine Thompson, Tabarak Khan,</text>
<text top="418" left="94" width="566" height="11" font="9">Toki Sherbakov, Joanne Jang, Peter Welinder, and Lilian Weng. 2022. Text and Code Embeddings by Contrastive</text>
<text top="432" left="94" width="100" height="11" font="9">Pre-Training. <a href="https://arxiv.org/abs/2201.10005">arXiv:</a></text>
<text top="432" left="194" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2201.10005">2201.10005</a></text>
<text top="432" left="250" width="35" height="11" font="9">[cs.CL]</text>
<text top="447" left="69" width="593" height="11" font="9">[50] Cyrus Omar, Ian Voysey, Ravi Chugh, and Matthew A. Hammer. 2019. Live Functional Programming with Typed Holes.</text>
<text top="462" left="94" width="344" height="11" font="33">Proceedings of the ACM on Programming Languages (PACMPL), Issue POPL</text>
<text top="462" left="440" width="31" height="11" font="9">(2019).</text>
<text top="462" left="476" width="184" height="11" font="32"><a href="https://dl.acm.org/doi/10.1145/3290327">https://dl.acm.org/doi/10.1145/3290327</a></text>
<text top="477" left="69" width="592" height="11" font="9">[51] Cyrus Omar, Ian Voysey, Michael Hilton, Jonathan Aldrich, and Matthew A. Hammer. 2017. Hazelnut: A Bidirectionally</text>
<text top="492" left="94" width="181" height="11" font="9">Typed Structure Editor Calculus. In</text>
<text top="492" left="279" width="380" height="11" font="33">ACM SIGPLAN Symposium on Principles of Programming Languages (POPL)</text>
<text top="492" left="659" width="3" height="11" font="9">.</text>
<text top="507" left="94" width="230" height="11" font="32"><a href="https://dl.acm.org/doi/10.1145/3009837.3009900">https://dl.acm.org/doi/10.1145/3009837.3009900</a></text>
<text top="522" left="69" width="593" height="11" font="9">[52] Cyrus Omar, Ian Voysey, Michael Hilton, Joshua Sunshine, Claire Le Goues, Jonathan Aldrich, and Matthew A. Hammer.</text>
<text top="537" left="94" width="289" height="11" font="9">2017. Toward Semantic Foundations for Program Editors. In</text>
<text top="537" left="386" width="274" height="11" font="33">Summit on Advances in Programming Languages (SNAPL)</text>
<text top="537" left="660" width="3" height="11" font="9">.</text>
<text top="552" left="94" width="155" height="11" font="32"><a href="https://arxiv.org/abs/1703.08694">https://arxiv.org/abs/1703.08694</a></text>
<text top="567" left="69" width="167" height="11" font="9">[53] OpenAI. 2024. Hello GPT-4o.</text>
<text top="567" left="245" width="191" height="11" font="32"><a href="https://openai.com/index/hello-gpt-4o/">https://openai.com/index/hello-gpt-4o/</a></text>
<text top="567" left="440" width="135" height="11" font="9">[Accessed August 31, 2024].</text>
<text top="582" left="69" width="286" height="11" font="9">[54] OpenAI. 2024. OpenAI Platform Chat Completions.</text>
<text top="582" left="368" width="292" height="11" font="32"><a href="https://platform.openai.com/docs/guides/chat-completions">https://platform.openai.com/docs/guides/chat-completions</a></text>
<text top="597" left="94" width="147" height="11" font="9">[Accessed September 1, 2024].</text>
<text top="612" left="69" width="521" height="11" font="9">[55] Peter-Michael Osera and Steve Zdancewic. 2015. Type-and-Example-Directed Program Synthesis. In</text>
<text top="612" left="593" width="67" height="11" font="33">Conference on</text>
<text top="627" left="94" width="282" height="11" font="33">Programming Language Design and Implementation (PLDI)</text>
<text top="627" left="377" width="3" height="11" font="9">.</text>
<text top="642" left="69" width="594" height="11" font="9">[56] Shuyin Ouyang, Jie M. Zhang, Mark Harman, and Meng Wang. 2023. LLM is Like a Box of Chocolates: the Non-</text>
<text top="657" left="94" width="259" height="11" font="9">determinism of ChatGPT in Code Generation. <a href="https://arxiv.org/abs/2308.02828">arXiv:</a></text>
<text top="657" left="353" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2308.02828">2308.02828</a></text>
<text top="657" left="409" width="33" height="11" font="9">[cs.SE]</text>
<text top="672" left="69" width="593" height="11" font="9">[57] Nikhil Parasaram, Huijie Yan, Boyu Yang, Zineb Flahy, Abriele Qudsi, Damian Ziaber, Earl Barr, and Sergey Mechtaev.</text>
<text top="687" left="94" width="351" height="11" font="9">2024. The Fact Selection Problem in LLM-Based Program Repair. <a href="https://arxiv.org/abs/2404.05520">arXiv:</a></text>
<text top="687" left="445" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2404.05520">2404.05520</a></text>
<text top="687" left="501" width="33" height="11" font="9">[cs.SE]</text>
<text top="701" left="69" width="593" height="11" font="9">[58] Pardis Pashakhanloo, Aaditya Naik, Yuepeng Wang, Hanjun Dai, Petros Maniatis, and Mayur Naik. 2021. Codetrek:</text>
<text top="716" left="94" width="378" height="11" font="9">Flexible modeling of code using an extensible relational representation. In</text>
<text top="716" left="477" width="184" height="11" font="33">International Conference on Learning</text>
<text top="731" left="94" width="74" height="11" font="33">Representations</text>
<text top="731" left="168" width="3" height="11" font="9">.</text>
<text top="731" left="178" width="271" height="11" font="32"><a href="https://www.seas.upenn.edu/~mhnaik/papers/iclr22.pdf">https://www.seas.upenn.edu/~mhnaik/papers/iclr22.pdf</a></text>
<text top="746" left="69" width="592" height="11" font="9">[59] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt. 2023. Examining Zero-Shot Vulnerability Repair with</text>
<text top="761" left="94" width="132" height="11" font="9">Large Language Models. In</text>
<text top="761" left="229" width="241" height="11" font="33">2023 IEEE Symposium on Security and Privacy (SP)</text>
<text top="761" left="470" width="191" height="11" font="9">. IEEE Computer Society, Los Alamitos,</text>
<text top="776" left="94" width="103" height="11" font="9">CA, USA, 2339–2356.</text>
<text top="776" left="205" width="226" height="11" font="32"><a href="https://doi.org/10.1109/SP46215.2023.10179420">https://doi.org/10.1109/SP46215.2023.10179420</a></text>
<text top="791" left="69" width="592" height="11" font="9">[60] Hengzhi Pei, Jinman Zhao, Leonard Lausen, Sheng Zha, and George Karypis. 2023. Better context makes better</text>
<text top="806" left="94" width="375" height="11" font="9">code language models: a case study on function call argument completion. In</text>
<text top="806" left="472" width="188" height="11" font="33">Proceedings of the Thirty-Seventh AAAI</text>
<text top="821" left="94" width="566" height="11" font="33">Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and</text>
<text top="836" left="94" width="467" height="11" font="33">Thirteenth Symposium on Educational Advances in Artificial Intelligence (AAAI’23/IAAI’23/EAAI’23)</text>
<text top="836" left="561" width="99" height="11" font="9">. AAAI Press, Article</text>
<text top="851" left="94" width="19" height="11" font="9">584.</text>
<text top="851" left="123" width="192" height="11" font="32"><a href="https://doi.org/10.1609/aaai.v37i4.25653">https://doi.org/10.1609/aaai.v37i4.25653</a></text>
<text top="866" left="69" width="594" height="11" font="9">[61] Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer. 2023. The Impact of AI on Developer Productivity: Evi-</text>
<text top="881" left="94" width="133" height="11" font="9">dence from GitHub Copilot.</text>
<text top="881" left="232" width="25" height="11" font="33">CoRR</text>
<text top="881" left="260" width="105" height="11" font="9">abs/2302.06590 (2023).</text>
<text top="881" left="373" width="204" height="11" font="32"><a href="https://doi.org/10.48550/ARXIV.2302.06590">https://doi.org/10.48550/ARXIV.2302.06590</a></text>
<text top="881" left="579" width="29" height="11" font="9"><a href="https://arxiv.org/abs/2302.06590">arXiv:</a></text>
<text top="881" left="609" width="52" height="11" font="32"><a href="https://arxiv.org/abs/2302.06590">2302.06590</a></text>
<text top="896" left="69" width="147" height="11" font="9">[62] Benjamin C. Pierce. 2002.</text>
<text top="896" left="220" width="167" height="11" font="33">Types and Programming Languages</text>
<text top="896" left="387" width="58" height="11" font="9">. MIT Press.</text>
<text top="896" left="453" width="207" height="11" font="32"><a href="https://dl.acm.org/doi/book/10.5555/509043">https://dl.acm.org/doi/book/10.5555/509043</a></text>
<text top="911" left="69" width="593" height="11" font="9">[63] Julian Aron Prenner, Hlib Babii, and Romain Robbes. 2022. Can OpenAI’s codex fix bugs? an evaluation on QuixBugs.</text>
<text top="926" left="94" width="10" height="11" font="9">In</text>
<text top="926" left="107" width="373" height="11" font="33">Proceedings of the Third International Workshop on Automated Program Repair</text>
<text top="926" left="484" width="128" height="11" font="9">(Pittsburgh, Pennsylvania)</text>
<text top="926" left="615" width="44" height="11" font="33">(APR ’22)</text>
<text top="926" left="659" width="3" height="11" font="9">.</text>
<text top="941" left="94" width="327" height="11" font="9">Association for Computing Machinery, New York, NY, USA, 69–75.</text>
<text top="941" left="429" width="194" height="11" font="32"><a href="https://doi.org/10.1145/3524459.3527351">https://doi.org/10.1145/3524459.3527351</a></text>
<text top="956" left="69" width="592" height="11" font="9">[64] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models</text>
<text top="970" left="94" width="182" height="11" font="9">are unsupervised multitask learners.</text>
<text top="971" left="282" width="62" height="11" font="33">OpenAI Blog</text>
<text top="970" left="348" width="33" height="11" font="9">(2019).</text>
<text top="970" left="389" width="272" height="11" font="32"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">https://d4mucfpksywv.cloudfront.net/better-language-</a></text>
<text top="1012" left="203" width="457" height="11" font="9"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</a></text>
</page>
<page number="30" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="30" height="11" font="12"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">288:30</a></text>
<text top="93" left="371" width="290" height="11" font="12"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Andrew Blinn, Xiang Li, June Hyung Kim, and Cyrus Omar</a></text>
<text top="134" left="94" width="331" height="11" font="32"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">models/language_models_are_unsupervised_multitask_learners.pdf</a></text>
<text top="149" left="69" width="592" height="11" font="9">[65] Oscar Sainz, Jon Campos, Iker García-Ferrero, Julen Etxaniz, Oier Lopez de Lacalle, and Eneko Agirre. 2023. NLP</text>
<text top="163" left="94" width="490" height="11" font="9">Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark. In</text>
<text top="164" left="588" width="72" height="11" font="33">Findings of the</text>
<text top="178" left="94" width="275" height="11" font="33">Association for Computational Linguistics: EMNLP 2023</text>
<text top="178" left="369" width="73" height="11" font="9">. 10776–10787.</text>
<text top="178" left="455" width="207" height="11" font="32"><a href="https://doi.org/10.18653/v1/2023.findings-emnlp.722">https://doi.org/10.18653/v1/2023.findings-</a></text>
<text top="193" left="94" width="50" height="11" font="32"><a href="https://doi.org/10.18653/v1/2023.findings-emnlp.722">emnlp.722</a></text>
<text top="208" left="69" width="593" height="11" font="9">[66] Anton Semenkin, Yaroslav Sokolov, and Evgeniia Vu. 2024. Context Composing for Full Line Code Completion.</text>
<text top="223" left="94" width="10" height="11" font="9">In</text>
<text top="223" left="109" width="472" height="11" font="33">Proceedings of the 1st ACM/IEEE Workshop on Integrated Development Environments (IDE ’24)</text>
<text top="223" left="581" width="39" height="11" font="9">. 15–17.</text>
<text top="223" left="633" width="28" height="11" font="32"><a href="https://doi.org/10.48550/arXiv.2402.09230">https:</a></text>
<text top="238" left="94" width="173" height="11" font="32"><a href="https://doi.org/10.48550/arXiv.2402.09230">//doi.org/10.48550/arXiv.2402.09230</a></text>
<text top="253" left="69" width="592" height="11" font="9">[67] Disha Shrivastava, Hugo Larochelle, and Daniel Tarlow. 2023. Repository-level prompt generation for large language</text>
<text top="268" left="94" width="89" height="11" font="9">models of code. In</text>
<text top="268" left="186" width="383" height="11" font="33">Proceedings of the 40th International Conference on Machine Learning (ICML’23)</text>
<text top="268" left="569" width="91" height="11" font="9">. JMLR.org, Article</text>
<text top="283" left="94" width="25" height="11" font="9">1314.</text>
<text top="283" left="126" width="230" height="11" font="32"><a href="https://dl.acm.org/doi/10.5555/3618408.3619722">https://dl.acm.org/doi/10.5555/3618408.3619722</a></text>
<text top="298" left="69" width="592" height="11" font="9">[68] Jeremy G. Siek, Michael M. Vitousek, Matteo Cimini, and John Tang Boyland. 2015. Refined Criteria for Gradual</text>
<text top="313" left="94" width="50" height="11" font="9">Typing. In</text>
<text top="313" left="147" width="513" height="11" font="33">1st Summit on Advances in Programming Languages, SNAPL 2015, May 3-6, 2015, Asilomar, California, USA</text>
<text top="328" left="94" width="72" height="11" font="33">(LIPIcs, Vol. 32)</text>
<text top="328" left="165" width="497" height="11" font="9">, Thomas Ball, Rastislav Bodík, Shriram Krishnamurthi, Benjamin S. Lerner, and Greg Morrisett (Eds.).</text>
<text top="343" left="94" width="297" height="11" font="9">Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 274–293.</text>
<text top="343" left="398" width="229" height="11" font="32"><a href="https://doi.org/10.4230/LIPICS.SNAPL.2015.274">https://doi.org/10.4230/LIPICS.SNAPL.2015.274</a></text>
<text top="358" left="69" width="220" height="11" font="9">[69] Nathan Sobo. 2024. Introducing Zed AI.</text>
<text top="358" left="297" width="131" height="11" font="32"><a href="https://zed.dev/blog/zed-ai">https://zed.dev/blog/zed-ai</a></text>
<text top="358" left="432" width="135" height="11" font="9">[Accessed August 31, 2024].</text>
<text top="373" left="69" width="319" height="11" font="9">[70] SourceGraph. 2023. Cody Context Architecture Whitepaper.</text>
<text top="373" left="396" width="265" height="11" font="32"><a href="https://sourcegraph.com/resources/a-lp-cody-context-architecture">https://sourcegraph.com/resources/a-lp-cody-context-</a></text>
<text top="388" left="94" width="59" height="11" font="32"><a href="https://sourcegraph.com/resources/a-lp-cody-context-architecture">architecture</a></text>
<text top="388" left="157" width="135" height="11" font="9">[Accessed August 31, 2024].</text>
<text top="403" left="69" width="208" height="11" font="9">[71] Parth Thakkar. 2022. Copilot Explorer.</text>
<text top="403" left="283" width="377" height="11" font="32"><a href="https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html">https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html</a></text>
<text top="418" left="94" width="135" height="11" font="9">[Accessed August 31, 2024].</text>
<text top="432" left="69" width="592" height="11" font="9">[72] U.S. Information Agency. 1948. Photograph of World’s First Computer, the Electronic Numerical Integrator and</text>
<text top="447" left="94" width="53" height="11" font="9">Calculator.</text>
<text top="447" left="156" width="184" height="11" font="32"><a href="https://catalog.archives.gov/id/594262">https://catalog.archives.gov/id/594262</a></text>
<text top="447" left="344" width="135" height="11" font="9">[Accessed August 30, 2024].</text>
<text top="462" left="69" width="593" height="11" font="9">[73] Priyan Vaithilingam, Elena L. Glassman, Peter Groenwegen, Sumit Gulwani, Austin Z. Henley, Rohan Malpani,</text>
<text top="477" left="94" width="568" height="11" font="9">David Pugh, Arjun Radhakrishna, Gustavo Soares, Joey Wang, and Aaron Yim. 2023. Towards More Effective AI-</text>
<text top="492" left="93" width="567" height="11" font="9">Assisted Programming: A Systematic Design Exploration to Improve Visual Studio IntelliCode’s User Experience. In</text>
<text top="507" left="94" width="567" height="11" font="33">45th IEEE/ACM International Conference on Software Engineering: Software Engineering in Practice, SEIP@ICSE 2023,</text>
<text top="522" left="94" width="182" height="11" font="33">Melbourne, Australia, May 14-20, 2023</text>
<text top="522" left="276" width="77" height="11" font="9">. IEEE, 185–195.</text>
<text top="522" left="361" width="248" height="11" font="32"><a href="https://doi.org/10.1109/ICSE-SEIP58684.2023.00022">https://doi.org/10.1109/ICSE-SEIP58684.2023.00022</a></text>
<text top="537" left="69" width="592" height="11" font="9">[74] Priyan Vaithilingam, Tianyi Zhang, and Elena L. Glassman. 2022. Expectation vs. Experience: Evaluating the Usability</text>
<text top="552" left="94" width="335" height="11" font="9">of Code Generation Tools Powered by Large Language Models. In</text>
<text top="552" left="433" width="227" height="11" font="33">CHI ’22: CHI Conference on Human Factors in</text>
<text top="567" left="94" width="432" height="11" font="33">Computing Systems, New Orleans, LA, USA, 29 April 2022 - 5 May 2022, Extended Abstracts</text>
<text top="567" left="527" width="134" height="11" font="9">, Simone D. J. Barbosa, Cliff</text>
<text top="582" left="94" width="358" height="11" font="9">Lampe, Caroline Appert, and David A. Shamma (Eds.). ACM, 332:1–332:7.</text>
<text top="582" left="460" width="194" height="11" font="32"><a href="https://doi.org/10.1145/3491101.3519665">https://doi.org/10.1145/3491101.3519665</a></text>
<text top="597" left="69" width="592" height="11" font="9">[75] Priyan Vaithilingam, Tianyi Zhang, and Elena L. Glassman. 2022. Expectation vs. Experience: Evaluating the Usability</text>
<text top="612" left="94" width="324" height="11" font="9">of Code Generation Tools Powered by Large Language Models. In</text>
<text top="612" left="422" width="239" height="11" font="33">Extended Abstracts of the 2022 CHI Conference on</text>
<text top="627" left="94" width="183" height="11" font="33">Human Factors in Computing Systems</text>
<text top="627" left="281" width="119" height="11" font="9">(New Orleans, LA, USA)</text>
<text top="627" left="403" width="61" height="11" font="33">(CHI EA ’22)</text>
<text top="627" left="464" width="198" height="11" font="9">. Association for Computing Machinery,</text>
<text top="642" left="94" width="200" height="11" font="9">New York, NY, USA, Article 332, 7 pages.</text>
<text top="642" left="303" width="194" height="11" font="32"><a href="https://doi.org/10.1145/3491101.3519665">https://doi.org/10.1145/3491101.3519665</a></text>
<text top="657" left="69" width="593" height="11" font="9">[76] Yanlin Wang, Yanli Wang, Daya Guo, Jiachi Chen, Ruikai Zhang, Yuchi Ma, and Zibin Zheng. 2024. RLCoder:</text>
<text top="672" left="94" width="347" height="11" font="9">Reinforcement Learning for Repository-Level Code Completion. <a href="https://arxiv.org/abs/2407.19487">arXiv:</a></text>
<text top="672" left="441" width="52" height="11" font="32"><a href="https://arxiv.org/abs/2407.19487">2407.19487</a></text>
<text top="672" left="496" width="33" height="11" font="9">[cs.SE]</text>
<text top="672" left="535" width="127" height="11" font="32"><a href="https://arxiv.org/abs/2407.19487">https://arxiv.org/abs/2407.</a></text>
<text top="687" left="94" width="28" height="11" font="32"><a href="https://arxiv.org/abs/2407.19487">19487</a></text>
<text top="701" left="69" width="592" height="11" font="9">[77] Yuxiang Wei, Chunqiu Steven Xia, and Lingming Zhang. 2023. Copiloting the Copilots: Fusing Large Language Models</text>
<text top="716" left="94" width="303" height="11" font="9">with Completion Engines for Automated Program Repair. In</text>
<text top="716" left="400" width="260" height="11" font="33">Proceedings of the 31st ACM Joint European Software</text>
<text top="731" left="94" width="486" height="11" font="33">Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2023)</text>
<text top="731" left="580" width="81" height="11" font="9">. Association for</text>
<text top="746" left="94" width="261" height="11" font="9">Computing Machinery, New York, NY, USA, 172–184.</text>
<text top="746" left="364" width="194" height="11" font="32"><a href="https://doi.org/10.1145/3611643.3616271">https://doi.org/10.1145/3611643.3616271</a></text>
<text top="761" left="69" width="592" height="11" font="9">[78] Frank F. Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn. 2022. A systematic evaluation of large language</text>
<text top="776" left="94" width="87" height="11" font="9">models of code. In</text>
<text top="776" left="184" width="478" height="11" font="33">MAPS@PLDI 2022: 6th ACM SIGPLAN International Symposium on Machine Programming, San Diego,</text>
<text top="791" left="94" width="108" height="11" font="33">CA, USA, 13 June 2022</text>
<text top="791" left="202" width="63" height="11" font="9">. ACM, 1–10.</text>
<text top="791" left="272" width="194" height="11" font="32"><a href="https://doi.org/10.1145/3520312.3534862">https://doi.org/10.1145/3520312.3534862</a></text>
<text top="806" left="69" width="593" height="11" font="9">[79] Rongwu Xu, Zehan Qi, Cunxiang Wang, Hongru Wang, Yue Zhang, and Wei Xu. 2024. Knowledge Conflicts for LLMs:</text>
<text top="821" left="94" width="83" height="11" font="9">A Survey. <a href="https://arxiv.org/abs/2403.08319">arXiv:</a></text>
<text top="821" left="177" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2403.08319">2403.08319</a></text>
<text top="821" left="232" width="35" height="11" font="9">[cs.CL]</text>
<text top="836" left="69" width="592" height="11" font="9">[80] Ziwei Xu, Sanjay Jain, and Mohan Kankanhalli. 2024. Hallucination is inevitable: An innate limitation of large language</text>
<text top="851" left="94" width="73" height="11" font="9">models. <a href="https://arxiv.org/abs/2401.11817">arXiv:</a></text>
<text top="851" left="167" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2401.11817">2401.11817</a></text>
<text top="851" left="223" width="35" height="11" font="9">[cs.CL]</text>
<text top="866" left="69" width="592" height="11" font="9">[81] Yongwei Yuan, Scott Guest, Eric Griffis, Hannah Potter, David Moon, and Cyrus Omar. 2023. Live Pattern Matching</text>
<text top="881" left="94" width="89" height="11" font="9">with Typed Holes.</text>
<text top="881" left="188" width="126" height="11" font="33">Proc. ACM Program. Lang.</text>
<text top="881" left="317" width="141" height="11" font="9">7, OOPSLA1 (2023), 609–635.</text>
<text top="881" left="465" width="152" height="11" font="32"><a href="https://doi.org/10.1145/3586048">https://doi.org/10.1145/3586048</a></text>
<text top="896" left="69" width="592" height="11" font="9">[82] Daoguang Zan, Bei Chen, Yongshun Gong, Junzhi Cao, Fengji Zhang, Bingchao Wu, Bei Guan, Yilong Yin, and Yongji</text>
<text top="911" left="94" width="437" height="11" font="9">Wang. 2023. Private-library-oriented code generation with large language models. <a href="https://arxiv.org/abs/2307.15370">arXiv:</a></text>
<text top="911" left="531" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2307.15370">2307.15370</a></text>
<text top="911" left="586" width="33" height="11" font="9">[cs.SE]</text>
<text top="926" left="69" width="593" height="11" font="9">[83] Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen.</text>
<text top="941" left="94" width="495" height="11" font="9">2023. RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation. In</text>
<text top="941" left="592" width="68" height="11" font="33">Proceedings of</text>
<text top="956" left="94" width="346" height="11" font="33">the 2023 Conference on Empirical Methods in Natural Language Processing</text>
<text top="956" left="441" width="58" height="11" font="9">. 2471–2484.</text>
<text top="956" left="506" width="156" height="11" font="32"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.151">https://doi.org/10.18653/v1/2023.</a></text>
<text top="970" left="94" width="79" height="11" font="32"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.151">emnlp-main.151</a></text>
<text top="1012" left="69" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<page number="31" position="absolute" top="0" left="0" height="1080" width="729">
<text top="93" left="69" width="337" height="11" font="12">Statically Contextualizing Large Language Models with Typed Holes</text>
<text top="93" left="630" width="30" height="11" font="12">288:31</text>
<text top="134" left="69" width="593" height="11" font="9">[84] Jialu Zhang, José Pablo Cambronero, Sumit Gulwani, Vu Le, Ruzica Piskac, Gustavo Soares, and Gust Verbruggen. 2024.</text>
<text top="149" left="94" width="366" height="11" font="9">PyDex: Repairing Bugs in Introductory Python Assignments using LLMs.</text>
<text top="149" left="465" width="129" height="11" font="33">Proc. ACM Program. Lang.</text>
<text top="149" left="597" width="64" height="11" font="9">8, OOPSLA1,</text>
<text top="163" left="94" width="107" height="11" font="9">Article 133 (apr 2024).</text>
<text top="163" left="208" width="152" height="11" font="32"><a href="https://doi.org/10.1145/3649850">https://doi.org/10.1145/3649850</a></text>
<text top="178" left="69" width="593" height="11" font="9">[85] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen,</text>
<text top="193" left="94" width="478" height="11" font="9">et al. 2023. Siren’s song in the AI ocean: a survey on hallucination in large language models. <a href="https://arxiv.org/abs/2309.01219">arXiv:</a></text>
<text top="193" left="573" width="52" height="11" font="32"><a href="https://arxiv.org/abs/2309.01219">2309.01219</a></text>
<text top="193" left="628" width="33" height="11" font="9">[cs.SE]</text>
<text top="208" left="69" width="592" height="11" font="9">[86] Yuntong Zhang, Haifeng Ruan, Zhiyu Fan, and Abhik Roychoudhury. 2024. AutoCodeRover: Autonomous Program</text>
<text top="223" left="94" width="104" height="11" font="9">Improvement. <a href="https://arxiv.org/abs/2404.05427">arXiv:</a></text>
<text top="223" left="198" width="53" height="11" font="32"><a href="https://arxiv.org/abs/2404.05427">2404.05427</a></text>
<text top="223" left="254" width="33" height="11" font="9">[cs.SE]</text>
<text top="238" left="69" width="592" height="11" font="9">[87] Eric Zhao, Raef Maroof, Anand Dukkipati, Andrew Blinn, Zhiyi Pan, and Cyrus Omar. 2024. Total Type Error</text>
<text top="253" left="94" width="186" height="11" font="9">Localization and Recovery with Holes.</text>
<text top="253" left="285" width="125" height="11" font="33">Proc. ACM Program. Lang.</text>
<text top="253" left="412" width="129" height="11" font="9">8, POPL (2024), 2041–2068.</text>
<text top="253" left="549" width="112" height="11" font="32"><a href="https://doi.org/10.1145/3632910">https://doi.org/10.1145/</a></text>
<text top="268" left="94" width="39" height="11" font="32"><a href="https://doi.org/10.1145/3632910">3632910</a></text>
<text top="283" left="69" width="592" height="11" font="9">[88] Albert Ziegler, Eirini Kalliamvakou, X. Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and</text>
<text top="298" left="94" width="392" height="11" font="9">Edward Aftandilian. 2024. Measuring GitHub Copilot’s Impact on Productivity.</text>
<text top="298" left="490" width="75" height="11" font="33">Commun. ACM</text>
<text top="298" left="569" width="93" height="11" font="9">67, 3 (2024), 54–63.</text>
<text top="313" left="94" width="152" height="11" font="32"><a href="https://doi.org/10.1145/3633453">https://doi.org/10.1145/3633453</a></text>
<text top="328" left="69" width="592" height="11" font="9">[89] Barret Zoph, Colin Raffel, Dale Schuurmans, Dani Yogatama, Denny Zhou, Don Metzler, Ed H. Chi, Jason Wei, Jeff</text>
<text top="343" left="94" width="567" height="11" font="9">Dean, Liam B. Fedus, Maarten Paul Bosma, Oriol Vinyals, Percy Liang, Sebastian Borgeaud, Tatsunori B. Hashimoto,</text>
<text top="358" left="94" width="303" height="11" font="9">and Yi Tay. 2022. Emergent abilities of large language models.</text>
<text top="358" left="401" width="29" height="11" font="33">TMLR</text>
<text top="358" left="433" width="32" height="11" font="9">(2022).</text>
<text top="386" left="69" width="228" height="13" font="3">Received 2024-04-06; accepted 2024-08-18</text>
<text top="1012" left="203" width="457" height="11" font="9">Proc. ACM Program. Lang., Vol. 8, No. OOPSLA2, Article 288. Publication date: October 2024.</text>
</page>
<outline>
<item page="1">Abstract</item>
<item page="2">1 Introduction</item>
<outline>
<item page="4">1.1 Evaluation Overview</item>
</outline>
<item page="6">2 Static Retrieval and Error Correction in the Hazel Assistant</item>
<outline>
<item page="6">2.1 Hazel</item>
<item page="7">2.2 Hazel Assistant</item>
<item page="8">2.3 The Hazel Assistant Trialogue</item>
<item page="8">2.4 System Message: The Hazel Crash Course</item>
<item page="9">2.5 Type Retrieval</item>
<item page="11">2.6 Relevant Headers from the Typing Context</item>
<item page="13">2.7 Syntactic and Semantic Error Correction</item>
<item page="13">2.8 Experimental Evaluation</item>
<item page="15">2.9 Hazel GPT-4 Results</item>
<item page="19">2.10 Hazel StarCoder2-15B Results</item>
</outline>
<item page="19">3 Static Retrieval in TypeScript</item>
<outline>
<item page="20">3.1 TypeScript Methodology</item>
<item page="20">3.2 TypeScript GPT-4 Results</item>
<item page="21">3.3 TypeScript StarCoder2-15B Results</item>
</outline>
<item page="21">4 Threats to Validity</item>
<item page="22">5 ChatLSP</item>
<outline>
<item page="22">5.1 ChatLSP API Methods</item>
<item page="23">5.2 Static Contextualization Language Server API</item>
</outline>
<item page="23">6 Related work</item>
<item page="25">7 Discussion and Conclusion</item>
<item page="26">8 Data Availability</item>
<item page="26">9 Acknowledgements</item>
<item page="26">References</item>
</outline>
</pdf2xml>
